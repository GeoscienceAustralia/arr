<?xml version="1.0" encoding="UTF-8"?>
<chapter status="In Preparation" xml:id="b3_ch3"
         xmlns="http://docbook.org/ns/docbook"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:svg="http://www.w3.org/2000/svg"
         xmlns:m="http://www.w3.org/1998/Math/MathML"
         xmlns:html="http://www.w3.org/1999/xhtml"
         xmlns:db="http://docbook.org/ns/docbook">
  <info>
    <title>CHAPTER 2 – AT-SITE FLOOD FREQUENCY ANALYSIS</title>

    <xi:include href="../../common/authors/rahman_ataur.xml"/>

    <xi:include href="../../common/authors/haddad_khaled.xml"/>

    <xi:include href="../../common/authors/kuczera_george.xml"/>

    <xi:include href="../../common/authors/weinmann_erwin.xml"/>
  </info>

  <section>
    <title>Introduction</title>

    <para>Flood frequency analysis refers to procedures that use recorded and
    related flood data to identify the underlying probability model of flood
    peaks at a particular location in the catchment. The flood probability
    model can then be used to perform risk-based design and flood risk
    assessment and to provide input to regional flood estimation
    methods.</para>

    <para>The primary purpose of this chapter is to present guidelines on
    performing flood frequency analyses<superscript>1</superscript>. Often
    judgment will need to be exercised. To inform such judgments, this chapter
    describes the key conceptual foundations that underpin flood frequency
    analysis – the reader will need an understanding of elementary probability
    theory and statistics to get maximum benefit. In addition a number of
    worked examples are provided to provide deeper insight with the implied
    caveat that the examples are not exhaustive in their scope. While it is
    expected that most users will use software written by others to implement
    the methods described in this chapter, sufficient information is provided
    to enable users to develop their own software applications.</para>

    <para><superscript>1</superscript>The chapter represents an update of
    Chapter 10 of the 3rd Edition of Australian Rainfall and Runoff (Pilgrim
    and Doran, 1987). Where appropriate the original contribution by Pilgrim
    and Doran has been retained. The major changes include introduction of
    non-homogeneous probability models, replacement of product log-moments
    with more efficient estimation methods, use of Bayesian methods to make
    better use of available flood information (such as censored flow data,
    rating error and regional information), reduced prescription about the
    choice of flood probability model, improved identification of potentially
    influential low flows and guidance on fitting frequency curves to
    “difficult” data sets.</para>
  </section>

  <section>
    <title>Conceptual Framework</title>

    <section>
      <title>Definition of Regional Flood Frequency Estimation</title>

      <para>In flood frequency analysis flood peaks are considered to be
      random variables. Following convention the random variable denoting the
      flood peak is denoted by an upper-case symbol (e.g., Q) whereas a
      specific realization (or sample) is denoted by the lower-case symbol
      (e.g., q) – where there is no ambiguity lower-case symbols will be
      used.</para>

      <para>It is assumed that each realization q is statistically independent
      of other realizations. This is the standard assumption in flood
      frequency analysis and is believed to be widely applicable [e.g.,
      Stedinger et al., 1993].</para>

      <para>In its most general form, the flood probability model can be
      described by its probability density function (pdf) p(q|θ(x)) where θ(x)
      is the vector (or list) of parameters dependent on x, a vector of
      exogenous or external variables such as climate indicies. The symbol ‘|’
      is interpreted as follows: the variable to the left of ‘|’ is a random
      variable, while the variables to the right of ‘|’ are known
      values.</para>

      <para>The distribution function of Q is defined as the non-exceedance
      probability P(Q≤q) and is related to the pdf by</para>

      <equation>
        <m:mrow><m:mi>P(Q≤q∣θ</m:mi><m:mo>(x))
        =</m:mo><m:mrow><m:mrow><m:mrow><m:munderover><m:mo>∫</m:mo><m:mi>o</m:mi><m:mi>q</m:mi></m:munderover><m:mi>p(s∣</m:mi></m:mrow><m:mi>θ</m:mi></m:mrow><m:mi>(x))
        ds</m:mi></m:mrow></m:mrow>
      </equation>

      <para>Empirically the pdf of q is the limiting form of the histogram of
      q as the number of samples approaches infinity. Importantly, eqn) shows
      that the area under the pdf is interpreted as probability.</para>

      <para>Homogeneous flood probability model</para>

      <para>The simplest form of the flood probability model arises when the
      parameters θ does not depend on an exogenous vector x. In that case each
      flood peak is considered to be a random realization from the same
      probability model p(q|θ). Under this assumption flood peaks form a
      homogeneous time series.</para>

      <para>Non-homogeneous flood probability model</para>

      <para>A more complicated situation arises when flood peaks do not form a
      homogeneous time series. This may arise for a number of reasons
      including the following:</para>

      <itemizedlist>
        <listitem>
          <para>Rainfall and flood mechanisms may be changing over time. For
          example, long-term climate change due to global warming, land use
          change and river regulation may render the flood record
          non-homogeneous.</para>
        </listitem>

        <listitem>
          <para>Climate may experience pseudo-periodic shifts that persist
          over periods lasting from several years to several decades. There is
          growing evidence that parts of Australia are subject to such forcing
          and that this significantly affects flood risk [for example, Franks
          and Kuczera, 2002; Franks, 2002a,b; Kiem et al., 2003; Micevski et
          al., 2003]</para>
        </listitem>
      </itemizedlist>

      <para>The user needs to assess the significance of such factors and
      identify appropriate exogenous variables x to condition the flood
      probability model. Although this chapter will provide some guidance it
      is stressed that this is an area of continuing research – users are
      therefore advised to keep abreast of new developments.</para>
    </section>

    <section>
      <title>Annual Maximum and Peak-Over-Threshold Perspectives</title>

      <para>Flood frequency analysis deals with the probability distribution
      of significant flood peaks. Throughout the year, there are typically
      many flood peaks associated with individual storm events. This is
      illustrated in Figure 1 which illustrates a time series record of
      continuous streamflow discharge. Two types of flood data can be
      extracted from such a record. In turn two measures of flood risk can be
      estimated:</para>

      <section>
        <title>Annual maximum (AM) series</title>

        <para>The AM series is formed by extracting the maximum discharge in
        each year. This yields the series
        {w<subscript>1</subscript>,..,w<subscript>n</subscript>} where
        w<subscript>i</subscript> is the maximum discharge in the
        i<superscript>th</superscript> of the n-year record.</para>

        <para>The data in the AM series can be used to estimate the
        probability that the maximum flood discharge in a year exceeds a
        particular magnitude w. In ARR this probability is called the annual
        exceedance probability AEP(w) and is formally defined as</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:mrow>
                <m:mi>AEP(w)</m:mi>

                <m:mo>=</m:mo>

                <m:mi>P(W&gt;w∣θ(x))</m:mi>
              </m:mrow>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:munderover>
                  <m:mo>∫</m:mo>

                  <m:mi>q</m:mi>

                  <m:mi>∞</m:mi>
                </m:munderover>

                <m:mi>p(s∣θ(x))ds</m:mi>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <para>where w is the maximum flood discharge in a year. Often it is
        convenient to express the AEP as the ratio 1 in Y. For example, the 1
        in 100 AEP is equivalent to an AEP of 0.01.</para>
      </section>

      <section>
        <title>Peak-over-threshold (POT) series</title>

        <para>The POT series is formed by extracting from the record every
        statistically independent peak discharge (that exceeds a threshold
        discharge). This yields the series
        {q<subscript>1</subscript>,..,q<subscript>m</subscript>} where
        q<subscript>i</subscript> is the peak discharge associated with the
        i<superscript>th</superscript> statistically independent flood event
        in the n-year record. Typically the threshold discharge is selected so
        that m is about 2 to 3 times greater than n.</para>

        <para>The data in the POT series can be used to estimate the
        probability distribution of the time to the next peak discharge that
        exceeds a particular magnitude</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:mi>P(Time to next peak exceeding q≤ t)</m:mi>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:mi>1</m:mi>

                <m:mo>-</m:mo>

                <m:msup>
                  <m:mi>e</m:mi>

                  <m:mi>-EY(q)t</m:mi>
                </m:msup>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <para>where t is time expressed in years and EY(q), the number of
        exceedances per year, is the expected number of times in a year that
        the peak discharge exceeds q</para>
      </section>

      <section>
        <title>When to use AM and POT series</title>

        <para>The risk measures AEP and EY are intimately connected. The
        analysis presented in Box 1 shows that</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:mi>EY(w)</m:mi>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:msub>
                  <m:mi>-log</m:mi>

                  <m:mi>e</m:mi>
                </m:msub>

                <m:mtext>[1-AEP(w)]</m:mtext>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:mo>=</m:mo>

              <m:mrow>
                <m:msub>
                  <m:mi>-log</m:mi>

                  <m:mi>e</m:mi>
                </m:msub>

                <m:mrow>
                  <m:mo>[</m:mo>

                  <m:mrow>
                    <m:mrow>
                      <m:mi>1-</m:mi>

                      <m:mfrac>
                        <m:mi>1</m:mi>

                        <m:mi>Y(w)</m:mi>
                      </m:mfrac>
                    </m:mrow>
                  </m:mrow>

                  <m:mo>]</m:mo>
                </m:mrow>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <para>where AEP(w) is expressed as the ratio 1 in Y(w). This
        relationship is plotted in Figure 2. For AEPs less than 0.1 (or 1 in
        10), EY and AEP are numerically the same from a practical perspective.
        However, as the AEP increases beyond 0.1, EY increases more rapidly
        than AEP. This occurs because in years with a large annual maximum
        peak, the smaller peaks of that year may exceed the annual maximum
        peak in other years.</para>

        <figure>
          <title>AEP-EY relationship</title>

          <mediaobject>
            <imageobject>
              <imagedata fileref="figures\Figure2.JPG"/>
            </imageobject>
          </mediaobject>
        </figure>

        <para>The question arises when should one use AM or POT approaches.
        The following guideline is offered:</para>

        <para>(i) AEP of interest &lt; 1 in 10</para>

        <para>AEPs in this range are generally required for estimation of a
        design flood for a structure or works at a particular site. Use of AM
        series is generally preferred because it yields virtually identical
        answers to POT series in most cases, provides a more
        robust<superscript>2</superscript> estimate of low AEP floods and is
        easier to extract and define.</para>

        <para>(ii) EY of interest &gt; 1 in 10 years</para>

        <para><superscript>2</superscript>In a POT series there are typically
        2 to 3 times more peaks than in the corresponding AM series. The
        additional peaks are largely smaller peaks. In the case when the data
        is not well fitted by the chosen probability model, the fit to the
        upper part of the distribution may be compromised in order to obtain a
        good fit to the smaller peaks where the bulk of the data lies.</para>

        <para>Use of POT series is generally preferred because all floods are
        of interest in this range, whether they are the highest in the
        particular year of record or not. The AM series may omit many floods
        of interest. The POT series is appropriate for estimating design
        floods with a relatively high EY in urban stormwater contexts and for
        diversion works, coffer dams and other temporary structures. However,
        in practice, flow records are not often available at sites where minor
        works with a design EY greater than 1 in 10 years is required.</para>
      </section>
    </section>

    <section>
      <title>Advantages and Disadvantages of Flood Frequency Analysis</title>

      <para>Users need to be aware of the advantages and disadvantages of
      flood frequency analysis.</para>

      <para>Flood peaks are the product of a complex joint probability process
      involving the interaction of many random variables associated with the
      rainfall event, antecedent conditions and rainfall-runoff
      transformation. Peak flood records represent the integrated response of
      the storm event with the catchment. They provide a direct measure of
      flood exceedance probabilities. As a result flood frequency analysis is
      not subject to the potential for bias, possibly large, that can affect
      alternative methods based on design rainfall [Kuczera et al.,
      2006].</para>

      <para>Other advantages of flood frequency analysis include its
      comparative simplicity and capacity to quantify uncertainty arising from
      limited information.</para>

      <para>Offsetting these significant advantages are several
      disadvantages:</para>

      <itemizedlist>
        <listitem>
          <para>The true probability distribution family M is unknown.
          Unfortunately, different models can fit the flood data with similar
          capability, yet can diverge in the right hand tail when extrapolated
          beyond the data.</para>
        </listitem>

        <listitem>
          <para>Short records may compromise the utility of flood estimates.
          Confidence limits inform the user about the credibility of the
          estimate.</para>
        </listitem>

        <listitem>
          <para>It may be difficult or impossible to adjust the data if the
          catchment conditions under which the flood data were obtained have
          changed during the period of record, or are different to those
          applying to the future economic life of a structure or works being
          designed.</para>
        </listitem>
      </itemizedlist>

      <para>Considerable extrapolation of rating curves is necessary to
      convert recorded stage to discharge for the largest flood peaks at most
      Australian gauging stations. Also the probability of malfunction of
      recording instruments is increased during major floods. Suspect floods
      and the years in which they occurred may be omitted in analysis of
      annual maximum series, but this reduces the sample size and may
      introduce bias if the suspect floods are all major events. These
      problems are inherent to the calibration of all methods employing major
      flood peaks. At this stage it is not clear whether flood frequency
      analysis is more sensitive to such problems than other methods.</para>
    </section>

    <section>
      <title>Range of Application</title>

      <para>As noted the true flood probability family M is unknown. In
      practice the choice of model is guided by goodness of fit to data.
      Therefore, use of the fitted frequency curve for AEPs reflected in the
      data is regarded as an interpolation exercise deemed to be reliable in
      the sense that confidence limits capture the uncertainty. However, when
      the frequency curve is extrapolated well beyond the observed data,
      confidence limits which quantify the effect of sampling variability on
      parameter uncertainty may underestimate the true uncertainty - model
      bias may be significant and even dominant. Example 1 demonstrates the
      need to understand the processes affecting flood peaks beyond the
      observed record and illustrates the pitfall of blind
      extrapolation.</para>

      <para>Large extrapolation of a flood frequency curve is not recommended.
      It is acknowledged that prescribing strict limits on the minimum AEP
      does not have a strong conceptual foundation. The limits to
      extrapolation should be guided by consideration of confidence limits,
      which are affected by the information content of the data and choice of
      flood model, and by judgments about model bias which cannot be
      quantified. In situations where the analyst is prepared to make the
      judgment that the processes operating in the range of the observed
      record continue to operate for larger floods, model bias may be deemed
      to be manageable – of course the effects of sampling uncertainty may be
      so amplified under significant extrapolation to render the frequency
      estimate of little value.</para>

      <para>In the absence of user analysis about the degree of model bias
      when extrapolating, the following guidelines are offered to promote
      consistency with previous practice: As discussed further in Book VI
      Section 1.2, the 1 in 100 AEP flood is the largest event that should be
      estimated by direct frequency analysis for important work. The maximum
      flood that should be estimated by this means under any circumstances is
      the 1 in 500 AEP event. Where a regional flood frequency method is used,
      the limiting AEP should be 1 in 100. Book VI Section 1 describes
      procedures for estimating floods beyond the probabilities noted above.
      These procedures interpolate flood magnitudes between the 1 in 100 AEP
      event and the probable maximum flood. While these procedures involve
      some arbitrary assumptions, they provide a consistent approach and
      overcome many of the problems involved in extrapolation of flood
      frequency analysis arising from the choice of probability model and
      estimation method.</para>
    </section>
  </section>

  <section>
    <title>SELECTION AND PREPARATION OF DATA</title>

    <section>
      <title>Requirements of Data for Valid Analysis</title>

      <para>For valid frequency analysis, the data used should constitute a
      random sample of independent values, ideally from a homogeneous
      population. Streamflow data are collected as a continuous record, and
      discrete values must be extracted from this record as the events to be
      analyzed. The problem of assessing independence of events, and of
      selecting all independent events, is illustrated by the streamflow
      record for a 1000 km<superscript>2</superscript> catchment in Figure 3.
      There is little doubt that peaks A and B are not independent or that
      they are serially correlated, while peak D is independent of A and B.
      However, the independence of peak C from A and B is open to question,
      and there is doubt as to whether the independent peaks in the record are
      B and D, or B, C and D. Methods for selecting the peaks to be included
      in the analysis are described in the following subsections.</para>

      <figure>
        <title>Hydrograph for a 1000 km2 catchment illustrating difficulty of
        assessing independence of floods.</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\Figure3.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>Lack of homogeneity of the population of floods is also a
      practical problem, particularly as the data sample from the past is used
      to derive flood estimates applicable to the design life of the structure
      or works in the future. Examples of changes in the collection of the
      data or in the nature of the catchment that lead to lack of homogeneity
      are:</para>

      <orderedlist>
        <listitem>
          <para>inability to allow for change of station rating curve, for
          example resulting from insufficient high-stage gauging;</para>
        </listitem>

        <listitem>
          <para>change of gauging station site;</para>
        </listitem>

        <listitem>
          <para>construction of large storages, levees and channel
          improvements;</para>
        </listitem>

        <listitem>
          <para>growth in the number of farm dams on the catchment; and</para>
        </listitem>

        <listitem>
          <para>changes in land use such as clearing, different farming
          practices, soil conservation works, reafforestation, and
          urbanization.</para>
        </listitem>
      </orderedlist>

      <para>The record should be carefully examined for these and other causes
      of lack of homogeneity. In some cases recorded values can be adjusted by
      means such as routing pre-dam floods through the storage to adjust them
      to equivalent present values, correcting rating errors where this is
      possible, or making some adjustment for urbanization. Such decisions
      must be made largely by judgment. As with all methods of flood
      estimation, it is important that likely conditions during the design
      life be considered rather than those existing at the time of design.
      Some arbitrary adjustment of derived values for likely changes in the
      catchment may be possible, but the recorded data must generally be
      accepted for analysis and design. Fortunately, the available evidence
      indicates that unless changes to the catchment involve large proportions
      of the total area or large changes in the storage on the catchment, the
      effects on flood magnitudes are likely to be low. Also, the effects are
      likely to be larger for small floods than for the large floods that are
      of primary interest in design.</para>
    </section>

    <section>
      <title>Types of Flood Data</title>

      <para>In the most general sense, flood peak data can be classified as
      either being gauged or censored.</para>

      <section>
        <title>Gauged data</title>

        <para>Gauged data consist of a time series of flood discharge
        estimates. Such estimates are based on observed peak (or
        instantaneous) stages (or water levels). A rating curve is used to
        transform stage observations to discharge estimates. When
        extrapolated, the rating curve can introduce large systematic error
        into discharge estimates.</para>

        <para>It is important to check how the peak discharges were obtained
        from the gauged record. Peak discharges may be derived from daily
        readings, possibly with some intermediate readings during some floods
        for part of the record, and continuous readings from the remainder of
        the record. If part of the record consists of daily readings it is
        necessary to assess whether daily readings adequately approximate the
        instantaneous peak discharge – see Example 2 for instances of adequate
        and inadequate approximations. If the daily reading is deemed an
        unreliable estimate of the peak discharge during that day, the reading
        need not be discarded but treated as a censored flow.</para>
      </section>

      <section>
        <title>Censored data</title>

        <para>Censored data consist of a time series of indicator values
        defined as</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:msub>
                <m:mi>I</m:mi>

                <m:mi>t</m:mi>
              </m:msub>

              <m:mo>(q)=</m:mo>

              <m:mrow>
                <m:mrow>
                  <m:mo>{</m:mo>

                  <m:mtable>
                    <m:mtr>
                      <m:mtd>
                        <m:mrow>
                          <m:mi>1 if the</m:mi>

                          <m:mrow>
                            <m:msup>
                              <m:mi>t</m:mi>

                              <m:mi>th</m:mi>
                            </m:msup>

                            <m:mo>flood peak &gt; threshold discharge q</m:mo>
                          </m:mrow>
                        </m:mrow>
                      </m:mtd>
                    </m:mtr>

                    <m:mtr>
                      <m:mtd>
                        <m:mrow>
                          <m:mi>-1 if the</m:mi>

                          <m:mrow>
                            <m:msup>
                              <m:mi>t</m:mi>

                              <m:mi>th</m:mi>
                            </m:msup>

                            <m:mo>flood peak ≤ threshold discharge q</m:mo>
                          </m:mrow>
                        </m:mrow>
                      </m:mtd>
                    </m:mtr>
                  </m:mtable>
                </m:mrow>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <para>They arise in a number of ways. For example, prior to gauging,
        water level records may have been kept only for large floods above
        some perception threshold. Therefore, all we may know is that there
        were n<subscript>a</subscript> flood peaks above the threshold and
        n<subscript>b</subscript> peaks below the threshold. Sometimes, we may
        deliberately exclude small floods below some threshold because the
        overall fit is being unduly influenced by the small floods.</para>

        <para>Figure 4 presents a graphical depiction of gauged and censored
        time series data. In the first part of the record all the peaks are
        below a threshold. In the second part, daily readings define a lower
        threshold for the peak. Finally in the third part, continuous gauging
        yields instantaneous peaks.</para>

        <figure>
          <title>Depiction of censored and gauged flow time series
          data.</title>

          <mediaobject>
            <imageobject>
              <imagedata fileref="figures\Figure4.JPG"/>
            </imageobject>
          </mediaobject>
        </figure>
      </section>
    </section>

    <section>
      <title>Annual Maximum Flood Gauged Series</title>

      <para>This is the most common method of selecting the floods to be
      analyzed. The series is comprised of the highest instantaneous rate of
      discharge in each year of record. The year may be a calendar year or a
      water year, the latter usually commencing at the end of the period of
      lowest average flow during the year. Where flows are highly seasonal,
      especially with a wet summer, use of the water year is preferable. The
      highest flow in each year is selected whether it is a major flood or
      not, and all other floods are neglected, even though some will be much
      larger than the maximum discharges selected from some other years. For N
      years of data, the annual flood series will consist of N values.</para>

      <para>The AM series has at least two advantages:</para>

      <orderedlist>
        <listitem>
          <para>As the individual annual maximum flows are likely to be
          separated by considerable intervals of time, it is probable that the
          values will be independent. Checking of dates of the annual maxima
          to ensure that they are likely to be independent is a simple
          procedure that should always be carried out. If the highest annual
          value occurred at the start of a year and was judged to be dependent
          on the annual maximum at the end of the previous year, the lower of
          these two values should be discarded, and the second highest flow in
          that year substituted.</para>
        </listitem>

        <listitem>
          <para>The series is easily and unambiguously extracted. Most data
          collection agencies have annual maxima on computer file and/or hard
          copy.</para>
        </listitem>
      </orderedlist>
    </section>

    <section>
      <title>Peak-Over-Threshold Gauged Series</title>

      <para>A POT flood series consists of all floods with peak discharges
      above a selected base value, regardless of the number of such floods
      occurring each year. The POT series is also referred to as the partial
      duration series or basic stage series. The number of floods K generally
      will be different to the number of years of record N, and will depend on
      the selected base discharge. The American Society of Civil Engineers
      (1949) recommended that the base discharge should be selected so that K
      is greater than N, but that there should not be more than 3 or 4 floods
      above the base in any one year. These two requirements can be
      incompatible. The U.S. Geological Survey (Dalrymple, 1960) recommended
      that K should equal 3N. If a probability distribution is to be fitted to
      the POT series the desirable base discharge and average number of floods
      per year selected depend on the type of distribution. These
      distributions are discussed further in Section 4.3. For the compound
      model using a Poisson distribution of occurrences and an exponential
      distribution of magnitudes, Tavares and da Silva (1983) and Jayasuriya
      and Mein (1985) found that K should equal 2N or greater, and the U.K
      Flood Studies Report (Natural Environment Research Council, 1975)
      recommended that K should equal 3N to 5N. For fitting the log Pearson
      III distribution, the values of the moments depend on the number of
      floods selected and the base discharge. McDermott and Pilgrim (1982) and
      Jayasuriya and Mein (1985) found that best results were obtained in this
      case when K equalled N.</para>

      <para>An important advantage of the POT series is that when the selected
      base value is sufficiently high, small events that are not really floods
      are excluded. With the AM series, non-floods in dry years may have an
      undue influence on shape of the distribution. This is particularly
      important for Australia, where both the range of flows and the
      non-occurrence of floods are greater than in many other countries such
      as the United States and the United Kingdom. For this reason it would
      also be expected that the desirable ratio of K to N would be lower in
      Australia than in these countries.</para>

      <para>A criterion for independence of successive peaks must also be
      applied in selecting events. As discussed by Laurenson (1987),
      statistical independence requires physical independence of the causative
      factors of the flood, mainly rainfall and antecedent wetness. This type
      of independence is necessary if the POT series is used to estimate the
      distribution of annual floods. On the other hand, selection of POT
      series floods for design flood studies should consider the consequences
      of the flood peaks in assessing independence of events where damages or
      financial penalties are the most important design variables. Factors to
      be considered might include duration of inundation, and time required to
      repair flood damage. In both cases, the size or response time of the
      catchment will have some effect.</para>

      <para>The decision regarding a criterion for independence therefore
      requires subjective judgment by the designer or analyst in each case.
      There is often some conflict in that some flood effects are short-lived,
      perhaps only as long as inundation, while others such as the destruction
      of an annual crop may last as long as a year. It is thus not possible to
      recommend a simple and clear-cut criterion for independence. The
      circumstances and objectives of each study, and the characteristics of
      the catchment and flood data, should be considered in each case before a
      criterion is adopted. It is inevitable that the adopted criterion will
      be arbitrary to some extent.</para>

      <para>While no specific criterion can be recommended, it may be helpful
      to consider some criteria that have been used in past studies:</para>

      <itemizedlist>
        <listitem>
          <para>Bulletin 17B of the Interagency Advisory Committee on Water
          Data (1982) states that no general criterion can be recommended and
          the decision should be based on the intended use in each case, as
          discussed above. However in Appendix 14 of that document, a study by
          Beard (1974) is summarised where the criterion used is that
          independent flood peaks should be separated by five days plus the
          natural logarithm of the square miles of drainage area, with the
          additional requirement that intermediate flows must drop to below
          75% of the lower of the two separate flood peaks. This may only be
          suitable for catchments larger than 1000
          km<superscript>2</superscript>. Jayasuriya and Mein (1985) used this
          criterion.</para>
        </listitem>

        <listitem>
          <para>The UK Flood Studies Report (Natural Environment Research
          Council, 1975) used a criterion that flood peaks should be separated
          by three times the time to peak and that the flow should decrease
          between peaks to two thirds of the first peak.</para>
        </listitem>

        <listitem>
          <para>McIllwraith (1953), in developing design rainfall data for
          flood estimation, used the following criteria based on the rainfall
          causing the floods:</para>

          <itemizedlist>
            <listitem>
              <para>for rainfalls of short duration up to two hours, only the
              one highest flood within a period of 24 hours.</para>
            </listitem>

            <listitem>
              <para>for longer rainfalls, a period of 24 hours in which no
              more than 5 mm of rain could occur between rain causing separate
              flood events.</para>
            </listitem>
          </itemizedlist>
        </listitem>
      </itemizedlist>

      <itemizedlist>
        <listitem>
          <para>In a study of small catchments, Potter and Pilgrim (1971) used
          a criterion of three calendar days between separate flood events but
          lesser events could occur in the intervening period. This was the
          most satisfactory of five criteria tested on data from seven small
          catchments located throughout eastern New South Wales. It also gave
          the closest approximation to the above criteria used by McIllwraith
          (1953).</para>
        </listitem>

        <listitem>
          <para>Pilgrim and McDermott (1982) and McDermott and Pilgrim (1983)
          adopted monthly maximum peak flows to give an effective criterion of
          independence in developing a design procedure for small to medium
          sized catchments. This was based primarily on the assumption that
          little additional damage would be caused by floods occurring within
          a month, and thus closer floods would not be independent in terms of
          their effects. This criterion was also used by Adams and McMahon
          (1985) and Adams (1987).</para>
        </listitem>
      </itemizedlist>

      <para>The criteria cited above represent a wide range, and illustrate
      the difficult and subjective nature of the choice. It is stressed that
      these criteria have been described for illustrative purposes only. In
      each particular application the designer or analyst should choose a
      criterion suitable to the analysis and relevant to all of the
      circumstances and objectives.</para>
    </section>

    <section>
      <title>Monthly and Seasonal Gauged Series</title>

      <para>In some circumstances, series other than the AM or POT series may
      be used. The monthly and seasonal series are the most useful.</para>

      <para>Maximum monthly flows are an approximation to the POT series in
      most parts of Australia, as the probability of two large independent
      floods occurring in the same month is low. Tropical northern Australia,
      the west coast Tasmania and the south west of Western Australia may be
      exceptions. It should be noted that not every monthly maximum flood will
      be selected, but only those large enough to exceed a selected base
      discharge, as is the case for the POT series. The monthly series has two
      important advantages over the POT series which it approximates:</para>

      <orderedlist>
        <listitem>
          <para>It is much more easily extracted, as most gauging authorities
          have monthly maximum flows on file.</para>
        </listitem>

        <listitem>
          <para>It can be argued that a flood occurring within a month of a
          previous large flood is of little concern in design, as repairs will
          not have been undertaken and little additional damage will
          result.</para>
        </listitem>
      </orderedlist>

      <para>With the monthly series, care is required to check any floods
      selected in successive months for independence. Where the dates are
      close, the lower value should be discarded. The second highest flood in
      that month could then be checked from the records, but this would
      generally not be worthwhile. An example of use of the monthly series is
      described by Pilgrim and McDermott (1982).</para>

      <para>Seasonal flood frequencies are sometimes required. For these
      cases, the data are selected for the particular month or season as for
      the annual series, and the flood frequency analysis is carried out in a
      similar fashion to that for the annual series.</para>
    </section>

    <section>
      <title>Extension of Gauged Records</title>

      <para>It may sometimes be possible to extend the recorded data by values
      estimated from longer records on adjacent catchments, by use of a
      catchment rainfall-runoff model, or by historical data from before the
      commencement of records. If this can be done validly, the effective
      sample size of the data will be increased and the reliability of the
      analysis will be greater. However, care is necessary to ensure that the
      extended data are valid, and that real information has been added.
      Several procedures can be used:</para>

      <section>
        <title>Regression relationship with data from an adjacent
        catchment</title>

        <para>If a regression of flood peaks for the study catchment on peaks
        for an adjacent catchment can be established for the period of
        concurrent record, the relation can be used to estimate values for the
        study catchment for the longer period when records are only available
        on the adjacent catchment. The data should first be plotted on linear
        and log-log scales. A regression equation can then be fitted to the
        values or alternatively, the graphical relation can be used directly
        with a smooth curve fitted by eye.</para>

        <para>The principal shortcoming of the regression approach is that
        uncertainty in the transfer process is ignored resulting in an
        overstatement of information content. To guard against this, an
        approximate criterion for deciding whether the regression should be
        used is that the correlation coefficient of the relation should exceed
        0.85 (Fiering, 1963; Matalas and Jacobs, 1964). More rigorous criteria
        are discussed in Book III Section 2.6.5.</para>

        <para>Care is needed when annual floods are used. The dates of the
        corresponding annual floods on the adjacent catchments should be
        compared. Not infrequently, the dates are different, resulting in a
        lack of physical basis for the relation. Although relationships of
        this type seem to have been used in some regional flood frequency
        procedures, it is recommended that regressions should only be used
        when the corresponding floods result from the same storm. This problem
        is discussed further by Potter and Pilgrim (1971).</para>

        <para>When floods resulting from the same storm on adjacent catchments
        are plotted against each other, there is often a large scatter.
        Frequently, a major flood occurs on one catchment but only a moderate
        to minor flood occurs on the other. The scatter is generally greater
        than for the physically unrealistic relation using floods which are
        the maximum annual values on the two catchments but which may have
        occurred on different dates. The resulting relation using floods that
        occurred in the same storm is often so weak that it should not be used
        to extend records.</para>

        <para>Wang (2001) describes a Bayesian approach that rigorously makes
        allowance for the noise in the transfer process. This approach is
        considered superior to the traditional regression transfer.</para>
      </section>

      <section>
        <title>Use of a catchment rainfall-runoff model</title>

        <para>A catchment rainfall-runoff model can range from a simple
        rainfall-runoff regression to a catchment model that simulates
        continuous runoff hydrographs from rainfall data. This discussion
        relates primarily to the latter type of model. The calibration of such
        a model for a period with concurrent rainfall and runoff records and
        its subsequent use to extend streamflow records for the period when
        rainfall data are available, while an attractive approach, should only
        be used with great caution. Appreciable differences often occur
        between observed and modelled runoff, especially in periods not used
        in calibration and in periods with runoff not represented in the
        calibration. Estimation of model parameters involves considerable
        uncertainty. Greatest accuracy in modelling can be expected in
        calculating flows around the mean value, and larger errors are likely
        in extreme values such as the major flood peaks required for frequency
        analysis. Overall, the use of catchment models to extend flood records
        should be adopted with caution.</para>
      </section>

      <section>
        <title>Station-year method</title>

        <para>This is included only to warn against its shortcomings. In this
        procedure, records from several adjacent catchments are joined
        "end-to-end" to give a single record equal in length to the sum of the
        lengths of the constituent records. As discussed by Clarke-Hafstad
        (1942) for rainfall data, spatial correlation between the records of
        the adjacent stations invalidates the procedure.</para>
      </section>
    </section>

    <section>
      <title>Rating Error in Gauged Flows</title>

      <para>Though it is widely accepted that discharge estimates for large
      floods can be in considerable error, there is limited published
      information on these errors and how they can be allowed for in a flood
      frequency analysis. Rating error can arise from a number of
      mechanisms:</para>

      <orderedlist>
        <listitem>
          <para>For large floods the rating curve typically is extrapolated or
          fitted to indirect discharge estimates. This can introduce a
          systematic but unknown bias.</para>
        </listitem>

        <listitem>
          <para>If the gauging station is located at a site with an unstable
          cross section the rating curve may shift causing a systematic but
          unknown bias.</para>
        </listitem>
      </orderedlist>

      <para>The conceptual model of rating error presented in this section is
      based on Kuczera (1999) and is considered to be rudimentary and subject
      to refinement. It is assumed the cross section is stable with the
      primary source of rating error arising from extension of the rating
      curve to large floods.</para>

      <para>Potter and Walker (1981, 1985) observe that flood discharge is
      inferred from a rating curve which is subject to discontinuous
      measurement error. Consider Figure 5 which depicts a rating curve with
      two regions having different error characteristics. The interpolation
      zone consists of that part of the rating curve well defined by
      discharge-stage measurements; typically the error coefficient of
      variation (CV) would be small, say 1 to 5%. In the extension zone the
      rating curve is extended by methods such as slope-conveyance, log-log
      extrapolation or fitting to indirect discharge estimates. Typically such
      extensions are smooth and, therefore, can induce systematic under- or
      over-estimation of the true discharge over a range of stage. The
      extension error CV is not well known but Potter and Walker (1981, 1985)
      suggest it may be as high as 30%.</para>

      <para>Figures 5 and 6 illustrate two cases of smooth rating curve
      extension wherein systematic error is introduced. In Figure 5, an
      indirect discharge estimate is made for a large flood well beyond the
      largest gauged flow. Such estimates are subject to considerable
      uncertainty. In this example the estimate was below the true discharge.
      In the absence of any other information the rating curve is extended to
      pass smoothly through this point thereby introducing a systematic
      underestimate of large flood discharges. Even if more than one indirect
      discharge estimate were available, it is likely the errors will be
      correlated because the same biases in estimating Manning's n, conveyance
      and friction slope would be present.</para>

      <para>In Figure 6 the rating curve is extended using the
      slope-conveyance method. The method relies on extrapolating gauged
      estimates of the friction slope so that the friction slope asymptotes to
      a constant value. Depending on how well the approach to asymptotic
      conditions is defined by the data considerable systematic error in
      extrapolation may occur. Perhaps of greater concern is the assumption
      that Manning's n and conveyance can be reliably estimated in the
      overbank flow regime particularly when there are strong contrasts in
      roughness along the wetted perimeter.</para>

      <para>Though Figure 5 represents an idealization of actual rating curve
      extension two points of practical significance are noted:</para>

      <orderedlist>
        <listitem>
          <para>The error is systematic in the sense that the extended rating
          is likely to diverge from the true rating as discharge increases.
          The error, therefore, is likely to be highly correlated - in fact,
          it is perfectly correlated in the idealization of Figure 5.</para>
        </listitem>

        <listitem>
          <para>The interpolation zone anchors the error in the extension
          zone. Therefore, the error in the extension zone depends on the
          distance from the anchor point and not from the origin. This error
          is termed incremental because it originates from the anchor point
          rather than the origin of the rating curve.</para>
        </listitem>
      </orderedlist>

      <figure>
        <title>Rating curve extension by fitting to an indirect discharge
        estimate.</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\Figure5.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <figure>
        <title>Rating curve extension by slope-conveyance method.</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\Figure6.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>
    </section>

    <section>
      <title>Historical and Paleo Flood Information</title>

      <para>A flood may have occurred before the period of gauged record and
      known to be the largest flood, or flood of other known rank, over a
      period longer than that of the gauged record. Such floods can provide
      valuable information and should be included in the analysis if
      possible.</para>

      <para>Care is needed in assessing historical floods. Only stages are
      usually available, and these may be determined by flood marks recorded
      on buildings or structures, by old newspaper reports, or from verbal
      evidence. Newspaper or other photographs can provide valuable
      information. Verbal evidence is often untrustworthy, and structures may
      have been moved. A further problem is that the channel morphology, and
      hence the stage-discharge relation of the stream, may have changed from
      those applying during the period of gauged record.</para>

      <para>It is desirable to carry out frequency analyses both by including
      and excluding the historical data. The analysis including the historical
      data should be used unless in the comparison of the two analyses, the
      magnitudes of the observed peaks, uncertainty regarding the accuracy of
      the historical peaks, or other factors, suggest that the historical
      peaks are not indicative of the extended period or are not accurate. All
      decisions made should be thoroughly documented.</para>

      <para>Considerable work has been carried out in the United States on the
      assessment of paleofloods. These are major floods that have occurred
      outside the historical record, but which are evidenced by geological,
      geomorphological or botanical information. Techniques of paleohydrology
      have been described by Costa (1978, 1983, 1986) and Kochel et al. (1982)
      and more recently by O’Connell et al. (2002), and a succinct summary is
      given by Stedinger and Cohn (1986). Although high accuracy is not
      possible with these estimates, they may only be marginally less accurate
      than other estimates requiring extrapolation of rating curves, and they
      have the potential for greatly extending the data base and providing
      valuable information on the tail of the underlying flood distribution. A
      procedure for assessing the value of paleoflood estimates of flood
      frequency analysis is given by Hosking and Wallis (1986). Only a little
      work on this topic has been carried out in Australia, but its potential
      has been indicated by its use to identify the five largest floods in the
      last 700 years in the Finke River Gorge in central Australia (Baker et
      al., 1983; Baker, 1984), and for more frequent floods, by identification
      of the six largest floods that occurred since a major flood in 1897 on
      the Katherine River in the Northern Territory (Baker, 1984). While the
      use of paleoflood data should be considered, it needs to be recognized
      that there are not many sites where paleofloods can be estimated and
      that climate changes may have affected the homogeneity of long-term
      flood data.</para>
    </section>

    <section>
      <title>Data Characterizing Climate Long-Term Persistence</title>

      <para>There is growing evidence that flood peaks are not identically
      distributed from year to year in some parts of Australia and that flood
      risk is dependent on long-term climate variability. The idea of
      alternating flood and drought dominated regimes that exist on decadal
      and longer timescales was first proposed by Warner and Erskine (1988).
      More recently, analyses of changes in climate state affecting flood risk
      have been published (see for example, Franks and Kuczera, 2002; Franks
      2002a,b). The climate-dependence of flood risk is an important
      consideration when assessing flood risk. Most flood frequency
      applications will require assessment of long-term flood risk; that is,
      flood risk that is independent of a particular current climate state. If
      a flood record is sufficiently long to sample all climate states
      affecting flood risk, a traditional analysis assuming homogeneity will
      yield the long-term flood risk. Unfortunately many flood records are
      relatively short and may be dominated by one climate state. Blind use of
      such data can result in substantial bias in long-term flood risk
      estimates. For this reason it may be necessary to obtain climate index
      data which characterizes long-term persistence in climate and to
      investigate the homogeneity of the flood distribution.</para>

      <para>A number of known climate phenomena impact on Australia climate
      variability. Most well known is the inter-annual El Nino/Southern
      Oscillation (ENSO). The cold ENSO phase, La Nina, results in a marked
      increase in flood risk across Eastern Australia, whereas El Nino years
      are typically without major floods (Kiem et al., 2003).</para>

      <para>There is also mounting evidence that longer-term climate processes
      also have a major impact on flood risk. The Interdecadal Pacific
      Oscillation (IPO) is a low frequency climate process related to the
      variable epochs of warming and cooling in the Pacific Ocean and is
      described by an index derived from low pass filtering of sea surface
      temperature (SST) anomalies in the Pacific Ocean [Power et al., 1998,
      1999; Allan, 2000]. The IPO is similar to the Pacific Decadal
      Oscillation (PDO) of Mantua et al. (1997), which is defined as the
      leading principal component of North Pacific monthly sea surface
      temperature variability.</para>

      <para>The IPO time series from 1880 is displayed in Figure 7. It reveals
      extended periods where the index either lies below or above zero. Power
      et al. (1999) have shown that the association between ENSO and
      Australian climate is modulated by the IPO - a strong association was
      found between the magnitude of ENSO impacts during negative IPO phases,
      whilst positive IPO phases showed a weaker, less predictable
      relationship. Additionally, Kiem et al. (2003) and Kiem and Franks
      (2004) analysed NSW flood and drought data and demonstrated that the IPO
      negative state magnified the impact of La Nina events. Moreover, they
      demonstrated that the IPO negative phase, related to mid-latitude
      Pacific Ocean cooling, appears to result in an increased frequency of
      cold La Nina events. The net effect of the dual modulation of ENSO by
      IPO is the occurrence of multi-decadal periods of elevated and reduced
      flood risk. To place this in context, Figure 8 shows regional flood
      index curves based on about 40 NSW sites for the different IPO states
      (Kiem et al., 2003) – the 1 in 100 AEP flood during years with a
      positive IPO index corresponds to the 1 in 6 AEP flood during years with
      a negative IPO index. Micevski et al. (2003) investigating a range of
      sites in NSW found that that floods occurring during IPO "negative"
      periods were, on average, about 1.8 times bigger than floods with the
      same frequency during IPO "positive" periods.</para>

      <para>A key area of current research is the spatial variability of ENSO
      and IPO impacts. The associations between ENSO, IPO and eastern
      Australian climate have been investigated from a mechanistic approach.
      Folland et al. (2002) showed that ENSO and IPO both affect the location
      of the South Pacific Convergence Zone (SPCZ) providing a mechanistic
      justification for the role of La Nina and IPO negative periods in
      enhancing flood risk in eastern Australia.</para>

      <para>Whilst the work to date has primarily focused on eastern
      Australia, a substantial step change in climate also occurred in Western
      Australia around the mid-1970’s, in line with the IPO and PDO indices
      (Franks, 2002b), however the role of ENSO is less clear and is likely to
      be additionally complicated by the role of the Indian Ocean.</para>

      <para>The finding that flood risk in parts of Australia is modulated by
      low frequency climate variability is recent. Users are reminded that
      this is an area of active research and therefore should keep abreast of
      future developments.</para>

      <figure>
        <title>Annual average IPO time series.</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\Figure7.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <figure>
        <title>NSW regional flood index frequency curves for positive and
        negative IPO epochs [Kiem et al., 2003.</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\Figure8.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>
    </section>

    <section>
      <title>Regional Flood Information</title>

      <para>Whereas the primary focus of this chapter is flood frequency
      analysis using at-site information, the accuracy of the frequency
      analysis can be improved, substantially in some cases, by augmenting
      at-site information with regional information. Subsequent chapters in
      this Book describe methods for estimating flood frequency at ungauged
      sites. Provided such methods also provide estimates of uncertainty, the
      regional information can be pooled with the at-site information to yield
      more accurate results. Section 6.3.5 shows how regional information on
      flood probability model parameters can pooled with at-site information.
      When pooling at-site and regional information it is important to
      establish that both sources of information are consistent – that is,
      they yield statistically consistent results.</para>
    </section>

    <section>
      <title>Missing Records</title>

      <para>Streamflow data frequently contain gaps for a variety of reasons
      including the malfunction of recording equipment. Rainfall records on
      the catchment and streamflow data from nearby catchments may indicate
      the likelihood of a large flood having occurred during the gap. A
      regression may be able to be derived to enable a missing flood to be
      estimated, but as discussed in Section 3.6.1, the degree correlation is
      often insufficient for a quantitative estimate.</para>

      <para>For AM series the missing record period is of no consequence and
      can be included in the period of record, if it can be determined that
      the largest flow for the year occurred outside the gap, or that no large
      rains occurred during the gap. However the rainfall records and
      streamflow on nearby catchments might indicate that a large flood could
      have occurred during the period of missing record. If a regression with
      good correlation can be derived from concurrent records, the missing
      flood can be estimated and used as the annual flood for the year. If the
      flood cannot be estimated with reasonable certainty, the whole year
      should be excluded from the analysis.</para>

      <para>For POT series data, treatment of missing records is less clear.
      McDermott and Pilgrim (1982) tested seven methods, leading to the
      following recommendations based on the assumption that the periods of
      missing data are random occurrences and are independent of the
      occurrence of flood peaks.</para>

      <orderedlist>
        <listitem>
          <para>Where a nearby station record exists covering the missing
          record period, and a good relation between the flood peaks on the
          two catchments can be obtained, then use this relation and the
          nearby station record to fill in the missing events of
          interest.</para>
        </listitem>

        <listitem>
          <para>Where a nearby station record exists covering the missing
          record period, and the relation between the flood peaks on the two
          catchments is such that only the occurrence of an event can be
          predicted but not its magnitude, then:</para>

          <itemizedlist>
            <listitem>
              <para>for record lengths less than 20 years, ignore the missing
              data and include the missing period in the overall period of
              record;</para>
            </listitem>

            <listitem>
              <para>for record lengths greater than 20 years, subtract an
              amount from each year with missing data proportional to the
              ratio of the number of peaks missed to the total number of
              ranked peaks in the year.</para>
            </listitem>
          </itemizedlist>
        </listitem>

        <listitem>
          <para>Where no nearby station record exists covering the missing
          record period, or where no relation between flood peaks on the
          catchment exists, then ignore the missing data and include the
          missing record period in the overall period of record.</para>
        </listitem>
      </orderedlist>
    </section>
  </section>

  <section>
    <title>CHOICE OF FLOOD PROBABILITY MODEL</title>

    <section>
      <title>General</title>

      <para>As noted in Section 2, it is assumed that each flood peak in an AM
      or POT series is statistically independent of other flood peaks in the
      series. In addition the flood probability model, described by its
      probability density function (pdf) p(q|θ(x)), must be specified.</para>

      <para>There is no universally accepted flood probability model. Many
      types of probability distributions have been applied to flood frequency
      analysis. Unfortunately, it is not possible to determine the true or
      correct form of distribution (see, for example, Cunnane, 1985), and
      there is no rigorous analytical proof that any particular probability
      distribution for floods is the correct theoretical distribution. The
      appropriateness of these distributions can be tested by examining the
      fit of each distribution to observed flood data. Various empirical tests
      of different distributions have been carried out with recorded data from
      many catchments but conclusive evidence is not possible largely because
      gauged records are of insufficient length to eliminate the confounding
      effect of sampling variability. Examples of sampling experiments
      illustrating this problem are given by Alexander (1957) and Benson in
      Dalrymple (1960). The choice of flood probability model is further
      exacerbated by recent evidence that in certain parts of Australia the
      flood record is not homogeneous due to variations in long-term climate
      controls.</para>

      <para>Given these considerations it is considered inappropriate to be
      prescriptive with regard to choice of flood probability model. As a
      general rule the selected probability distribution family M should be
      consistent with available data. It is recognized that more than one
      probability distribution family may be consistent with the data. One
      approach to deal with this problem is to select the distribution family
      on the basis of best overall fit to a range of catchments within a
      region or landscape space – L moment diagrams offer a useful tool for
      judging overall goodness of fit [see Stedinger et al., 1993, Section
      18.3.3 for more details].</para>
    </section>

    <section>
      <title>Choice of Distribution Family for Annual Maximum Series</title>

      <para>Two distribution families are suggested as reasonable initial
      choices for AM series, namely the generalized extreme value (GEV) and
      log Pearson III (LP3) families. These families have been shown to fit
      most AM flood data adequately. Nonetheless the user is reminded that
      there is no rigorous justification for these families, which is
      particularly important when extrapolating – Example 1 demonstrates the
      importance of understanding the mechanisms controlling flood response.
      The following sections describe the GEV and LP3 distributions and also
      some other distributions which may be more appropriate in certain
      circumstances.</para>

      <section>
        <title>Generalized Extreme Value (GEV) distribution</title>

        <para>Table 1 lists the pdf p(q|θ), distribution function P(Q≤q|θ) and
        product moments for the generalized extreme value (GEV) distribution.
        It has three parameters: τ, the location parameter, α, the scale
        parameter and κ, the shape parameter. When the shape parameter κ
        equals 0, the GEV simplifies to the Gumbel distribution whose details
        are also presented in Table 1. For positive values of κ there exists
        an upper bound, while for negative κ there exists a lower
        bound.</para>

        <table>
          <title>Table 1. Selected homogeneous probability models families for
          use in flood frequency analysis</title>

          <tgroup cols="3">
            <colspec colwidth="27*"/>

            <colspec align="center" colwidth="41*"/>

            <colspec colwidth="32*"/>

            <thead>
              <row>
                <entry align="center">Family</entry>

                <entry align="center">Distribution</entry>

                <entry align="center">Moments</entry>
              </row>
            </thead>

            <tbody>
              <row>
                <entry>Generalized extreme value (GEV)</entry>

                <entry><inlineequation>
                    <m:math display="inline">
                      <m:mrow>
                        <m:mtable>
                          <m:mtr>
                            <m:mtd>
                              <m:mrow>
                                <m:mi>p(q || θ)</m:mi>

                                <m:mo>=</m:mo>

                                <m:mrow>
                                  <m:mfrac>
                                    <m:mi>1</m:mi>

                                    <m:mi>α</m:mi>
                                  </m:mfrac>

                                  <m:mo>exp</m:mo>

                                  <m:mrow>
                                    <m:mo>{</m:mo>

                                    <m:mrow>
                                      <m:mi>-</m:mi>

                                      <m:mrow>
                                        <m:mo>[</m:mo>

                                        <m:mrow>
                                          <m:mi>1</m:mi>

                                          <m:mo>-</m:mo>

                                          <m:mfrac>
                                            <m:mrow>
                                              <m:mi>κ</m:mi>

                                              <m:mrow>
                                                <m:mo>(</m:mo>

                                                <m:mrow>
                                                  <m:mi>q</m:mi>

                                                  <m:mo>-</m:mo>

                                                  <m:mi>τ</m:mi>
                                                </m:mrow>

                                                <m:mo>)</m:mo>
                                              </m:mrow>
                                            </m:mrow>

                                            <m:mi>α</m:mi>
                                          </m:mfrac>
                                        </m:mrow>

                                        <m:mo>]</m:mo>
                                      </m:mrow>
                                    </m:mrow>

                                    <m:msup>
                                      <m:mi>}</m:mi>

                                      <m:mfrac>
                                        <m:mi>1</m:mi>

                                        <m:mi>κ</m:mi>
                                      </m:mfrac>
                                    </m:msup>
                                  </m:mrow>

                                  <m:mrow>
                                    <m:mo>[</m:mo>

                                    <m:mrow>
                                      <m:mi>1</m:mi>

                                      <m:mo>-</m:mo>

                                      <m:mfrac>
                                        <m:mrow>
                                          <m:mi>κ</m:mi>

                                          <m:mrow>
                                            <m:mo>(</m:mo>

                                            <m:mrow>
                                              <m:mi>q</m:mi>

                                              <m:mo>-</m:mo>

                                              <m:mi>τ</m:mi>
                                            </m:mrow>

                                            <m:mo>)</m:mo>
                                          </m:mrow>
                                        </m:mrow>

                                        <m:mi>α</m:mi>
                                      </m:mfrac>
                                    </m:mrow>
                                  </m:mrow>

                                  <m:msup>
                                    <m:mi>]</m:mi>

                                    <m:mrow>
                                      <m:mfrac>
                                        <m:mi>1</m:mi>

                                        <m:mi>κ</m:mi>
                                      </m:mfrac>

                                      <m:mo>-1</m:mo>
                                    </m:mrow>
                                  </m:msup>
                                </m:mrow>
                              </m:mrow>
                            </m:mtd>
                          </m:mtr>

                          <m:mtr>
                            <m:mtd>
                              <m:mrow>
                                <m:mi>P(Q≤q|θ)</m:mi>

                                <m:mo>=</m:mo>

                                <m:mrow>
                                  <m:mi>exp</m:mi>

                                  <m:mrow>
                                    <m:mo>{</m:mo>

                                    <m:mrow>
                                      <m:mi>-</m:mi>

                                      <m:mrow>
                                        <m:mo>[</m:mo>

                                        <m:mi>1-</m:mi>
                                      </m:mrow>
                                    </m:mrow>

                                    <m:mrow>
                                      <m:mfrac>
                                        <m:mrow>
                                          <m:mi>κ</m:mi>

                                          <m:mrow>
                                            <m:mi>(q</m:mi>

                                            <m:mo>-</m:mo>

                                            <m:mi>τ)</m:mi>
                                          </m:mrow>
                                        </m:mrow>

                                        <m:mi>α</m:mi>
                                      </m:mfrac>

                                      <m:mrow>
                                        <m:msup>
                                          <m:mi>]</m:mi>

                                          <m:mfrac>
                                            <m:mi>1</m:mi>

                                            <m:mi>κ</m:mi>
                                          </m:mfrac>
                                        </m:msup>

                                        <m:mo>}</m:mo>
                                      </m:mrow>
                                    </m:mrow>
                                  </m:mrow>
                                </m:mrow>
                              </m:mrow>
                            </m:mtd>
                          </m:mtr>

                          <m:mtr>
                            <m:mtd>
                              <m:mrow>
                                <m:mi>when κ&gt;0, q&lt;τ+</m:mi>

                                <m:mrow>
                                  <m:mfrac>
                                    <m:mi>α</m:mi>

                                    <m:mi>κ</m:mi>
                                  </m:mfrac>

                                  <m:mo>; when κ&lt;0, q&gt;τ+</m:mo>

                                  <m:mfrac>
                                    <m:mi>α</m:mi>

                                    <m:mi>κ</m:mi>
                                  </m:mfrac>
                                </m:mrow>
                              </m:mrow>
                            </m:mtd>
                          </m:mtr>
                        </m:mtable>
                      </m:mrow>
                    </m:math>
                  </inlineequation></entry>

                <entry><inlineequation>
                    <m:math display="inline">
                      <m:mtable>
                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mtable>
                                <m:mtr>
                                  <m:mtd>
                                    <m:mrow>
                                      <m:mi>Mean (q)=</m:mi>

                                      <m:mo>τ+</m:mo>

                                      <m:mrow>
                                        <m:mfrac>
                                          <m:mi>α</m:mi>

                                          <m:mi>κ</m:mi>
                                        </m:mfrac>

                                        <m:mi>[ 1-Γ(1+κ)]</m:mi>
                                      </m:mrow>
                                    </m:mrow>
                                  </m:mtd>
                                </m:mtr>

                                <m:mtr>
                                  <m:mtd>
                                    <m:mrow>
                                      <m:mrow>
                                        <m:mi>for κ&gt;-1</m:mi>
                                      </m:mrow>
                                    </m:mrow>
                                  </m:mtd>
                                </m:mtr>
                              </m:mtable>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>

                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mrow>
                                <m:mi>Variance (q)=</m:mi>

                                <m:mfrac>
                                  <m:msup>
                                    <m:mi>α</m:mi>

                                    <m:mi>2</m:mi>
                                  </m:msup>

                                  <m:msup>
                                    <m:mi>κ</m:mi>

                                    <m:mi>2</m:mi>
                                  </m:msup>
                                </m:mfrac>

                                <m:mi>[ Γ(1+2κ)-[Γ(1+κ)</m:mi>

                                <m:msup>
                                  <m:mi>]</m:mi>

                                  <m:mi>2</m:mi>
                                </m:msup>

                                <m:mi>]</m:mi>
                              </m:mrow>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>

                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mtable>
                                <m:mtr>
                                  <m:mtd>
                                    <m:mrow>
                                      <m:mrow>
                                        <m:mi>for</m:mi>

                                        <m:mo>κ &gt;-</m:mo>

                                        <m:mfrac>
                                          <m:mi>1</m:mi>

                                          <m:mi>2</m:mi>
                                        </m:mfrac>
                                      </m:mrow>
                                    </m:mrow>
                                  </m:mtd>
                                </m:mtr>

                                <m:mtr>
                                  <m:mtd>
                                    <m:mrow>
                                      <m:mrow>
                                        <m:mi>where Γ() is the gamma function</m:mi>
                                      </m:mrow>
                                    </m:mrow>
                                  </m:mtd>
                                </m:mtr>
                              </m:mtable>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>
                      </m:mtable>
                    </m:math>
                  </inlineequation></entry>
              </row>

              <row>
                <entry>Gumbel</entry>

                <entry><inlineequation>
                    <m:math display="inline">
                      <m:mtable>
                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mi>p(q∣θ)</m:mi>

                              <m:mo>=</m:mo>

                              <m:mrow>
                                <m:mfrac>
                                  <m:mi>1</m:mi>

                                  <m:mi>α</m:mi>
                                </m:mfrac>

                                <m:mo>exp[-</m:mo>

                                <m:mfrac>
                                  <m:mrow>
                                    <m:mi>(q</m:mi>

                                    <m:mo>-</m:mo>

                                    <m:mi>τ)</m:mi>
                                  </m:mrow>

                                  <m:mi>α</m:mi>
                                </m:mfrac>

                                <m:mo>]</m:mo>

                                <m:mi>exp{-exp[-</m:mi>

                                <m:mfrac>
                                  <m:mrow>
                                    <m:mi>(q</m:mi>

                                    <m:mo>-</m:mo>

                                    <m:mi>τ)</m:mi>
                                  </m:mrow>

                                  <m:mi>α</m:mi>
                                </m:mfrac>

                                <m:mi>]}</m:mi>
                              </m:mrow>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>

                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mi>P(Q≤q∣θ)</m:mi>

                              <m:mo>=</m:mo>

                              <m:mrow>
                                <m:mi>exp{-exp[-</m:mi>

                                <m:mfrac>
                                  <m:mrow>
                                    <m:mi>(q</m:mi>

                                    <m:mo>-</m:mo>

                                    <m:mi>τ)</m:mi>
                                  </m:mrow>

                                  <m:mi>α</m:mi>
                                </m:mfrac>

                                <m:mi>]}</m:mi>
                              </m:mrow>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>
                      </m:mtable>
                    </m:math>
                  </inlineequation></entry>

                <entry><inlineequation>
                    <m:math display="inline">
                      <m:mtable>
                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mi>Mean (q)</m:mi>

                              <m:mo>=</m:mo>

                              <m:mi>τ+0.5772α</m:mi>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>

                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mi>Variance(q)</m:mi>

                              <m:mo>=</m:mo>

                              <m:mfrac>
                                <m:mrow>
                                  <m:msup>
                                    <m:mi>Π</m:mi>

                                    <m:mi>2</m:mi>
                                  </m:msup>

                                  <m:msup>
                                    <m:mi>α</m:mi>

                                    <m:mi>2</m:mi>
                                  </m:msup>
                                </m:mrow>

                                <m:mi>6</m:mi>
                              </m:mfrac>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>

                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mi>Skew(q)</m:mi>

                              <m:mo>=</m:mo>

                              <m:mi>1.1396</m:mi>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>
                      </m:mtable>
                    </m:math>
                  </inlineequation></entry>
              </row>

              <row>
                <entry>Log-Pearson III (LP3)</entry>

                <entry><inlineequation>
                    <m:math display="inline">
                      <m:mtable>
                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mi>p(q|θ)</m:mi>

                              <m:mo>=</m:mo>

                              <m:mrow>
                                <m:mfrac>
                                  <m:mi>|β|</m:mi>

                                  <m:mi>qΓ(α)</m:mi>
                                </m:mfrac>

                                <m:mo>[β(</m:mo>

                                <m:msub>
                                  <m:mi>log</m:mi>

                                  <m:mi>e</m:mi>
                                </m:msub>

                                <m:mrow>
                                  <m:mi>q-τ)</m:mi>

                                  <m:msup>
                                    <m:mi>]</m:mi>

                                    <m:mi>α-1</m:mi>
                                  </m:msup>

                                  <m:mi>exp</m:mi>

                                  <m:mo>[-β(</m:mo>

                                  <m:msub>
                                    <m:mi>log</m:mi>

                                    <m:mi>e</m:mi>
                                  </m:msub>

                                  <m:mi>q-τ)]</m:mi>
                                </m:mrow>
                              </m:mrow>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>

                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mi>α &gt;0</m:mi>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>

                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mi>when β&gt;0,</m:mi>

                              <m:msub>
                                <m:mi>log</m:mi>

                                <m:mi>e</m:mi>
                              </m:msub>

                              <m:mrow>
                                <m:mi>q&gt;τ; when β&lt;0,</m:mi>

                                <m:msub>
                                  <m:mi>log</m:mi>

                                  <m:mi>e</m:mi>
                                </m:msub>

                                <m:mi>q&lt;τ</m:mi>
                              </m:mrow>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>
                      </m:mtable>
                    </m:math>
                  </inlineequation></entry>

                <entry><inlineequation>
                    <m:math display="inline">
                      <m:mtable>
                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mrow>
                                <m:mi>Mean (</m:mi>

                                <m:msub>
                                  <m:mi>log</m:mi>

                                  <m:mi>e</m:mi>
                                </m:msub>

                                <m:mi>q)</m:mi>
                              </m:mrow>

                              <m:mo>=</m:mo>

                              <m:mrow>
                                <m:mi>m</m:mi>

                                <m:mo>=</m:mo>

                                <m:mrow>
                                  <m:mi>τ</m:mi>

                                  <m:mo>+</m:mo>

                                  <m:mfrac>
                                    <m:mi>α</m:mi>

                                    <m:mi>β</m:mi>
                                  </m:mfrac>
                                </m:mrow>
                              </m:mrow>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>

                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mrow>
                                <m:mi>Variance (</m:mi>

                                <m:msub>
                                  <m:mi>log</m:mi>

                                  <m:mi>e</m:mi>
                                </m:msub>

                                <m:mi>q)</m:mi>
                              </m:mrow>

                              <m:mo>=</m:mo>

                              <m:mrow>
                                <m:msup>
                                  <m:mi>s</m:mi>

                                  <m:mi>2</m:mi>
                                </m:msup>

                                <m:mo>=</m:mo>

                                <m:mfrac>
                                  <m:mi>α</m:mi>

                                  <m:msup>
                                    <m:mi>β</m:mi>

                                    <m:mi>2</m:mi>
                                  </m:msup>
                                </m:mfrac>
                              </m:mrow>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>

                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mrow>
                                <m:mi>Skew(</m:mi>

                                <m:msub>
                                  <m:mi>log</m:mi>

                                  <m:mi>e</m:mi>
                                </m:msub>

                                <m:mi>q)</m:mi>
                              </m:mrow>

                              <m:mo>=</m:mo>

                              <m:mrow>
                                <m:mi>g</m:mi>

                                <m:mo>=</m:mo>

                                <m:mrow>
                                  <m:mo>(</m:mo>

                                  <m:mtable>
                                    <m:mtr>
                                      <m:mtd>
                                        <m:mrow>
                                          <m:mfrac>
                                            <m:mi>2</m:mi>

                                            <m:msqrt>
                                              <m:mi>α</m:mi>
                                            </m:msqrt>
                                          </m:mfrac>

                                          <m:mo>if β&gt;0</m:mo>
                                        </m:mrow>
                                      </m:mtd>
                                    </m:mtr>

                                    <m:mtr>
                                      <m:mtd>
                                        <m:mrow>
                                          <m:mrow>
                                            <m:mi>-</m:mi>

                                            <m:mfrac>
                                              <m:mi>2</m:mi>

                                              <m:msqrt>
                                                <m:mi>α</m:mi>
                                              </m:msqrt>
                                            </m:mfrac>
                                          </m:mrow>

                                          <m:mo>if β&lt;0</m:mo>
                                        </m:mrow>
                                      </m:mtd>
                                    </m:mtr>
                                  </m:mtable>

                                  <m:mo>)</m:mo>
                                </m:mrow>
                              </m:mrow>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>
                      </m:mtable>
                    </m:math>
                  </inlineequation></entry>
              </row>

              <row>
                <entry>Log-normal</entry>

                <entry><inlineequation>
                    <m:math display="inline">
                      <m:mrow>
                        <m:mtable>
                          <m:mtr>
                            <m:mtd>
                              <m:mrow>
                                <m:mi>p(q|θ)</m:mi>

                                <m:mo>=</m:mo>

                                <m:mrow>
                                  <m:mfrac>
                                    <m:mi>1</m:mi>

                                    <m:mrow>
                                      <m:mi>q</m:mi>

                                      <m:msqrt>
                                        <m:mrow>
                                          <m:mi>2</m:mi>

                                          <m:mo>∏</m:mo>

                                          <m:msup>
                                            <m:mi>s</m:mi>

                                            <m:mi>2</m:mi>
                                          </m:msup>
                                        </m:mrow>
                                      </m:msqrt>
                                    </m:mrow>
                                  </m:mfrac>

                                  <m:mo>exp</m:mo>

                                  <m:mrow>
                                    <m:mo>[</m:mo>

                                    <m:mrow>
                                      <m:mi>-</m:mi>

                                      <m:mfrac>
                                        <m:mi>1</m:mi>

                                        <m:msup>
                                          <m:mi>2s</m:mi>

                                          <m:mi>i</m:mi>
                                        </m:msup>
                                      </m:mfrac>

                                      <m:mrow>
                                        <m:mo>(</m:mo>

                                        <m:mrow>
                                          <m:msub>
                                            <m:mi>log</m:mi>

                                            <m:mi>e</m:mi>
                                          </m:msub>

                                          <m:mo>q -</m:mo>

                                          <m:mi>m</m:mi>
                                        </m:mrow>
                                      </m:mrow>

                                      <m:msup>
                                        <m:mi>)</m:mi>

                                        <m:mi>2</m:mi>
                                      </m:msup>
                                    </m:mrow>

                                    <m:mo>]</m:mo>
                                  </m:mrow>
                                </m:mrow>
                              </m:mrow>
                            </m:mtd>
                          </m:mtr>

                          <m:mtr>
                            <m:mtd>
                              <m:mrow>
                                <m:mi>q&gt;0, s&gt;0</m:mi>
                              </m:mrow>
                            </m:mtd>
                          </m:mtr>
                        </m:mtable>
                      </m:mrow>
                    </m:math>
                  </inlineequation></entry>

                <entry><inlineequation>
                    <m:math display="inline">
                      <m:mtable>
                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mrow>
                                <m:mo>Mean</m:mo>

                                <m:msub>
                                  <m:mi>(log</m:mi>

                                  <m:mi>e</m:mi>
                                </m:msub>

                                <m:mo>q)</m:mo>
                              </m:mrow>

                              <m:mo>= m</m:mo>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>

                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mrow>
                                <m:mi>Variance</m:mi>

                                <m:msub>
                                  <m:mi>(log</m:mi>

                                  <m:mi>e</m:mi>
                                </m:msub>

                                <m:mi>q )</m:mi>
                              </m:mrow>

                              <m:mo>=</m:mo>

                              <m:msup>
                                <m:mi>s</m:mi>

                                <m:mi>2</m:mi>
                              </m:msup>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>
                      </m:mtable>
                    </m:math>
                  </inlineequation></entry>
              </row>

              <row>
                <entry>Generalized Pareto</entry>

                <entry><inlineequation>
                    <m:math display="inline">
                      <m:mtable>
                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mrow>
                                <m:mi>p(q|</m:mi>

                                <m:mrow>
                                  <m:mi>θ)</m:mi>

                                  <m:mo>=</m:mo>

                                  <m:mfrac>
                                    <m:mi>1</m:mi>

                                    <m:mi>β</m:mi>
                                  </m:mfrac>
                                </m:mrow>

                                <m:mrow>
                                  <m:mo>(</m:mo>

                                  <m:mrow>
                                    <m:mi>1</m:mi>

                                    <m:mo>-</m:mo>

                                    <m:mfrac>
                                      <m:mrow>
                                        <m:mo>κ (</m:mo>

                                        <m:mrow>
                                          <m:mi>q</m:mi>

                                          <m:mo>-</m:mo>

                                          <m:msub>
                                            <m:mi>q</m:mi>

                                            <m:mi>*</m:mi>
                                          </m:msub>
                                        </m:mrow>

                                        <m:mo>)</m:mo>
                                      </m:mrow>

                                      <m:mi>β</m:mi>
                                    </m:mfrac>
                                  </m:mrow>

                                  <m:msup>
                                    <m:mi>)</m:mi>

                                    <m:mrow>
                                      <m:mfrac>
                                        <m:mi>1</m:mi>

                                        <m:mi>κ</m:mi>
                                      </m:mfrac>

                                      <m:mo>-1</m:mo>
                                    </m:mrow>
                                  </m:msup>
                                </m:mrow>
                              </m:mrow>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>

                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mtable>
                                <m:mtr>
                                  <m:mtd>
                                    <m:mrow>
                                      <m:mrow>
                                        <m:mi>P(Q≤</m:mi>

                                        <m:mrow>
                                          <m:mi>q|θ)</m:mi>

                                          <m:mo>=</m:mo>
                                        </m:mrow>

                                        <m:mi>1 -</m:mi>

                                        <m:mrow>
                                          <m:mo>(</m:mo>

                                          <m:mrow>
                                            <m:mi>1 -</m:mi>

                                            <m:mfrac>
                                              <m:mrow>
                                                <m:mo>κ (</m:mo>

                                                <m:mrow>
                                                  <m:mi>q</m:mi>

                                                  <m:mo>-</m:mo>

                                                  <m:msub>
                                                    <m:mi>q</m:mi>

                                                    <m:mi>*</m:mi>
                                                  </m:msub>
                                                </m:mrow>

                                                <m:mo>)</m:mo>
                                              </m:mrow>

                                              <m:mi>β</m:mi>
                                            </m:mfrac>
                                          </m:mrow>
                                        </m:mrow>

                                        <m:msup>
                                          <m:mi>)</m:mi>

                                          <m:mfrac>
                                            <m:mi>1</m:mi>

                                            <m:mi>κ</m:mi>
                                          </m:mfrac>
                                        </m:msup>
                                      </m:mrow>
                                    </m:mrow>
                                  </m:mtd>
                                </m:mtr>

                                <m:mtr>
                                  <m:mtd>
                                    <m:mrow>
                                      <m:mi>when κ&lt;0,</m:mi>

                                      <m:msub>
                                        <m:mi>q</m:mi>

                                        <m:mi>*</m:mi>
                                      </m:msub>

                                      <m:mi>≤q&lt;∞; when κ&gt;0,</m:mi>

                                      <m:mrow>
                                        <m:msub>
                                          <m:mi>q</m:mi>

                                          <m:mi>*</m:mi>
                                        </m:msub>

                                        <m:mo>≤q ≤</m:mo>
                                      </m:mrow>

                                      <m:mfrac>
                                        <m:mi>β</m:mi>

                                        <m:mi>κ</m:mi>
                                      </m:mfrac>
                                    </m:mrow>
                                  </m:mtd>
                                </m:mtr>
                              </m:mtable>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>
                      </m:mtable>
                    </m:math>
                  </inlineequation></entry>

                <entry><inlineequation>
                    <m:math display="inline">
                      <m:mtable>
                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mrow>
                                <m:mi>Mean (q)</m:mi>

                                <m:mo>=</m:mo>

                                <m:msub>
                                  <m:mi>q</m:mi>

                                  <m:mi>*</m:mi>
                                </m:msub>
                              </m:mrow>

                              <m:mrow>
                                <m:mo>+</m:mo>

                                <m:mfrac>
                                  <m:mi>β</m:mi>

                                  <m:mrow>
                                    <m:mi>1</m:mi>

                                    <m:mo>+</m:mo>

                                    <m:mi>κ</m:mi>
                                  </m:mrow>
                                </m:mfrac>
                              </m:mrow>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>

                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mtable>
                                <m:mtr>
                                  <m:mtd>
                                    <m:mrow>
                                      <m:mi>Variance (q)</m:mi>

                                      <m:mo>=</m:mo>

                                      <m:mfrac>
                                        <m:msup>
                                          <m:mi>β</m:mi>

                                          <m:mi>2</m:mi>
                                        </m:msup>

                                        <m:mrow>
                                          <m:mrow>
                                            <m:mrow>
                                              <m:mo>(</m:mo>

                                              <m:mrow>
                                                <m:mi>1</m:mi>

                                                <m:mo>+ κ</m:mo>
                                              </m:mrow>
                                            </m:mrow>

                                            <m:msup>
                                              <m:mi>)</m:mi>

                                              <m:mi>2</m:mi>
                                            </m:msup>
                                          </m:mrow>

                                          <m:mrow>
                                            <m:mo>(</m:mo>

                                            <m:mrow>
                                              <m:mo>1 + 2κ</m:mo>
                                            </m:mrow>

                                            <m:mo>)</m:mo>
                                          </m:mrow>
                                        </m:mrow>
                                      </m:mfrac>
                                    </m:mrow>
                                  </m:mtd>
                                </m:mtr>

                                <m:mtr>
                                  <m:mtd>
                                    <m:mrow>
                                      <m:mi>Skew (q)</m:mi>

                                      <m:mo>=</m:mo>

                                      <m:mrow>
                                        <m:mfrac>
                                          <m:mrow>
                                            <m:mi>2</m:mi>

                                            <m:mrow>
                                              <m:mo>(1</m:mo>

                                              <m:mrow>
                                                <m:mo>-</m:mo>

                                                <m:mi>κ</m:mi>
                                              </m:mrow>

                                              <m:mo>)</m:mo>
                                            </m:mrow>

                                            <m:mrow>
                                              <m:mo>(</m:mo>

                                              <m:mrow>
                                                <m:mi>1</m:mi>

                                                <m:mo>+</m:mo>

                                                <m:mi>2</m:mi>
                                              </m:mrow>

                                              <m:mo>κ</m:mo>
                                            </m:mrow>

                                            <m:msup>
                                              <m:mi>)</m:mi>

                                              <m:mfrac>
                                                <m:mi>1</m:mi>

                                                <m:mi>2</m:mi>
                                              </m:mfrac>
                                            </m:msup>
                                          </m:mrow>

                                          <m:mrow>
                                            <m:mo>(</m:mo>

                                            <m:mrow>
                                              <m:mi>1</m:mi>

                                              <m:mo>+</m:mo>

                                              <m:mi>3κ</m:mi>
                                            </m:mrow>

                                            <m:mo>)</m:mo>
                                          </m:mrow>
                                        </m:mfrac>

                                        <m:mo>κ &gt; - 1/3</m:mo>
                                      </m:mrow>
                                    </m:mrow>
                                  </m:mtd>
                                </m:mtr>
                              </m:mtable>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>
                      </m:mtable>
                    </m:math>
                  </inlineequation></entry>
              </row>

              <row>
                <entry>Exponential</entry>

                <entry><inlineequation>
                    <m:math display="inline">
                      <m:mtable>
                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mrow>
                                <m:mi>p(q|θ)</m:mi>

                                <m:mo>=</m:mo>

                                <m:mfrac>
                                  <m:mi>1</m:mi>

                                  <m:mi>β</m:mi>
                                </m:mfrac>
                              </m:mrow>

                              <m:mo>exp</m:mo>

                              <m:mrow>
                                <m:mo>(</m:mo>

                                <m:mrow>
                                  <m:mi>-</m:mi>

                                  <m:mfrac>
                                    <m:mrow>
                                      <m:mi>q</m:mi>

                                      <m:mo>-</m:mo>

                                      <m:msub>
                                        <m:mi>q</m:mi>

                                        <m:mi>*</m:mi>
                                      </m:msub>
                                    </m:mrow>

                                    <m:mi>β</m:mi>
                                  </m:mfrac>
                                </m:mrow>

                                <m:mo>)</m:mo>
                              </m:mrow>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>

                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mrow>
                                <m:mi>P(Q≤ q|θ)</m:mi>

                                <m:mo>=</m:mo>

                                <m:mi>1- exp</m:mi>
                              </m:mrow>

                              <m:mrow>
                                <m:mrow>
                                  <m:mo>(</m:mo>

                                  <m:mrow>
                                    <m:mi>-</m:mi>

                                    <m:mfrac>
                                      <m:mrow>
                                        <m:mi>q</m:mi>

                                        <m:mo>-</m:mo>

                                        <m:msub>
                                          <m:mi>q</m:mi>

                                          <m:mi>*</m:mi>
                                        </m:msub>
                                      </m:mrow>

                                      <m:mi>β</m:mi>
                                    </m:mfrac>
                                  </m:mrow>

                                  <m:mo>)</m:mo>
                                </m:mrow>

                                <m:mo>, q ≥</m:mo>
                              </m:mrow>

                              <m:msub>
                                <m:mi>q</m:mi>

                                <m:mi>*</m:mi>
                              </m:msub>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>
                      </m:mtable>
                    </m:math>
                  </inlineequation></entry>

                <entry><inlineequation>
                    <m:math display="inline">
                      <m:mtable>
                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mi>Mean (q)</m:mi>

                              <m:mo>=</m:mo>

                              <m:mrow>
                                <m:msub>
                                  <m:mi>q</m:mi>

                                  <m:mi>*</m:mi>
                                </m:msub>

                                <m:mo>+</m:mo>

                                <m:mi>β</m:mi>
                              </m:mrow>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>

                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mi>Variance (q)</m:mi>

                              <m:mo>=</m:mo>

                              <m:msup>
                                <m:mi>β</m:mi>

                                <m:mi>2</m:mi>
                              </m:msup>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>

                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:mi>Skew (q)</m:mi>

                              <m:mo>=</m:mo>

                              <m:mi>2</m:mi>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>
                      </m:mtable>
                    </m:math>
                  </inlineequation></entry>
              </row>
            </tbody>
          </tgroup>
        </table>

        <para>Of the widely used distribution families, the GEV distribution
        has the strongest theoretical appeal because it is the asymptotic
        distribution of extreme values for a wide range of underlying parent
        distributions. In the flood frequency context, suppose there are N
        flood peaks in a year. Provided N is large and the flood peaks are
        identically and independently distributed, the distribution of the
        largest peak flow in the year approaches the GEV under quite general
        conditions. However, it is questionable whether these assumptions are
        satisfied in practice.</para>

        <para>The number of independent flood peaks in any year may not be
        sufficient to ensure asymptotic behaviour particularly for catchments
        that tend to aridity. Moreover, in strongly seasonal climates, it is
        unlikely the within-year independent flood peaks are random
        realizations from the same probability distribution.</para>

        <para>The GEV has gained widespread acceptance (for example, Natural
        Environment Research Council, 1975; Wallis and Wood, 1985; Handbook of
        Hydrology, Stedinger et al., 1993).</para>
      </section>

      <section>
        <title>Log Pearson III (LP3) distribution</title>

        <para>Table 1 lists the pdf p(q|θ) and product moments for log Pearson
        III (LP3) distribution. It has three parameters: τ, the location
        parameter,α, the scale parameter and β, the shape parameter. When the
        skew of log q is zero, the distribution simplifies to the log normal
        whose details are provided in Table 1.</para>

        <para>The LP3 distribution has been widely accepted in practice
        because it consistently fits flood data as well if not better than
        other probability families. It has performed best of those that have
        been tested on data for Australian catchments (Conway 1970; Kopittke
        et al., 1976; McMahon, 1979, McMahon and Srikanthan, 1981). It is the
        recommended distribution for the United States in Bulletin 17B of the
        Interagency Advisory Committee on Water Data (1982).</para>

        <para>The distribution, however, is not well-behaved from an inference
        perspective. Direct inference of the parameters α, β and τ can cause
        numerical problems. For example, when the skew of log q is close to
        zero, the shape parameter α tends to infinity. Experience indicates it
        is preferable to fit the first three moments of log q rather than α, β
        and τ. Note that τ is a lower bound for positive skew and an upper
        bound for negative skew.</para>

        <para>A problem arises when the absolute value of the skew of log q
        exceeds 2; that is, when α ≥ 1. When α &lt; 1, the LP3 has a
        gamma-shaped density. However, when α ≥ 1, the density changes to a
        J-shaped function. Indeed when α = 1, the pdf degenerates to that of
        an exponential distribution with scale parameter β and location
        parameter τ. For α ≥ 1, the J-shaped density seems to be
        over-parameterized with three parameters. In such circumstances, it is
        pointless to use the LP3. It is suggested either the GEV or the
        generalized Pareto distributions be used as a substitute.</para>

        <para>An analytical form of the distribution function is not available
        for the LP3 and log-normal distributions. To compute the quantile qY
        (that is, the discharge with a 1 in Y AEP) the following equation may
        be used:</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:mrow>
                <m:mi>log</m:mi>

                <m:msub>
                  <m:mi>q</m:mi>

                  <m:mi>Y</m:mi>
                </m:msub>
              </m:mrow>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:mi>m</m:mi>

                <m:mo>+</m:mo>

                <m:mrow>
                  <m:msub>
                    <m:mi>K</m:mi>

                    <m:mi>Y</m:mi>
                  </m:msub>

                  <m:mo>(g)s</m:mo>
                </m:mrow>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <para>where m, s and g are the mean, standard deviation and skewness
        of the log discharge and KY is a frequency factor well-approximated by
        the Wilson-Hilferty transformation</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:mrow>
                <m:msub>
                  <m:mi>K</m:mi>

                  <m:mi>Y</m:mi>
                </m:msub>

                <m:mo>(g)</m:mo>
              </m:mrow>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:mo>{</m:mo>

                <m:mtable>
                  <m:mtr>
                    <m:mtd>
                      <m:mrow>
                        <m:mfrac>
                          <m:mi>2</m:mi>

                          <m:mi>g</m:mi>
                        </m:mfrac>

                        <m:mrow>
                          <m:mrow>
                            <m:mo>[ {</m:mo>

                            <m:mrow>
                              <m:mfrac>
                                <m:mi>g</m:mi>

                                <m:mi>6</m:mi>
                              </m:mfrac>

                              <m:mrow>
                                <m:mrow>
                                  <m:mo>(</m:mo>

                                  <m:mrow>
                                    <m:mrow>
                                      <m:msub>
                                        <m:mi>Z</m:mi>

                                        <m:mi>Y</m:mi>
                                      </m:msub>

                                      <m:mo>-</m:mo>

                                      <m:mfrac>
                                        <m:mi>g</m:mi>

                                        <m:mi>6</m:mi>
                                      </m:mfrac>
                                    </m:mrow>
                                  </m:mrow>

                                  <m:mo>)</m:mo>
                                </m:mrow>

                                <m:mo>+1}³</m:mo>
                              </m:mrow>
                            </m:mrow>
                          </m:mrow>

                          <m:mrow>
                            <m:mi>-1</m:mi>

                            <m:mtext>] if ∣g∣&gt;0</m:mtext>
                          </m:mrow>
                        </m:mrow>
                      </m:mrow>
                    </m:mtd>
                  </m:mtr>

                  <m:mtr>
                    <m:mtd>
                      <m:mi>0 if g=0</m:mi>
                    </m:mtd>
                  </m:mtr>
                </m:mtable>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <para>for |g| &lt; 2 and AEPs ranging from 0.99 to 0.01. The term
        z<subscript>Y</subscript> is the frequency factor for the standard
        normal distribution which has a mean of zero and standard deviation of
        1; z<subscript>Y</subscript> is the value of the standard normal
        deviate with exceedance probability 1/Y. Table 2 lists
        z<subscript>Y</subscript> for selected exceedance probabilities.
        Comprehensive tables of K<subscript>Y</subscript> can be found in
        Australian Rainfall and Runoff (1987, p.208).</para>

        <table>
          <title>Table 2. Frequency factors for standard normal
          distribution.</title>

          <tgroup cols="2">
            <colspec align="center"/>

            <thead>
              <row>
                <entry align="center">Y in AEP of 1 in Y</entry>

                <entry align="center">zY</entry>
              </row>
            </thead>

            <tbody>
              <row>
                <entry>2</entry>

                <entry>0.0000</entry>
              </row>

              <row>
                <entry>5</entry>

                <entry>0.8416</entry>
              </row>

              <row>
                <entry>10</entry>

                <entry>1.2816</entry>
              </row>

              <row>
                <entry>20</entry>

                <entry>1.6449</entry>
              </row>

              <row>
                <entry>50</entry>

                <entry>2.0537</entry>
              </row>

              <row>
                <entry>100</entry>

                <entry>2.3263</entry>
              </row>

              <row>
                <entry>200</entry>

                <entry>2.5758</entry>
              </row>

              <row>
                <entry>500</entry>

                <entry>2.8782</entry>
              </row>

              <row>
                <entry>1000</entry>

                <entry>3.0902</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </section>

      <section>
        <title>Generalized Pareto distribution</title>

        <para>In POT modelling the generalized Pareto (GP) distribution is
        often found to satisfactorily fit the data. Table 1 lists the pdf
        p(q|θ), distribution function P(Q≤q|θ) and product moments for the GP
        distribution. It has three parameters: q<subscript>*</subscript>, the
        location parameter, β, the scale parameter and κ, the shape parameter.
        When κ equals zero, the distribution simplifies to the exponential
        distribution also described in Table 1.</para>

        <para>The GP distribution has an intimate relationship with the GEV.
        If the GP describes the distribution of peaks over a threshold, then
        for Poisson arrivals of the POT peaks with ν being the average number
        of arrivals per year, it can be shown that the distribution of annual
        maximum peaks is GEV with shape parameter κ, scale parameter and
        location parameter .</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:mi>α</m:mi>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:mi>β</m:mi>

                <m:msup>
                  <m:mi>ν</m:mi>

                  <m:mi>-κ</m:mi>
                </m:msup>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <para>and location parameter</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:mi>τ</m:mi>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:mi>q∗</m:mi>

                <m:mo>+</m:mo>

                <m:mfrac>
                  <m:mi>β</m:mi>

                  <m:mi>κ</m:mi>
                </m:mfrac>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>
      </section>

      <section>
        <title>Zero-threshold mixture model</title>

        <para>In certain parts of Australia, the AM flood series may contain
        one or more years of zero or virtually zero flow. In such cases the
        flood probability model is best described by a two-component mixture
        model. In any year, there are two possibilities:</para>

        <para>1. There is a (fixed) probability P0 that the peak flow equals
        the zero-threshold flow q0, which may be zero or a near-zero
        flow.</para>

        <para>2.There is a probability 1- P0 that the peak flow exceeds the
        threshold. In that case the distribution of the peak flow follows a
        standard probability model.</para>

        <para>A formal definition of this model can be found in Box 2.</para>
      </section>

      <section>
        <title>Multi-component or mixture models</title>

        <para>In some areas, flooding may be affected by different types of
        meteorological events (for example, intense tropical cyclones and
        storms characterized by more usual synoptic conditions) or by changing
        hydraulic controls (e.g., see Example 1), causing abnormal slope
        changes in the frequency curve. In such cases the GEV or LP3 families
        may not adequately fit the data. This type of problem may be of
        particular importance in northern Australia, and an example is
        described by Ashkanasy and Weeks (1975). It may be desirable to
        separate the data by cause and analyze each set separately. The above
        reference describes a procedure using a combination of two log Normal
        distributions. A two-component extreme value distribution has been
        described by Rossi et al. (1984) and Fiorentino et al. (1985), and
        developed and applied to U.K. data by Beran et al. (1986).
        Alternatively the four or five parameter Wakeby distribution may be
        used to fit such data (Houghton, 1978).</para>
      </section>

      <section>
        <title>Non-homogeneous models</title>

        <para>If the evidence suggests that flood risk is affected by
        multi-decadal climate persistence, the use of non-homogeneous
        probability models may need to be investigated. The concern is that
        ignoring the non-homogeneity of the flood record may lead to biased
        estimates of long-term flood risk.</para>

        <para>If a non-homogeneous probability model with pdf p(q|θ(x)) is
        identified this cannot be used to estimate long-term or marginal flood
        risk. This is because the flood risk is dependent on the exogeneous
        variables x. To estimate long-term flood risk the dependence on x must
        be removed using the total probability rule to give</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:mi>P(Q≤q)</m:mi>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:mrow>
                  <m:munderover>
                    <m:mo>∫</m:mo>

                    <m:mi>x</m:mi>

                    <m:mi/>
                  </m:munderover>
                </m:mrow>

                <m:mrow>
                  <m:mo>(</m:mo>

                  <m:mrow>
                    <m:mrow>
                      <m:munderover>
                        <m:mo>∫</m:mo>

                        <m:mi>0</m:mi>

                        <m:mi>q</m:mi>
                      </m:munderover>

                      <m:mi>p(z∣θ</m:mi>
                    </m:mrow>

                    <m:mo>(x))dz</m:mo>
                  </m:mrow>

                  <m:mo>)</m:mo>
                </m:mrow>

                <m:mi>p(x)dx</m:mi>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <para>where p(x) is the pdf of the exogenous variables.</para>

        <para>If the gauged record adequately samples the distribution of x,
        it is not necessary to identify a non-homogeneous model. It suffices
        to fit a probability model to all the record to estimate the long-term
        flood risk.</para>

        <para>However, if the gauged record does not adequately sample x,
        significant bias in flood risk may result if only at-site data are
        used. In such instances, it will be necessary to employ regional
        frequency methods that take the nonhomogeneity into account. This is
        an area of current research. Users are advised to keep abreast of new
        developments.</para>

        <para>Example 3 illustrates the impact on flood risk arising from
        multi-decadal persistence in climate state as represented by the IPO
        index. It illustrates how the exogenous variable x can be constructed,
        demonstrates the serious bias in flood risk that can arise if short
        records do not adequately sample different climate states and
        illustrates the use of eqn (8).</para>
      </section>
    </section>

    <section>
      <title>Choice of Distribution for POT Series</title>

      <para>In some cases, it may be desirable to analytically fit a
      probability distribution to POT data. Distributions that have been used
      to describe the flood peak above a threshold include the exponential, GP
      and LP3.</para>
    </section>
  </section>

  <section>
    <title>CHOICE OF FLOOD QUANTILE ESTIMATOR</title>

    <para>In general the estimation of a design quantile should be guided by
    the consequences of over- and under-design [Slack et al., 1975].This
    section considers the following question: Given data D, what is the best
    estimate of the flood discharge which has an AEP of 1 in Y?</para>

    <para>If the true value of θ were known, then the pdf p(q|θ) can be used
    to compute the flood quantile q<subscript>Y</subscript>(θ). For AM series
    the quantile with an AEP of 1 in Y is defined as</para>

    <equation>
      <m:math display="block">
        <m:mrow>
          <m:mrow>
            <m:mo>P(q&gt;</m:mo>

            <m:msub>
              <m:mi>q</m:mi>

              <m:mi>Y</m:mi>
            </m:msub>

            <m:mi>∣θ</m:mi>
          </m:mrow>

          <m:mo>)=</m:mo>

          <m:mrow>
            <m:mfrac>
              <m:mi>1</m:mi>

              <m:mi>Y</m:mi>
            </m:mfrac>

            <m:mrow>
              <m:mo>=</m:mo>

              <m:mrow>
                <m:munderover>
                  <m:mo>∫</m:mo>

                  <m:msub>
                    <m:mi>q</m:mi>

                    <m:mi>Y</m:mi>
                  </m:msub>

                  <m:mi>ͯ∞</m:mi>
                </m:munderover>

                <m:mi>p(q∣θ</m:mi>
              </m:mrow>
            </m:mrow>

            <m:mi>)dq</m:mi>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>However, in practice the true value of θ (as well as the
    distribution family) is unknown. All that is known about θ, given the data
    D, is summarized by a probability distribution with pdf p(θ|D). Section 6
    describes how this distribution may be obtained – this distribution is the
    posterior distribution if performing a Bayesian analysis or the sampling
    distribution if performing a bootstrap analysis.</para>

    <para>If the true value of θ is not known, it follows that the true value
    of the quantile p(θ|D) is not known. The uncertainty about θ described by
    the pdf p(θ|D) , translates into uncertainty about the quantile, described
    by the quantile predictive pdf p(q<subscript>Y</subscript>|D). The
    question then arises, which value from the quantile predictive pdf
    p(q<subscript>Y</subscript>|D) should be adopted as the flood quantile
    estimate? This section presents two approaches for determining the best
    estimate of a flood discharge with a 1 in Y AEP knowing the pdf
    p(θ|D).</para>

    <section>
      <title>Expected Parameter Quantiles</title>

      <para>In general the estimation of a design quantile should be guided by
      the consequences of over- and under-design [Slack et al., 1975]. This
      section considers the case where the consequence of over- and
      under-design is expressed by some measure of the difference between the
      true and estimated 1-in-Y AEP quantiles – this difference is called the
      quantile error.</para>

      <para>The loss function L[
      q<subscript>y</subscript>(D),q<subscript>y</subscript>(θ)] describes the
      loss or consequence when the true quantile q<subscript>Y</subscript>(θ),
      which depends on θ, is incorrectly estimated by
      q<subscript>y</subscript>(D), which depends on the data D. Because the
      true value of θ is uncertain, the best estimator q<subscript>y
      </subscript>(D)<subscript>opt</subscript> is the one that minimizes the
      expected loss</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:msub>
              <m:mi>q</m:mi>

              <m:mi>Y</m:mi>
            </m:msub>

            <m:msub>
              <m:mi>(D)</m:mi>

              <m:mi>opt</m:mi>
            </m:msub>

            <m:mi>←</m:mi>

            <m:mo>min</m:mo>

            <m:mrow>
              <m:munderover>
                <m:mo>∫</m:mo>

                <m:mi>θ</m:mi>

                <m:mi/>
              </m:munderover>

              <m:mi>L[</m:mi>
            </m:mrow>

            <m:msub>
              <m:mi>q</m:mi>

              <m:mi>Y</m:mi>
            </m:msub>

            <m:mrow>
              <m:mi>(D),</m:mi>

              <m:msub>
                <m:mi>q</m:mi>

                <m:mi>Y</m:mi>
              </m:msub>

              <m:mi>(θ)]p(θ|D)dθ</m:mi>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>The optimal quantile estimator depends on the choice of loss
      function.</para>

      <section>
        <title>Quadratic loss</title>

        <para>The quadratic loss function may be appropriate when the
        consequences of under- or overdesign are judged to be the same and the
        loss is proportional to the square of the quantile error. The loss
        function is expressed as<equation>
            <m:math display="block">
              <m:mrow>
                <m:mi>L[</m:mi>

                <m:msub>
                  <m:mi>q</m:mi>

                  <m:mi>Y</m:mi>
                </m:msub>

                <m:mi>(D),</m:mi>

                <m:msub>
                  <m:mi>q</m:mi>

                  <m:mi>Y</m:mi>
                </m:msub>

                <m:mrow>
                  <m:mi>(θ)]α</m:mi>

                  <m:msub>
                    <m:mi>[ q</m:mi>

                    <m:mi>Y</m:mi>
                  </m:msub>

                  <m:mi>(D)</m:mi>

                  <m:mo>-</m:mo>

                  <m:msub>
                    <m:mi>q</m:mi>

                    <m:mi>Y</m:mi>
                  </m:msub>

                  <m:mo>(θ)]₂</m:mo>
                </m:mrow>
              </m:mrow>
            </m:math>
          </equation></para>

        <para>The expected value of this loss function is commonly referred to
        as the mean-squared-error (MSE). It can be shown the optimal quantile
        estimator is the expected value of qY(D) [DeGroot, 1970]</para>

        <para><equation>
            <m:math display="block">
              <m:mrow>
                <m:mrow>
                  <m:mi>E[</m:mi>

                  <m:msub>
                    <m:mi>q</m:mi>

                    <m:mi>Y</m:mi>
                  </m:msub>

                  <m:mi>|D]</m:mi>
                </m:mrow>

                <m:mo>=</m:mo>

                <m:mrow>
                  <m:mrow>
                    <m:munderover>
                      <m:mo>∫</m:mo>

                      <m:mi>θ</m:mi>

                      <m:mi/>
                    </m:munderover>
                  </m:mrow>

                  <m:msub>
                    <m:mi>q</m:mi>

                    <m:mi>Y</m:mi>
                  </m:msub>

                  <m:mi>(θ)p(θ|D)dθ</m:mi>
                </m:mrow>
              </m:mrow>
            </m:math>
          </equation></para>

        <para>Stedinger (1983) observes that this integral may not exist for
        some of the probability distributions used in flood frequency
        analysis. To avoid this problem the following first-order
        approximation may be used</para>

        <para><equation>
            <m:math display="block">
              <m:mrow>
                <m:mi>E[</m:mi>

                <m:msub>
                  <m:mi>q</m:mi>

                  <m:mi>Y</m:mi>
                </m:msub>

                <m:mi>| D]</m:mi>

                <m:msub>
                  <m:mi>q</m:mi>

                  <m:mi>Y</m:mi>
                </m:msub>

                <m:mi>[E(θ|D)].</m:mi>
              </m:mrow>
            </m:math>
          </equation></para>

        <para>where E(θ|D)] is the expected parameter given the data D</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:mi>E[θ|D]</m:mi>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:mrow>
                  <m:mo>∫</m:mo>

                  <m:mi>θp(θ|D)dθ</m:mi>
                </m:mrow>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <para>The term q<subscript>Y</subscript>[E(θ|D)] is referred to as the
        expected parameter 1-in-Y AEP quantile. When this term is used it is
        understood that the quantile is computed with θ assigned
        E(θ|D)].</para>
      </section>

      <section>
        <title>Linear asymmetric loss</title>

        <para>The linear asymmetric loss function may be appropriate when the
        consequences of under- and overdesign are judged to be different. The
        loss function is expressed as</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:mrow>
                <m:mi>L[</m:mi>

                <m:msub>
                  <m:mi>q</m:mi>

                  <m:mi>Y</m:mi>
                </m:msub>

                <m:mi>(D),</m:mi>

                <m:msub>
                  <m:mi>q</m:mi>

                  <m:mi>Y</m:mi>
                </m:msub>

                <m:mi>(θ)]</m:mi>
              </m:mrow>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:mo>{</m:mo>

                <m:mrow>
                  <m:mfrac>
                    <m:mrow>
                      <m:mi>α (</m:mi>

                      <m:msub>
                        <m:mi>q</m:mi>

                        <m:mi>Y</m:mi>
                      </m:msub>

                      <m:mi>(θ)-</m:mi>

                      <m:mrow>
                        <m:msub>
                          <m:mi>q</m:mi>

                          <m:mi>Y</m:mi>
                        </m:msub>

                        <m:mo>(D)) if</m:mo>

                        <m:msub>
                          <m:mi>q</m:mi>

                          <m:mi>Y</m:mi>
                        </m:msub>

                        <m:mo>(θ)&gt;</m:mo>

                        <m:msub>
                          <m:mi>q</m:mi>

                          <m:mi>Y</m:mi>
                        </m:msub>

                        <m:mo>(D),</m:mo>

                        <m:mi>underdesign</m:mi>
                      </m:mrow>
                    </m:mrow>

                    <m:mrow>
                      <m:mi>β(</m:mi>

                      <m:msub>
                        <m:mi>q</m:mi>

                        <m:mi>Y</m:mi>
                      </m:msub>

                      <m:mi>(D) -</m:mi>

                      <m:mrow>
                        <m:msub>
                          <m:mi>q</m:mi>

                          <m:mi>Y</m:mi>
                        </m:msub>

                        <m:mo>(θ)) if</m:mo>

                        <m:msub>
                          <m:mi>q</m:mi>

                          <m:mi>Y</m:mi>
                        </m:msub>

                        <m:mo>θ≤</m:mo>

                        <m:msub>
                          <m:mi>q</m:mi>

                          <m:mi>Y</m:mi>
                        </m:msub>
                      </m:mrow>

                      <m:mi>(D), overdesign</m:mi>
                    </m:mrow>
                  </m:mfrac>
                </m:mrow>

                <m:mo>}</m:mo>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <para>where α and β are the loss coefficients for under- and
        overdesign respectively. It can be shown that the quantile estimator
        that minimizes the expected asymmetric linear loss must satisfy
        [DeGroot, 1970]</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:mrow>
                <m:mi>P(</m:mi>

                <m:msub>
                  <m:mi>Q</m:mi>

                  <m:mi>Y</m:mi>
                </m:msub>

                <m:mi>≤</m:mi>

                <m:msub>
                  <m:mi>q</m:mi>

                  <m:mi>Y</m:mi>
                </m:msub>

                <m:msub>
                  <m:mi>(D)</m:mi>

                  <m:mi>opt</m:mi>
                </m:msub>

                <m:mo>|</m:mo>

                <m:mi>D)</m:mi>
              </m:mrow>

              <m:mo>=</m:mo>

              <m:mfrac>
                <m:mi>α</m:mi>

                <m:mrow>
                  <m:mi>α</m:mi>

                  <m:mo>+</m:mo>

                  <m:mi>β</m:mi>
                </m:mrow>
              </m:mfrac>
            </m:mrow>
          </m:math>
        </equation>

        <para>When α equals
        β,q<subscript>Y</subscript>(D)<subscript>opt</subscript>, is the
        median of the quantile predictive distribution. However, when α equals
        4β, implying the consequences of underdesign are four times more
        severe than overdesign, is the 80-percentile of the predictive
        distribution, a far more conservative estimate than the median.</para>
      </section>
    </section>

    <section>
      <title>Expected AEP Quantiles</title>

      <para>This section considers a different perspective on selecting a
      quantile estimator. In the previous section the uncertainty in the
      quantile for a given AEP was considered. In this section the uncertainty
      in AEP for a given q is considered.</para>

      <para>Stedinger (1983) showed that the dependence of the flood peak pdf
      on uncertain parameters can be removed using total probability to yield
      the design flood distribution</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mi>p(q|D)</m:mi>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mrow>
                <m:munderover>
                  <m:mo>∫</m:mo>

                  <m:mi>θ</m:mi>

                  <m:mi/>
                </m:munderover>

                <m:mi>p(q|θ)p(θ|D)dθ</m:mi>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>This distribution only depends on the data D (and the assumed
      probability family).</para>

      <para>The design flood quantile qY with 1 in Y AEP can be derived by
      solving</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mrow>
              <m:mi>P(q&gt;</m:mi>

              <m:msub>
                <m:mi>q</m:mi>

                <m:mi>Y</m:mi>
              </m:msub>

              <m:mi>|</m:mi>

              <m:mo>D)</m:mo>
            </m:mrow>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mrow>
                <m:mrow>
                  <m:munderover>
                    <m:mo>∫</m:mo>

                    <m:mi>θ</m:mi>

                    <m:mi/>
                  </m:munderover>

                  <m:mrow>
                    <m:mo>(</m:mo>

                    <m:mrow>
                      <m:mrow>
                        <m:munderover>
                          <m:mo>∫</m:mo>

                          <m:msub>
                            <m:mi>q</m:mi>

                            <m:mi>Y</m:mi>
                          </m:msub>

                          <m:mi>∞</m:mi>
                        </m:munderover>

                        <m:mi>p(q|θ)dq</m:mi>
                      </m:mrow>
                    </m:mrow>

                    <m:mo>)</m:mo>
                  </m:mrow>
                </m:mrow>

                <m:mo>p(θ</m:mo>

                <m:mi>|</m:mi>

                <m:mo>D)dθ</m:mo>
              </m:mrow>

              <m:mo>=</m:mo>

              <m:mfrac>
                <m:mi>1</m:mi>

                <m:mi>Y</m:mi>
              </m:mfrac>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>This quantile is greater than the expected parameter 1-in-Y AEP
      quantile q<subscript>Y</subscript>[E(θ|D)] . To gain further insight
      suppose we make qY equal to the expected parameter 1-in-Y AEP quantile
      and compute its design flood AEP using eqn (18). Noting the inner
      integral is the probability of the flood peak exceeding
      q<subscript>Y</subscript> given a particular value of θ, eqn (18) can be
      rewritten as</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mrow>
              <m:mi>P(q&gt;</m:mi>

              <m:msub>
                <m:mi>q</m:mi>

                <m:mi>Y</m:mi>
              </m:msub>

              <m:mi>|</m:mi>

              <m:mo>D)</m:mo>
            </m:mrow>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mrow>
                <m:mrow>
                  <m:munderover>
                    <m:mo>∫</m:mo>

                    <m:mi>θ</m:mi>

                    <m:mi/>
                  </m:munderover>

                  <m:mrow>
                    <m:mo>(</m:mo>

                    <m:mrow>
                      <m:mrow>
                        <m:munderover>
                          <m:mo>∫</m:mo>

                          <m:msub>
                            <m:mi>q</m:mi>

                            <m:mi>Y</m:mi>
                          </m:msub>

                          <m:mi>∞</m:mi>
                        </m:munderover>

                        <m:mi>p(q|θ)dq</m:mi>
                      </m:mrow>
                    </m:mrow>

                    <m:mo>)</m:mo>
                  </m:mrow>
                </m:mrow>

                <m:mo>p(θ</m:mo>

                <m:mi>|</m:mi>

                <m:mo>D)dθ</m:mo>
              </m:mrow>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:mrow>
                  <m:munderover>
                    <m:mo>∫</m:mo>

                    <m:mi>θ</m:mi>

                    <m:mi/>
                  </m:munderover>

                  <m:mi>P(q&gt;</m:mi>
                </m:mrow>

                <m:mrow>
                  <m:msub>
                    <m:mi>q</m:mi>

                    <m:mi>Y</m:mi>
                  </m:msub>

                  <m:mo>|θ)p(θ|D)dθ</m:mo>
                </m:mrow>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>It thus follows that the expected parameter 1-in-Y AEP quantile
      q<subscript>Y</subscript>[E(θ|D)] has an expected AEP given by
      P(q&gt;q<subscript>Y</subscript>|D) which exceeds 1/Y.</para>
    </section>

    <section>
      <title>Selection of Flood Quantile Estimator</title>

      <para>The choice of quantile estimator depends on whether design is
      being carried out for many sites or a single site, on whether risk,
      actual discharge or average annual damage is of primary interest in
      design and on whether the consequences of under- and overdesign are
      different. The choice is somewhat subjective and may be a matter of
      policy. As a general guide, a non-exhaustive list of recommendations is
      given below:</para>

      <orderedlist>
        <listitem>
          <para>In situations where there is indifference to the consequences
          of under- or overdesign, either the expected parameter or expected
          AEP quantile can be chosen.</para>

          <para>Expected parameter quantiles should be considered
          where:</para>

          <orderedlist numeration="lowerroman">
            <listitem>
              <para> Sizing of a structure is of primary interest rather than
              actual frequency of flooding, such as some bridges, culverts or
              drainage pipes</para>
            </listitem>

            <listitem>
              <para>Design is carried out to an arbitrary standard which has
              been judged to be satisfactory on the basis of experience from
              previous practice. Many of the design standards in Book III
              Sections 1.8 and 1.9, fall into this category.</para>
            </listitem>

            <listitem>
              <para>Unbiased estimates of annual flood damages are required
              (Doran and Irish, 1980).</para>
            </listitem>
          </orderedlist>

          <para>Expected AEP quantiles should be considered where:</para>

          <orderedlist numeration="lowerroman">
            <listitem>
              <para>Design is required for many sites in a region, and the
              objective is to attain a desired AEP over all sites.</para>
            </listitem>

            <listitem>
              <para>Flood estimates are made at multiple sites with different
              record lengths, and a comparable basis is required for flood
              estimates of a given AEP.</para>
            </listitem>

            <listitem>
              <para>Risk or frequency of exceedance is of primary importance
              for design at a single site (such as in floodplain management).
              iv. Split sample testing of flood estimation procedures (Beard,
              1960).</para>
            </listitem>

            <listitem>
              <para>Split sample testing of flood estimation procedures
              (Beard, 1960).</para>
            </listitem>
          </orderedlist>

          <para>5<emphasis>.</emphasis> If there are significant differences
          between the consequences of under- and overdesign, consideration
          should be given to using eqn (16) as the flood quantile
          estimator.</para>
        </listitem>
      </orderedlist>
    </section>
  </section>

  <section>
    <title>FITTING FLOOD PROBABILITY MODELS TO AM SERIES</title>

    <section>
      <title>Overview of Methods</title>

      <para>Fitting a flood probability model involves three steps:</para>

      <para>1. Calibrating the model to available data D to determine the
      parameter values consistent with the data D.</para>

      <para>2. Estimation of flood quantiles and their confidence
      limits.</para>

      <para>3. Evaluation of goodness of fit and consistency of model with
      data.</para>

      <para>Two calibration approaches are described involving Bayesian and L
      moment techniques. For each approach the algorithms are documented and
      illustrated with worked examples. Implementation of the algorithms in
      software requires specialist skill; therefore the typical user is
      advised to make use of available software. The use of the method of
      product-moments applied to log flows is not recommended. The choice of
      calibration methods depends on the type of data available (gauged and
      censored), the extent of measurement error associated with the rating
      curve and the availability of regional information about
      parameters.</para>
    </section>

    <section>
      <title>Probability Plots</title>

      <para>An essential part of a flood frequency analysis is the
      construction of an empirical distribution function, better known as a
      probability plot. In such a plot an estimate of AEP is plotted against
      the observed discharge. This enables one to draw a smooth curve as an
      empirical probability distribution or to visually check the adequacy of
      a fitted distribution.</para>

      <para>The following steps describe the production of a probability plot
      for gauged annual maximum floods:</para>

      <itemizedlist>
        <listitem>
          <para>Rank the gauged flows in descending order (that is, from
          largest to smallest) yielding the series
          {q<subscript>(1)</subscript>,
          q<subscript>(2)</subscript>,…,q<subscript>(n)</subscript>} where
          q<subscript>(i)</subscript> is the rank i or the
          i<superscript>th</superscript> largest flood.</para>
        </listitem>

        <listitem>
          <para>Estimate the AEP for each q<subscript>(i)</subscript> using a
          suitable plotting position.</para>
        </listitem>

        <listitem>
          <para>Using suitable scales plot the estimated AEP against
          q<subscript>(i)</subscript>.</para>
        </listitem>
      </itemizedlist>

      <para>For analysis of the AM series, a general formula (Blom, 1958) for
      estimating the AEP of an observed flood is</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:msub>
              <m:mi>P</m:mi>

              <m:mi>(i)</m:mi>
            </m:msub>

            <m:mo>=</m:mo>

            <m:mfrac>
              <m:mrow>
                <m:mi>i</m:mi>

                <m:mo>-</m:mo>

                <m:mi>α</m:mi>
              </m:mrow>

              <m:mrow>
                <m:mi>n</m:mi>

                <m:mo>+</m:mo>

                <m:mrow>
                  <m:mi>1</m:mi>

                  <m:mo>-</m:mo>

                  <m:mi>2α</m:mi>
                </m:mrow>
              </m:mrow>
            </m:mfrac>
          </m:mrow>
        </m:math>
      </equation>

      <para>where i is the rank of the gauged flood, n is the number of years
      of gauged floods and α is a constant whose value is selected to preserve
      desirable statistical properties.</para>

      <para>There are several choices for α:</para>

      <itemizedlist>
        <listitem>
          <para>α= 0 yields the Weibull plotting position which produces
          unbiased estimates of the AEP of q<subscript>(i)</subscript>.</para>
        </listitem>

        <listitem>
          <para>α= 0.375 yields the Blom’s plotting position which produces
          unbiased quantile estimates for the normal distribution.</para>
        </listitem>

        <listitem>
          <para>α= 0.4 yields the Cunnane’s (1978) plotting position which
          produces nearly unbiased quantile estimates for a range of
          probability families.</para>
        </listitem>
      </itemizedlist>

      <para>While there are arguments in favour of plotting positions that
      yield unbiased AEPs, usage has favoured plotting positions that yield
      unbiased quantiles. To maintain consistency it is recommended that the
      Cunnane plotting position be used, namely</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:msub>
              <m:mi>P</m:mi>

              <m:mi>(i)</m:mi>
            </m:msub>

            <m:mo>=</m:mo>

            <m:mfrac>
              <m:mrow>
                <m:mi>i</m:mi>

                <m:mo>-</m:mo>

                <m:mi>0.4</m:mi>
              </m:mrow>

              <m:mrow>
                <m:mi>n</m:mi>

                <m:mo>+</m:mo>

                <m:mi>0.2</m:mi>
              </m:mrow>
            </m:mfrac>
          </m:mrow>
        </m:math>
      </equation>

      <para>A fuller discussion on plotting positions can be found in
      Stedinger et al. (1993).</para>

      <para>It is stressed that plotting positions should not be used as an
      estimate of the actual AEP or ARI of an observed flood discharge. Such
      estimates should be obtained from the fitted distribution.</para>

      <para>Judicious choice of scale for the probability plot can assist the
      evaluation of goodness of fit. The basic idea is to select a scale so
      that the data plot as a straight line if the data are consistent with
      the assumed probability model.</para>

      <para>This is best illustrated by an example. Suppose it is assumed that
      floods follow an exponential distribution. From Table 1 the distribution
      function is</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mi>P(Q≤q)</m:mi>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mi>1</m:mi>

              <m:mo>-exp</m:mo>

              <m:mrow>
                <m:mo>(-</m:mo>

                <m:mfrac>
                  <m:mrow>
                    <m:mi>q</m:mi>

                    <m:mo>-</m:mo>

                    <m:msub>
                      <m:mi>q</m:mi>

                      <m:mi>*</m:mi>
                    </m:msub>
                  </m:mrow>

                  <m:mi>β</m:mi>
                </m:mfrac>

                <m:mo>)</m:mo>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>Replacing q by q<subscript>(i)</subscript> and 1-P(Q≤q) by the
      plotting position of q<subscript>(i)</subscript> gives</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:msub>
              <m:mi>q</m:mi>

              <m:mi>(i)</m:mi>
            </m:msub>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:msub>
                <m:mi>q</m:mi>

                <m:mi>*</m:mi>
              </m:msub>

              <m:mo>-</m:mo>

              <m:mrow>
                <m:mi>βlog</m:mi>

                <m:msub>
                  <m:mi>P</m:mi>

                  <m:mi>(i)</m:mi>
                </m:msub>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>If q<subscript>(i)</subscript> is plotted against
      logP<subscript>(i)</subscript> the data will plot approximately as a
      straight line if they are consistent with the exponential
      distribution.</para>

      <para>Examples for other distributions include:</para>

      <itemizedlist>
        <listitem>
          <para>For the Gumbel distribution plot q<subscript>(i)</subscript>
          against –log[-log(1-P<subscript>(i)</subscript>)]. Data following a
          GEV distribution will plot as a curved line.</para>
        </listitem>

        <listitem>
          <para>For the log normal distribution plot log
          q<subscript>(i)</subscript> against the standard normal deviate with
          exceedance probability P<subscript>(i)</subscript>. Data following a
          LP3 distribution will plot as a curved line.</para>
        </listitem>
      </itemizedlist>

      <para>When visually evaluating the goodness of fit care needs to be
      exercised in judging the significance of departures from the assumed
      distribution. Plotting positions are correlated. As a result, they do
      not scatter about the fitted distribution independently of each other.
      The correlation can induce “waves” or regions of systematic departure
      from the fitted distribution. To guard against this it is suggested that
      statistical tests be used to assist goodness-of-fit assessment.
      Stedinger et al. (1993) discuss the use of the Kolmogorov-Smirnov test,
      the Filiben probability plot correlation test and L moment diagrams and
      ratio tests.</para>

      <para>The estimation of plotting positions for censored and historic
      data is more involved and in some cases can be inaccurate - see
      Stedinger et al. (1993, p 18.41) for more details.</para>
    </section>

    <section>
      <title>Bayesian Calibration</title>

      <section>
        <title>Overview</title>

        <para>The Bayesian approach is a very general approach for calibrating
        and identifying models. The Handbook of Hydrology [Stedinger et al.,
        1993, p18.8] observes that “the Bayesian approach .. allows the
        explicit modeling of uncertainty in parameters and provides a
        theoretically consistent framework for integrating systematic flow
        records with regional and other hydrologic information”. However, it
        is only with the advent of new computational methods that Bayesian
        methods can be routinely applied to flood frequency
        applications.</para>

        <para>The core of the Bayesian approach is described below – see Lee
        (1989) and Gelman et al. (1995) for general expositions. The data D is
        hypothesized to be a random realization from a probability model with
        pdf p(D|θ,M) where θ is a vector of unknown parameters. The pdf p(D|θ)
        is given two labels depending on the context. When p(D|θ) is used to
        describe the probability model generating the sample data D for a
        given θ, it is called the sampling distribution. However, when
        inference about the parameter θ is sought, p(D|θ) is called the
        likelihood function to emphasize that the data D is known and the
        parameter θ is the object of attention. The same notation for the
        sampling distribution and likelihood function is used to emphasize its
        oneness.</para>

        <para>In Bayesian inference the parameter vector θ is considered to be
        a random vector whose probability distribution describes what is known
        about the true value of θ. Prior to analyzing the data D, knowledge
        about θ given the probability model is summarized by the pdf p(θ).
        This density, referred to as the prior density, can incorporate
        subjective belief about θ.</para>

        <para>Bayes theorem is then used to process the information contained
        in the data D by updating what is known about the true value of θ as
        follows:</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:mi>p(θ|D)</m:mi>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:mfrac>
                  <m:mi>p(D|θ)p(θ)</m:mi>

                  <m:mi>p(D)</m:mi>
                </m:mfrac>

                <m:mo>α</m:mo>

                <m:mi>p(D|θ)p(θ)</m:mi>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <para>The posterior density p(θ|D) describes what is known about the
        true value of θ given the data D, prior information and the
        probability model. The denominator p(D) is the marginal likelihood
        defined as</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:mi>p(D)</m:mi>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:mrow>
                  <m:mo>∫</m:mo>

                  <m:mi>p(D|</m:mi>
                </m:mrow>

                <m:mrow>
                  <m:mi>θ)p(θ)dθ</m:mi>
                </m:mrow>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <para>Usually the marginal likelihood is not computed as it does not
        depend on θ and serves as a normalizing constant.</para>
      </section>

      <section>
        <title>Likelihood Function</title>

        <para>The key to a Bayesian analysis is the formulation of the
        likelihood function. In the context of flood frequency analysis two
        formulations are considered. The first assumes there is no error in
        the flood data. The focus is on the contribution to the likelihood
        function made by gauged and censored data. The second case generalizes
        the likelihood function to allow for error-in-discharge
        estimates.</para>
      </section>

      <section>
        <title>Likelihood function: No-error-discharge Case</title>

        <para>Suppose the following data are available:</para>

        <orderedlist>
          <listitem>
            <para>A gauged record of n true flood peaks
            {q<subscript>1</subscript>,...,q<subscript>n</subscript>};
            and</para>
          </listitem>

          <listitem>
            <para>m censored records in which a<subscript>i</subscript> annual
            flood peaks in (a<subscript>i</subscript> +
            b<subscript>i</subscript>) ungauged years exceeded a threshold
            with true discharge s<subscript>i</subscript>, i=1,..,m.</para>
          </listitem>
        </orderedlist>

        <para>This data is denoted by D = {q<subscript>i</subscript>,
        i=1,..,n; (a<subscript>i</subscript>, b<subscript>i</subscript>,
        s<subscript>i</subscript>), i=1,..,m}. It is shown in Box 3 that the
        likelihood function is</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:mi>p(D|θ)α</m:mi>

              <m:mrow>
                <m:munderover>
                  <m:mo>∏</m:mo>

                  <m:mi>i=1</m:mi>

                  <m:mi>n</m:mi>
                </m:munderover>

                <m:mi>p(</m:mi>
              </m:mrow>

              <m:msub>
                <m:mi>q</m:mi>

                <m:mi>i</m:mi>
              </m:msub>

              <m:mi>|θ)</m:mi>

              <m:mrow>
                <m:munderover>
                  <m:mo>∏</m:mo>

                  <m:mi>i=1</m:mi>

                  <m:mi>m</m:mi>
                </m:munderover>

                <m:mi>[1-P(Q≤</m:mi>
              </m:mrow>

              <m:mrow>
                <m:msub>
                  <m:mi>s</m:mi>

                  <m:mi>i</m:mi>
                </m:msub>

                <m:mi>|θ)</m:mi>

                <m:msup>
                  <m:mi>]</m:mi>

                  <m:mi>ai</m:mi>
                </m:msup>

                <m:mi/>

                <m:mo>P(Q≤</m:mo>

                <m:mrow>
                  <m:msub>
                    <m:mi>x</m:mi>

                    <m:mi>i</m:mi>
                  </m:msub>

                  <m:mo>|</m:mo>

                  <m:mi>θ</m:mi>

                  <m:msup>
                    <m:mi>)</m:mi>

                    <m:mi>bi</m:mi>
                  </m:msup>

                  <m:mi/>
                </m:mrow>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>
      </section>

      <section>
        <title>The Likelihood Function: Error-in-discharge Case</title>

        <para>The incorporation of rating errors into the likelihood function
        complicates matters. Box 4 outlines the derivation of the likelihood
        function using the simple rating error model presented in Section 3.7.
        There has been limited research into the use of this likelihood and on
        the characterization of rating errors. Kuczera (1996) shows that, as
        rating error grows for floods well in excess of the largest gauged
        flow, less weight is given to high floods in the calibration. This
        loss of information about the right tail of the flood distribution is
        sensitive to the magnitude of rating errors when extrapolating beyond
        gauged flows. Unfortunately little is known about these errors.
        Therefore caution is recommended if using this advanced
        likelihood.</para>
      </section>

      <section>
        <title>Prior Distributions</title>

        <para>The prior pdf p(θ) reflects the worth of prior information on θ
        obtained preferably from a regional analysis. A convenient
        distribution is the multivariate normal with mean μp and covariance
        Σp; that is,</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:mi>θ</m:mi>

              <m:mo>~</m:mo>

              <m:mi>N(</m:mi>

              <m:msub>
                <m:mi>μ</m:mi>

                <m:mi>p</m:mi>
              </m:msub>

              <m:mrow>
                <m:msub>
                  <m:mi>,Σ</m:mi>

                  <m:mi>p</m:mi>
                </m:msub>

                <m:mo>)</m:mo>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <para>In the absence of prior information, the covariance matrix can
        be made non-informative as illustrated in the following equation for a
        three-parameter model:</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:msub>
                <m:mi>Σ</m:mi>

                <m:mi>p</m:mi>
              </m:msub>

              <m:mo>v→</m:mo>

              <m:mi>∞</m:mi>

              <m:mrow>
                <m:mo>(</m:mo>

                <m:mtable>
                  <m:mtr>
                    <m:mtd>
                      <m:mi>v</m:mi>
                    </m:mtd>

                    <m:mtd>
                      <m:mi>0</m:mi>
                    </m:mtd>

                    <m:mtd>
                      <m:mi>0</m:mi>
                    </m:mtd>
                  </m:mtr>

                  <m:mtr>
                    <m:mtd>
                      <m:mi>0</m:mi>
                    </m:mtd>

                    <m:mtd>
                      <m:mi>v</m:mi>
                    </m:mtd>

                    <m:mtd>
                      <m:mi>0</m:mi>
                    </m:mtd>
                  </m:mtr>

                  <m:mtr>
                    <m:mtd>
                      <m:mi>0</m:mi>
                    </m:mtd>

                    <m:mtd>
                      <m:mi>0</m:mi>
                    </m:mtd>

                    <m:mtd>
                      <m:mi>v</m:mi>
                    </m:mtd>
                  </m:mtr>
                </m:mtable>

                <m:mo>)</m:mo>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <para>Informative prior information can be obtained from a regional
        analysis of flood data.</para>

        <para>The use of an informative prior based on regional analysis is
        strongly recommended in all flood frequency analyses involving at-site
        data. Even with long at-site records, the shape parameter in the LP3
        and GEV distribution is subject to considerable uncertainty. Regional
        priors can substantially reduce the uncertainty in the shape (and even
        scale) parameter.</para>

        <para>The regional procedures in Book 3, Chapter 3 are designed to
        express the prior information in the form of eqn (28) for the log
        Pearson 3 probability model. They should be used in any flood
        frequency analysis involving the log Pearson 3 distribution unless
        there is evidence that the regional prior is not applicable to the
        catchment of interest.</para>
      </section>

      <section>
        <title>Monte Carlo Sampling from the Posterior Distribution</title>

        <para>The posterior pdf p(θ|D) fully defines the parameter
        uncertainty. However, interpreting this distribution is difficult
        using analytical methods. Modern Monte Carlo methods for sampling from
        the posterior have overcome this limitation – for example, see Gelman
        et al. (1995). Box 5 describes a particular sampling procedure called
        importance sampling.</para>
      </section>

      <section>
        <title>Quantile Confidence Limits and Expected Probability</title>

        <para>The posterior distribution of any function dependent on θ can be
        readily approximated using Monte Carlo samples. Confidence limits
        describe the uncertainty about quantiles arising from uncertainty in
        the fitted parameters. They are used in conjunction with the
        probability plot to evaluate goodness-of-fit. 100(1-α)% quantile
        confidence limits, or more correctly probability limits. Confidence
        limits can be derived as follows:</para>

        <orderedlist>
          <listitem>
            <para>Draw N samples from the posterior distribution
            {θ,w,i=1,...,N) where w<subscript>i</subscript> is the normalized
            weight assigned to the sample θ.</para>
          </listitem>

          <listitem>
            <para> Rank in ascending order the N quantiles
            {q<subscript>Y</subscript>(θ<subscript>(i)</subscript>),i=1,..,N}.
            .</para>
          </listitem>

          <listitem>
            <para>For each ranked quantile evaluate the non-exceedance
            probability <inlineequation>
                <m:math display="inline">
                  <m:munderover>
                    <m:mo>∑</m:mo>

                    <m:mi>j=1</m:mi>

                    <m:mi>i</m:mi>
                  </m:munderover>

                  <m:msub>
                    <m:mi>W</m:mi>

                    <m:mi>(j)</m:mi>
                  </m:msub>

                  <m:mi> </m:mi>
                </m:math>
              </inlineequation>where W<subscript>(j)</subscript> is the weight
            for the j<superscript>th</superscript> ranked quantile
            q<subscript>Y</subscript>(θ<subscript>(j)</subscript>) .</para>
          </listitem>

          <listitem>
            <para>The lower and upper confidence limits are approximated by
            the quantiles whose non-exceedance probabilities are
            nearest.</para>
          </listitem>
        </orderedlist>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:mfrac>
                <m:mi>α</m:mi>

                <m:mi>2</m:mi>
              </m:mfrac>

              <m:mo>and</m:mo>

              <m:mi>1-</m:mi>

              <m:mfrac>
                <m:mi>α</m:mi>

                <m:mi>2</m:mi>
              </m:mfrac>

              <m:mi>respectively.</m:mi>
            </m:mrow>
          </m:math>
        </equation>

        <para>The expected posterior parameters can be estimated</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:mi>E[θ|</m:mi>

              <m:mo>D]=</m:mo>

              <m:mrow>
                <m:munderover>
                  <m:mo>∑</m:mo>

                  <m:mi>i=1</m:mi>

                  <m:mi>N</m:mi>
                </m:munderover>

                <m:msub>
                  <m:mi>W</m:mi>

                  <m:mi>i</m:mi>
                </m:msub>
              </m:mrow>

              <m:msub>
                <m:mi>q</m:mi>

                <m:mi>Y</m:mi>
              </m:msub>

              <m:msub>
                <m:mi>(θ)</m:mi>

                <m:mi>i</m:mi>
              </m:msub>
            </m:mrow>
          </m:math>
        </equation>

        <para>These parameters can then be used to compute the expected
        parameter 1-in-Y AEP quantiles described in Section 5.1.</para>

        <para>Finally, the expected AEP probability for a flood of magnitude
        q<subscript>Y</subscript> can be estimated</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:mrow>
                <m:mi>E[P(q&gt;</m:mi>

                <m:msub>
                  <m:mi>q</m:mi>

                  <m:mi>Y</m:mi>
                </m:msub>

                <m:mi>|</m:mi>

                <m:mo>D)]</m:mo>
              </m:mrow>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:mrow>
                  <m:munderover>
                    <m:mo>∑</m:mo>

                    <m:mi>i=1</m:mi>

                    <m:mi>N</m:mi>
                  </m:munderover>

                  <m:msub>
                    <m:mi>w</m:mi>

                    <m:mi>i</m:mi>
                  </m:msub>
                </m:mrow>

                <m:mo>P(q&gt;</m:mo>

                <m:msub>
                  <m:mi>q</m:mi>

                  <m:mi>Y</m:mi>
                </m:msub>

                <m:msub>
                  <m:mi>|θ</m:mi>

                  <m:mi>i</m:mi>
                </m:msub>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>
      </section>

      <section>
        <title>Treatment of Poor Fits</title>

        <para>The standard probability models described in Section 4 may
        sometimes poorly fit flood data. Typically the goodness-of-fit is
        assessed by comparing observed data against the fitted probability
        model and its confidence limits. A poor fit may be characterized
        by:</para>

        <itemizedlist>
          <listitem>
            <para>Presence of outliers in the upper or lower tail of the
            distribution. Outliers in flood frequency analysis represent
            observations that are inconsistent with the trend of the remaining
            data and typically would lie well outside confidence
            limits.</para>
          </listitem>

          <listitem>
            <para>Systematic discrepancies between observed and fitted
            distributions. Caution is required in interpreting systematic
            departures because plotting positions are correlated. Confidence
            limits can help guide the interpretation.</para>
          </listitem>
        </itemizedlist>

        <para>Poor fits to the standard probability models may arise for a
        variety of reasons including the following:</para>

        <orderedlist>
          <listitem>
            <para>Small AM peaks may not be significant floods and thus may be
            unrepresentative of significant flood peaks.</para>
          </listitem>

          <listitem>
            <para>By chance, one or more observed floods may be unusually rare
            for the length of gauged record. Recourse to the historical flood
            record may be useful in resolving this issue.</para>
          </listitem>

          <listitem>
            <para>Rating curve extensions are biased resulting in a systematic
            under or over-estimate of large floods (see discussion in Section
            3.7).</para>
          </listitem>

          <listitem>
            <para>A change in hydraulic control with discharge may affect the
            shape of the frequency curve as illustrated in Example 1.</para>
          </listitem>

          <listitem>
            <para>Storm events responsible for significant flooding may be
            caused by different meteorological mechanisms which lead to a
            mixed population not amenable to three-parameter distributions.
            This may arise when the majority of flood-producing storms are
            generated by one meteorological mechanism and the minority by an
            atypical mechanism such as a tropical cyclone.</para>
          </listitem>

          <listitem>
            <para>Nonhomogeneity of the flood record.</para>
          </listitem>
        </orderedlist>

        <para>The potential causes of a poor fit need careful
        investigation.</para>

        <para>If it is decided the poor fit is due to inadequacy of the
        probability model, three strategies are available to deal with the
        problem:</para>

        <orderedlist>
          <listitem>
            <para>Observations can be censored.</para>
          </listitem>

          <listitem>
            <para>The data responsible for the unsatisfactory fit may be given
            less weight.</para>
          </listitem>

          <listitem>
            <para>A more flexible probability model can used to fit the
            data.</para>
          </listitem>
        </orderedlist>

        <para>Data in the upper part of the distribution is typically of more
        interest and therefore a strong case needs to be made to justify
        reduction in weight of such data.</para>
      </section>

      <section>
        <title>Censoring of Potentially Influential Low Flows</title>

        <para>AM series contain many annual maximum flows which are less than
        bankfull discharge. In arid zones these low peaks may be zero or very
        low values not associated with any significant storm event. These low
        peaks may not be representative of the physical processes driving
        large floods (Cohn et al., 2013; Pedruco et al., 2013). The inclusion
        of such data in a flood frequency analysis runs the risk of low peaks
        unrepresentative of large floods influencing the fit to the right-hand
        tail of the frequency distribution, which is of most interest to the
        hydrologist. Therefore the identification and removal of potentially
        influential low flows (PILFs) is considered an important step in a
        flood frequency analysis.</para>

        <para>Cohn et al. (2013) developed a generalization of the Grubbs-Beck
        test that was recommended in Bulletin 17B (IACWD, 1982) to identify
        PILFS. The multiple Grubbs-Beck test, checks if the kth smallest flow
        is unusually low and, if it is, uses this flow to define a threshold
        for censoring flows below the threshold. The test involves two
        steps:</para>

        <orderedlist>
          <listitem>
            <para>The outward sweep starts at the median flow and moves
            towards the smallest flow. Each flow is tested at the 0.5%
            significance level. If the k<superscript>th</superscript> smallest
            flow is identified as a low outlier, the outward sweep
            stops.</para>
          </listitem>

          <listitem>
            <para>The inward sweep starts at the smallest flow and moves
            towards the median. Each flow is tested at the 10% significance
            level. If the m<superscript>th</superscript> flow is identified as
            a low outlier, the inward sweep stops.</para>
          </listitem>
        </orderedlist>

        <para>The total number of low outliers is then the maximum of k and m
        - 1. The flows identified as low outliers are treated as censored
        flows.</para>

        <para>The multiple Grubbs-Beck test is recommended for general use but
        must be conducted in unison with a visual assessment of the fitted
        frequency curve.</para>
      </section>

      <section>
        <title>Software</title>

        <para>The Bayesian approach to calibrating flood probability models is
        numerically complex and is best implemented in a high level
        programming language. The web-based software called TUFLOW FLIKE
        supporting the Bayesian methods described in this chapter is available
        at www.xxx.com.au. The reader is advised that this does not preclude
        use of other software if it is fit for purpose.</para>
      </section>

      <section>
        <title>Worked Examples</title>

        <para>Example 3 illustrates fitting a LP3 distribution to a 31-year
        gauged record. Although the fit is judged satisfactory, considerable
        uncertainty in the 1 in 100 AEP quantile is noted.</para>

        <para>Example 4 is a continuation of Example 3 and illustrates the
        benefit of incorporating censored historic flood information. In the
        118 years prior to gauging only one flood exceed the largest gauged
        flood. This information is shown to substantially reduce quantile
        uncertainty.</para>

        <para>Example 5 is a continuation of Example 3. It illustrates the
        value of regional information in reducing uncertainty in parameters
        and quantiles. It is recommended that regional information be always
        used unless there is contray evidence.</para>

        <para>Examples 6 illustrates the identification of PILFs using the
        multiple Grubbs-Beck test and fitting a LP3 distribution with PILFs
        treated as censored flows. It is recommended that multiple Grubbs-Beck
        test be performed in all flood frequency analyses.</para>

        <para>Example 7 illustrates how three–parameter distributions such as
        the GEV and LP3 can be made to fit data exhibiting sigmoidal
        behaviour. Because interest is in fitting the higher flows the low
        flows are de-emphasized by treating them as censored observations. In
        this example the multiple Grubbs-Beck test improved the fit but a more
        severe manual censoring produced an even better fit to the right-hand
        tail.</para>

        <para>Finally Example 8 illustrates application of a non-homogeneous
        flood probability model conditioned on the IPO index. It shows how the
        long-term flood risk may be estimated.</para>
      </section>
    </section>

    <section>
      <title>L Moments Approach</title>

      <section>
        <title>Overview</title>

        <para>L moments were developed by Hosking (1990) to overcome the bias
        and sensitivity of the method of product-moments approach to fitting
        distributions. L moment estimators are unbiased and are less sensitive
        to outliers than product-moment estimators. They have been used
        extensively by researchers to analyze extremes and are recommended for
        use in flood frequency analysis in the Handbook of Hydrology
        [Stedinger et al., 1993].</para>

        <para>The L moment approach is simpler than the Bayesian approach but
        limited in capability. It is restricted to applications involving
        gauged flow data where there is no useful regional information and
        rating curve errors do not require special attention.</para>
      </section>

      <section>
        <title>L-moments for summarizing distributions</title>

        <para>Hosking (1990) developed the L-moment theory based on order
        statistics. The first four L-moments are defined as</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:msub>
                <m:mi>λ</m:mi>

                <m:mi>1</m:mi>
              </m:msub>

              <m:mo>=</m:mo>

              <m:msub>
                <m:mi>E[X]</m:mi>

                <m:mi>1:1</m:mi>
              </m:msub>
            </m:mrow>
          </m:math>
        </equation>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:msub>
                <m:mi>λ</m:mi>

                <m:mi>2</m:mi>
              </m:msub>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:mfrac>
                  <m:mi>1</m:mi>

                  <m:mi>2</m:mi>
                </m:mfrac>

                <m:mo>E</m:mo>

                <m:mrow>
                  <m:mo>[</m:mo>

                  <m:mrow>
                    <m:msub>
                      <m:mi>X</m:mi>

                      <m:mi>2:2</m:mi>
                    </m:msub>

                    <m:mo>-</m:mo>

                    <m:msub>
                      <m:mi>X</m:mi>

                      <m:mi>1:2</m:mi>
                    </m:msub>
                  </m:mrow>

                  <m:mo>]</m:mo>
                </m:mrow>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:msub>
                <m:mi>λ</m:mi>

                <m:mi>3</m:mi>
              </m:msub>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:mfrac>
                  <m:mi>1</m:mi>

                  <m:mi>3</m:mi>
                </m:mfrac>

                <m:mo>E</m:mo>

                <m:mrow>
                  <m:mo>[</m:mo>

                  <m:mrow>
                    <m:msub>
                      <m:mi>X</m:mi>

                      <m:mi>3:3</m:mi>
                    </m:msub>

                    <m:mo>-</m:mo>

                    <m:mrow>
                      <m:msub>
                        <m:mi>2X</m:mi>

                        <m:mi>2:3</m:mi>
                      </m:msub>

                      <m:mo>+</m:mo>

                      <m:msub>
                        <m:mi>X</m:mi>

                        <m:mi>1:3</m:mi>
                      </m:msub>
                    </m:mrow>
                  </m:mrow>

                  <m:mo>]</m:mo>
                </m:mrow>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:msub>
                <m:mi>λ</m:mi>

                <m:mi>4</m:mi>
              </m:msub>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:mfrac>
                  <m:mi>1</m:mi>

                  <m:mi>4</m:mi>
                </m:mfrac>

                <m:mo>E</m:mo>

                <m:mrow>
                  <m:mo>[</m:mo>

                  <m:mrow>
                    <m:msub>
                      <m:mi>X</m:mi>

                      <m:mi>4:4</m:mi>
                    </m:msub>

                    <m:mo>-</m:mo>

                    <m:mrow>
                      <m:msub>
                        <m:mi>3X</m:mi>

                        <m:mi>3:4</m:mi>
                      </m:msub>

                      <m:mo>+</m:mo>

                      <m:mrow>
                        <m:msub>
                          <m:mi>3X</m:mi>

                          <m:mi>2:4</m:mi>
                        </m:msub>

                        <m:mo>-</m:mo>

                        <m:msub>
                          <m:mi>X</m:mi>

                          <m:mi>1:4</m:mi>
                        </m:msub>
                      </m:mrow>
                    </m:mrow>
                  </m:mrow>

                  <m:mo>]</m:mo>
                </m:mrow>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <para>where X<subscript>j:m</subscript> is the
        j<superscript>th</superscript> smallest variable in a sample of size m
        and E stands for expectation.</para>

        <para>Wang (1996) justifies L-moments as follows: “When there is only
        one value in a sample, it gives a feel of the magnitude of the random
        variable. When there are two values in a sample, their difference
        gives a sense of how varied the random variable is. When there are
        three values in a sample, they give some indication on how asymmetric
        the distribution is. When there are four values in a sample, they give
        some clue on how peaky, roughly speaking, the distribution is.
        “</para>

        <para>When many such samples are considered, the expectations
        λ<subscript>1</subscript> and λ<subscript>2</subscript> give measures
        of location and scale. Moreover, the L moment ratios</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:msub>
                <m:mi>τ</m:mi>

                <m:mi>3</m:mi>
              </m:msub>

              <m:mo>=</m:mo>

              <m:mfrac>
                <m:msub>
                  <m:mi>λ</m:mi>

                  <m:mi>3</m:mi>
                </m:msub>

                <m:msub>
                  <m:mi>λ</m:mi>

                  <m:mi>2</m:mi>
                </m:msub>
              </m:mfrac>
            </m:mrow>
          </m:math>
        </equation>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:msub>
                <m:mi>τ</m:mi>

                <m:mi>4</m:mi>
              </m:msub>

              <m:mo>=</m:mo>

              <m:mfrac>
                <m:msub>
                  <m:mi>λ</m:mi>

                  <m:mi>4</m:mi>
                </m:msub>

                <m:msub>
                  <m:mi>λ</m:mi>

                  <m:mi>2</m:mi>
                </m:msub>
              </m:mfrac>
            </m:mrow>
          </m:math>
        </equation>

        <para>give measures of skewness and kurtosis respectively. Hosking
        termed τ<subscript>3</subscript> L-skewness and
        τ<subscript>4</subscript> L-kurtosis. Hosking also defined the
        L-coefficient of variation as</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:msub>
                <m:mi>τ</m:mi>

                <m:mi>2</m:mi>
              </m:msub>

              <m:mo>=</m:mo>

              <m:mfrac>
                <m:msub>
                  <m:mi>λ</m:mi>

                  <m:mi>2</m:mi>
                </m:msub>

                <m:msub>
                  <m:mi>λ</m:mi>

                  <m:mi>1</m:mi>
                </m:msub>
              </m:mfrac>
            </m:mrow>
          </m:math>
        </equation>

        <para>Table 3 summarizes L moments for a range of
        distributions.</para>

        <informaltable>
          <tgroup cols="2">
            <tbody>
              <row>
                <entry>Family</entry>

                <entry>L Moments</entry>
              </row>

              <row>
                <entry>Generalized extreme value (GEV)</entry>

                <entry><inlineequation>
                    <m:math display="inline">
                      <m:mtable>
                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:msub>
                                <m:mi>λ</m:mi>

                                <m:mi>1</m:mi>
                              </m:msub>

                              <m:mo>=</m:mo>

                              <m:mrow>
                                <m:mrow>
                                  <m:mi>τ</m:mi>

                                  <m:mo>+</m:mo>

                                  <m:mfrac>
                                    <m:mi>α</m:mi>

                                    <m:mi>κ</m:mi>
                                  </m:mfrac>
                                </m:mrow>

                                <m:mrow>
                                  <m:mo>[</m:mo>

                                  <m:mrow>
                                    <m:mi>1</m:mi>

                                    <m:mo>-</m:mo>

                                    <m:mrow>
                                      <m:mo>Γ(</m:mo>

                                      <m:mrow>
                                        <m:mi>1</m:mi>

                                        <m:mo>+</m:mo>

                                        <m:mi>κ</m:mi>
                                      </m:mrow>

                                      <m:mo>)</m:mo>
                                    </m:mrow>
                                  </m:mrow>

                                  <m:mo>]</m:mo>
                                </m:mrow>

                                <m:mrow>
                                  <m:msub>
                                    <m:mi>λ</m:mi>

                                    <m:mi>2</m:mi>
                                  </m:msub>

                                  <m:mo>=</m:mo>

                                  <m:mfrac>
                                    <m:mi>α</m:mi>

                                    <m:mi>κ</m:mi>
                                  </m:mfrac>
                                </m:mrow>

                                <m:mi>Γ</m:mi>

                                <m:mrow>
                                  <m:mrow>
                                    <m:mo>(1</m:mo>

                                    <m:mrow>
                                      <m:mo>+</m:mo>

                                      <m:mi>κ</m:mi>
                                    </m:mrow>

                                    <m:mo>)</m:mo>
                                  </m:mrow>

                                  <m:mrow>
                                    <m:mo>[</m:mo>

                                    <m:mrow>
                                      <m:mi>1</m:mi>

                                      <m:mo>-</m:mo>

                                      <m:msup>
                                        <m:mi>2</m:mi>

                                        <m:mi>-κ</m:mi>
                                      </m:msup>
                                    </m:mrow>

                                    <m:mo>]</m:mo>
                                  </m:mrow>
                                </m:mrow>
                              </m:mrow>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>

                        <m:mtr>
                          <m:mtd>
                            <m:mrow>
                              <m:msub>
                                <m:mi>τ</m:mi>

                                <m:mi>3</m:mi>
                              </m:msub>

                              <m:mo>=</m:mo>

                              <m:mrow>
                                <m:mfrac>
                                  <m:mrow>
                                    <m:mo>2(</m:mo>

                                    <m:mrow>
                                      <m:mi>1</m:mi>

                                      <m:mo>-</m:mo>

                                      <m:msup>
                                        <m:mi>3</m:mi>

                                        <m:mi>-κ</m:mi>
                                      </m:msup>
                                    </m:mrow>

                                    <m:mo>)</m:mo>
                                  </m:mrow>

                                  <m:mrow>
                                    <m:mi>1</m:mi>

                                    <m:mo>-</m:mo>

                                    <m:msup>
                                      <m:mi>2</m:mi>

                                      <m:mi>-κ</m:mi>
                                    </m:msup>
                                  </m:mrow>
                                </m:mfrac>

                                <m:mo>-3</m:mo>

                                <m:mrow>
                                  <m:msub>
                                    <m:mi>τ</m:mi>

                                    <m:mi>4</m:mi>
                                  </m:msub>

                                  <m:mo>=</m:mo>

                                  <m:mfrac>
                                    <m:mrow>
                                      <m:mi>1-5(</m:mi>

                                      <m:msup>
                                        <m:mi>4</m:mi>

                                        <m:mi>-κ</m:mi>
                                      </m:msup>

                                      <m:mi>)+10(</m:mi>

                                      <m:msup>
                                        <m:mi>3</m:mi>

                                        <m:mi>-κ</m:mi>
                                      </m:msup>

                                      <m:mrow>
                                        <m:mi>)</m:mi>

                                        <m:mo>- 6(</m:mo>

                                        <m:msup>
                                          <m:mi>2</m:mi>

                                          <m:mi>-κ</m:mi>
                                        </m:msup>

                                        <m:mo>)</m:mo>
                                      </m:mrow>
                                    </m:mrow>

                                    <m:mrow>
                                      <m:mi>1</m:mi>

                                      <m:mo>-</m:mo>

                                      <m:msup>
                                        <m:mi>2</m:mi>

                                        <m:mi>-κ</m:mi>
                                      </m:msup>
                                    </m:mrow>
                                  </m:mfrac>
                                </m:mrow>

                                <m:mo>,</m:mo>

                                <m:mi>κ</m:mi>

                                <m:mo>≠</m:mo>

                                <m:mi>0</m:mi>
                              </m:mrow>
                            </m:mrow>
                          </m:mtd>
                        </m:mtr>
                      </m:mtable>
                    </m:math>
                  </inlineequation></entry>
              </row>

              <row>
                <entry>Gumbel</entry>

                <entry><inlineequation>
                    <m:math display="inline">
                      <m:mrow>
                        <m:mrow>
                          <m:msub>
                            <m:mi>λ</m:mi>

                            <m:mi>1</m:mi>
                          </m:msub>

                          <m:mo>=</m:mo>

                          <m:mi>τ+0.5772α</m:mi>
                        </m:mrow>

                        <m:mrow>
                          <m:msub>
                            <m:mi>λ</m:mi>

                            <m:mi>2</m:mi>
                          </m:msub>

                          <m:mo>=</m:mo>

                          <m:mi>α</m:mi>
                        </m:mrow>

                        <m:msub>
                          <m:mi>log</m:mi>

                          <m:mi>e</m:mi>
                        </m:msub>

                        <m:mi>2</m:mi>

                        <m:mrow>
                          <m:msub>
                            <m:mi>τ</m:mi>

                            <m:mi>3</m:mi>
                          </m:msub>

                          <m:mo>=</m:mo>

                          <m:mi>0.1699</m:mi>
                        </m:mrow>

                        <m:mrow>
                          <m:mrow>
                            <m:msub>
                              <m:mi>τ</m:mi>

                              <m:mi>4</m:mi>
                            </m:msub>

                            <m:mo>=</m:mo>

                            <m:mi>0.1504</m:mi>
                          </m:mrow>
                        </m:mrow>
                      </m:mrow>
                    </m:math>
                  </inlineequation></entry>
              </row>

              <row>
                <entry>Generalized Pareto</entry>

                <entry><inlineequation>
                    <m:math display="inline">
                      <m:mrow>
                        <m:mrow>
                          <m:msub>
                            <m:mi>λ</m:mi>

                            <m:mi>1</m:mi>
                          </m:msub>

                          <m:mo>=</m:mo>

                          <m:msub>
                            <m:mi>q</m:mi>

                            <m:mi>*</m:mi>
                          </m:msub>
                        </m:mrow>

                        <m:mo>+</m:mo>

                        <m:mfrac>
                          <m:mi>β</m:mi>

                          <m:mi>1+κ</m:mi>
                        </m:mfrac>

                        <m:mo/>

                        <m:mrow>
                          <m:msub>
                            <m:mi>λ</m:mi>

                            <m:mi>2</m:mi>
                          </m:msub>

                          <m:mo>=</m:mo>

                          <m:mfrac>
                            <m:mi>β</m:mi>

                            <m:mrow>
                              <m:mi>(1+κ)(2+κ)</m:mi>
                            </m:mrow>
                          </m:mfrac>
                        </m:mrow>

                        <m:mrow>
                          <m:mrow>
                            <m:msub>
                              <m:mi>τ</m:mi>

                              <m:mi>3</m:mi>
                            </m:msub>

                            <m:mo>=</m:mo>

                            <m:mfrac>
                              <m:mi>1-κ</m:mi>

                              <m:mi>3+κ</m:mi>
                            </m:mfrac>
                          </m:mrow>

                          <m:mi/>

                          <m:mrow>
                            <m:msub>
                              <m:mi>τ</m:mi>

                              <m:mi>4</m:mi>
                            </m:msub>

                            <m:mo>=</m:mo>

                            <m:mfrac>
                              <m:mi>(1-κ)(2-κ)</m:mi>

                              <m:mi>(3+κ)(4+κ)</m:mi>
                            </m:mfrac>
                          </m:mrow>
                        </m:mrow>
                      </m:mrow>
                    </m:math>
                  </inlineequation></entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>

        <para>Table 3. L moments for several distributions (from Stedinger et
        al., 1993)</para>
      </section>

      <section>
        <title>L-moments estimates for gauged data sample data</title>

        <para>The traditional L moment estimator is based on probability
        weighted moments. However, Wang (1996) derived the following sample
        estimators directly from the definition of the first four
        L-moments:</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:msub>
                <m:mi>λ</m:mi>

                <m:mi>1</m:mi>
              </m:msub>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:mfrac>
                  <m:mi>1</m:mi>

                  <m:msubsup>
                    <m:mi>C</m:mi>

                    <m:mi>1</m:mi>

                    <m:mi>n</m:mi>
                  </m:msubsup>
                </m:mfrac>

                <m:mrow>
                  <m:munderover>
                    <m:mo>∑</m:mo>

                    <m:mi>i=1</m:mi>

                    <m:mi>n</m:mi>
                  </m:munderover>

                  <m:msub>
                    <m:mi>q</m:mi>

                    <m:mi>(i)</m:mi>
                  </m:msub>
                </m:mrow>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:msub>
                <m:mi>λ</m:mi>

                <m:mi>2</m:mi>
              </m:msub>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:mfrac>
                  <m:mi>1</m:mi>

                  <m:mi>2</m:mi>
                </m:mfrac>

                <m:mfrac>
                  <m:mi>1</m:mi>

                  <m:msubsup>
                    <m:mi>C</m:mi>

                    <m:mi>2</m:mi>

                    <m:mi>n</m:mi>
                  </m:msubsup>
                </m:mfrac>

                <m:mrow>
                  <m:munderover>
                    <m:mo>∑</m:mo>

                    <m:mi>i=1</m:mi>

                    <m:mi>n</m:mi>
                  </m:munderover>

                  <m:mrow>
                    <m:mo>(</m:mo>

                    <m:mrow>
                      <m:msubsup>
                        <m:mi>C</m:mi>

                        <m:mi>1</m:mi>

                        <m:mi>i-1</m:mi>
                      </m:msubsup>

                      <m:mo>-</m:mo>

                      <m:msubsup>
                        <m:mi>C</m:mi>

                        <m:mi>1</m:mi>

                        <m:mi>n-i</m:mi>
                      </m:msubsup>
                    </m:mrow>

                    <m:mo>)</m:mo>
                  </m:mrow>
                </m:mrow>

                <m:msub>
                  <m:mi>q</m:mi>

                  <m:mi>(i)</m:mi>
                </m:msub>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:msub>
                <m:mi>λ</m:mi>

                <m:mi>3</m:mi>
              </m:msub>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:mfrac>
                  <m:mi>1</m:mi>

                  <m:mi>3</m:mi>
                </m:mfrac>

                <m:mfrac>
                  <m:mi>1</m:mi>

                  <m:msubsup>
                    <m:mi>C</m:mi>

                    <m:mi>3</m:mi>

                    <m:mi>n</m:mi>
                  </m:msubsup>
                </m:mfrac>

                <m:mrow>
                  <m:mrow>
                    <m:munderover>
                      <m:mo>∑</m:mo>

                      <m:mi>i=1</m:mi>

                      <m:mi>n</m:mi>
                    </m:munderover>

                    <m:mrow>
                      <m:mo>(</m:mo>

                      <m:mrow>
                        <m:msubsup>
                          <m:mi>C</m:mi>

                          <m:mi>2</m:mi>

                          <m:mi>i-1</m:mi>
                        </m:msubsup>

                        <m:mo>-</m:mo>

                        <m:mrow>
                          <m:msubsup>
                            <m:mi>2C</m:mi>

                            <m:mi>1</m:mi>

                            <m:mi>i-1</m:mi>
                          </m:msubsup>

                          <m:mrow>
                            <m:msubsup>
                              <m:mi>C</m:mi>

                              <m:mi>1</m:mi>

                              <m:mi>n-i</m:mi>
                            </m:msubsup>

                            <m:mo>+</m:mo>

                            <m:msubsup>
                              <m:mi>C</m:mi>

                              <m:mi>2</m:mi>

                              <m:mi>n-i</m:mi>
                            </m:msubsup>
                          </m:mrow>
                        </m:mrow>
                      </m:mrow>

                      <m:mo>)</m:mo>
                    </m:mrow>
                  </m:mrow>

                  <m:msub>
                    <m:mi>q</m:mi>

                    <m:mi>(i)</m:mi>
                  </m:msub>
                </m:mrow>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:msub>
                <m:mi>λ</m:mi>

                <m:mi>4</m:mi>
              </m:msub>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:mfrac>
                  <m:mi>1</m:mi>

                  <m:mi>4</m:mi>
                </m:mfrac>

                <m:mfrac>
                  <m:mi>1</m:mi>

                  <m:msubsup>
                    <m:mi>C</m:mi>

                    <m:mi>4</m:mi>

                    <m:mi>n</m:mi>
                  </m:msubsup>
                </m:mfrac>

                <m:mrow>
                  <m:munderover>
                    <m:mo>∑</m:mo>

                    <m:mi>i=1</m:mi>

                    <m:mi>n</m:mi>
                  </m:munderover>

                  <m:mrow>
                    <m:mo>(</m:mo>

                    <m:mrow>
                      <m:msubsup>
                        <m:mi>C</m:mi>

                        <m:mi>3</m:mi>

                        <m:mi>i-1</m:mi>
                      </m:msubsup>

                      <m:mo>-</m:mo>

                      <m:mrow>
                        <m:msubsup>
                          <m:mi>3C</m:mi>

                          <m:mi>2</m:mi>

                          <m:mi>i-1</m:mi>
                        </m:msubsup>

                        <m:mrow>
                          <m:msubsup>
                            <m:mi>C</m:mi>

                            <m:mi>1</m:mi>

                            <m:mi>n-i</m:mi>
                          </m:msubsup>

                          <m:mo>+</m:mo>

                          <m:mrow>
                            <m:msubsup>
                              <m:mi>3C</m:mi>

                              <m:mi>1</m:mi>

                              <m:mi>i-1</m:mi>
                            </m:msubsup>

                            <m:mrow>
                              <m:msubsup>
                                <m:mi>C</m:mi>

                                <m:mi>2</m:mi>

                                <m:mi>n-i</m:mi>
                              </m:msubsup>

                              <m:mo>-</m:mo>

                              <m:msubsup>
                                <m:mi>C</m:mi>

                                <m:mi>3</m:mi>

                                <m:mi>n-i</m:mi>
                              </m:msubsup>
                            </m:mrow>
                          </m:mrow>
                        </m:mrow>
                      </m:mrow>
                    </m:mrow>

                    <m:mo>)</m:mo>
                  </m:mrow>
                </m:mrow>

                <m:msub>
                  <m:mi>q</m:mi>

                  <m:mi>(i)</m:mi>
                </m:msub>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <para>where q<subscript>(i)</subscript>, i=1,2,..,n are gauged peak
        flows ranked in ascending order and</para>

        <equation>
          <m:math display="block">
            <m:mrow>
              <m:msubsup>
                <m:mi>C</m:mi>

                <m:mi>k</m:mi>

                <m:mi>m</m:mi>
              </m:msubsup>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:mo>{</m:mo>

                <m:mtable>
                  <m:mtr>
                    <m:mtd>
                      <m:mrow>
                        <m:mfrac>
                          <m:mi>m!</m:mi>

                          <m:mi>k!(m-k)!</m:mi>
                        </m:mfrac>

                        <m:mo>if k≤m</m:mo>
                      </m:mrow>
                    </m:mtd>
                  </m:mtr>

                  <m:mtr>
                    <m:mtd>
                      <m:mrow>
                        <m:mi>0 if k&gt;m</m:mi>
                      </m:mrow>
                    </m:mtd>
                  </m:mtr>
                </m:mtable>
              </m:mrow>
            </m:mrow>
          </m:math>
        </equation>

        <para>is the number of combinations of any k items from m
        items.</para>
      </section>

      <section>
        <title>Parameter and quantile estimation</title>

        <para>The method of L moments involves matching theoretical and sample
        L moments to estimate parameters. The L moments in Table 3 are
        replaced by their sample estimates given by eqn (44). The resulting
        equations are then solved to obtain estimates of the parameters. These
        parameters are used to calculate the 1-in-Y AEP quantiles.</para>
      </section>

      <section>
        <title>LH-moments for fitting the GEV distribution</title>

        <para>When the selected probability model does not adequately fit all
        the gauged data the lower flows may exert undue influence on the fit
        and give insufficient weight to the higher flows which are the
        principal object of interest. To deal with this situation Wang (1997)
        introduced a generalization of L moments called LH moments. A more
        detailed exposition can be found in Box 6.</para>
      </section>

      <section>
        <title>Parameter Uncertainty and Quantile Confidence Limits</title>

        <para>The sampling distribution p(θ|D) can be approximated using the
        Monte Carlo method known as the parametric bootstrap described in Box
        7. This procedure yields N equi-weighted samples that approximate the
        sampling distribution p(θ|D). As a result, they can be used to
        quantify parameter uncertainty and estimate quantile confidence
        limits. However, because the parametric bootstrap assumes θ is the
        true parameter, it underestimates the uncertainty and therefore should
        not be used to estimate expected probabilities.</para>
      </section>

      <section>
        <title>Software</title>

        <para>Implementation of L and LH moments requires extensive
        computation. The web-based software called TUFLOW FLIKE supports L and
        LH moment estimation is available at www.xxx.com.au. An extensive
        library of FORTRAN L moment procedures can be found at
        www.research.ibm.com/people/h/hosking.</para>
      </section>

      <section>
        <title>Worked Examples</title>

        <para>Example 9 illustrates fitting the GEV distribution using L
        moments to a 47-year gauged record. Example 10 revisits Example 7
        demonstrating the search procedure for finding the optimal shift in LH
        moments fitting.</para>
      </section>
    </section>

    <section>
      <title>Method of Moments Approach</title>

      <para>The method of moments used in conjunction with the LP3
      distribution was the recommended method in Australian Rainfall and
      Runoff (1987). The method was simple to implement but, unlike US
      practice, did not use regionalized skew. Its use is no longer
      recommended. Both the Bayesian and L moment procedures make better use
      of the available information.</para>
    </section>
  </section>

  <section>
    <title>FITTING FLOOD PROBABILITY MODELS TO POT SERIES</title>

    <section>
      <title>Probability Plots</title>

      <para>As with the analysis of annual maximum series it is recommended
      that a probability plot of the POT data series be prepared. The plot
      involves plotting an estimate of the observed ARI against the discharge.
      The ARI of a gauged flood can be estimated using</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:msub>
              <m:mi>T</m:mi>

              <m:mi>(i)</m:mi>
            </m:msub>

            <m:mo>=</m:mo>

            <m:mfrac>
              <m:mrow>
                <m:mi>n</m:mi>

                <m:mo>+</m:mo>

                <m:mi>0.2</m:mi>
              </m:mrow>

              <m:mrow>
                <m:mi>i</m:mi>

                <m:mo>-</m:mo>

                <m:mi>0.4</m:mi>
              </m:mrow>
            </m:mfrac>
          </m:mrow>
        </m:math>
      </equation>

      <para>where i is the rank of the gauged flood (in descending order) and
      n is the number of years of record.</para>
    </section>

    <section>
      <title>Fitting POT Models</title>

      <para>In some cases, it may be desirable to analytically fit a
      probability distribution to POT data. Two general approaches have been
      used.</para>

      <para>In the first, the annual flow series distribution has been
      estimated from the POT series on the basis that the latter considers all
      of the relevant data and should thus provide a better estimate. The
      basis for the procedure is eqn (5) which links Poisson arrivals of flood
      peaks with a distribution of flood magnitudes above some threshold.
      Jayasuriya and Mein (1985), Ashkar and Rousselle (1983) and Tavares and
      da Silva (1983) explored this approach using the exponential
      distribution. The approach has been fairly successful, but some results
      have diverged from the distribution derived directly from the annual
      series. At this stage, the approach cannot be recommended as a
      replacement for the analysis of annual series data. If possible, the
      base discharge for this approach should be selected so that the number
      of floods in the POT series K is at least 2 to 3 times the number of
      years of record N. However, it may be necessary to use a much lower
      value of K in regions with low rainfall where the number of recorded
      events that could be considered as floods is low.</para>

      <para>The second approach uses a probability distribution as an
      arbitrary means of providing a consistent and objective fit to POT
      series data. For example, McDermott and Pilgrim (1982), Adams and
      McMahon (1985) and Jayasuriya and Mein 1985) used the LP3 distribution –
      they found that selecting a threshold discharge such that K equalled N
      was best. Example 11 illustrates this approach using L moments to fit an
      exponential distribution to a POT series.</para>
    </section>
  </section>

  <section>
    <title>REFERENCES</title>

    <para>Adams, C.A. (1987) Design flood estimation for ungauged rural
    catchments in Victoria Road Construction Authority, Victoria. Draft
    Technical Bulletin.</para>

    <para>Adams, C.A. and McMahon, T.A. (1985) Estimation of flood discharge
    for ungauged rural catchments in Victoria. Hydrol. and Water Resources
    Symposium 1985, Inst Engrs Aust., Natl Conf. Publ. No. 85/2, pp.
    86-90.</para>

    <para>Alexander, G.N. (1957) Flood flow estimation, probability and the
    return period. Jour. Inst. Engrs Aust, Vol. 29, pp. 263-278.</para>

    <para>Allan, R.J. (2000) ENSO and climatic variability in the last 150
    years, in El Nino and the Southern Oscillation, Multi-scale variability,
    Global and Regional Impacts, edited by H.F. Diaz and V. Markgraf,
    Cambridge University Press, Cambridge, uk, p3-56.</para>

    <para>American Society of Civil Engineers (1949) Hydrology Handbook</para>

    <para>Ashkanasy, N.M. and Weeks, W.D. (1975) Flood frequency distribution
    in a catchment subject to two storm rainfall producing mechanisms. Hydrol.
    Symposium 1975, Inst Engrs Aust, Natl Conf. Publ. No. 75/3, pp.
    153-157.</para>

    <para>Ashkar, F. and Rousselle, J. (1983) Some remarks on the truncation
    used in partial flood series models. Water Resources Research, Vol. 19,
    pp. 477-480.</para>

    <para>Australian Rainfall and Runoff: A guide to flood estimation (1987)
    Pilgrim, D.H. (ed), The Institution of Engineers, Australia,
    Canberra.</para>

    <para>Baker, V. (1984) Recent paleoflood hydrology studies in arid and
    semi-arid environments (abstract). EOS Trans. Amer. Geophys. Union, Vol.
    65, p. 893.</para>

    <para>Baker, V., Pickup, G. and Polach, H.A. (1983) Desert paleofloods in
    central Australia. Nature, Vol. 301, pp. 502-504.</para>

    <para>Beard, L.R (1960) Probability estimates based in small
    normal-distribution samples. Jour. of Geophysical Research, Vol.65, pp.
    2143-2148.</para>

    <para>Beard, L.R (1974) Flood flow frequency techniques Univ. of Texas at
    Austin, Center for Research in Water Resources, Tech. Report CRWR119,
    October.</para>

    <para>Beran, M., Hosking, J.RM. and Arnell, N. (1986) Comment on
    "Two-component extreme value distribution for flood frequency analysis."
    Water Resources Research Vol.22, pp. 263-266.</para>

    <para>Blom, G. (1958) Statistical Estimates and Transformed
    Beta-Variables. Wiley, New York, 176 p.</para>

    <para>Clarke-Hafstad, K. (1942) Reliability of station-year
    rainfall-frequency determinations. Trans. Amer. Soc. Civ. Engrs, Vol.107,
    pp. 633-652.</para>

    <para>Cohn, T. A., England, J.F., Berenbrock, C.E., Mason, R.R.,
    Stedinger, J.R. and Lamontagne, J.R. (2013), A generalized Grubbs-Beck
    test statistic for detecting multiple potentially influential low outliers
    in flood series, Water Resour. Res., 49, 5047–5058,
    doi:10.1002/wrcr.20392.</para>

    <para>Conway, K.M. (1970) Flood frequency analysis of some N.S.W. coastal
    rivers. Thesis (M.Eng Sc.), Univ.NSW.</para>

    <para>Costa, J.E. (1978) Holocene stratigraphy in flood frequency
    analysis. Water Resources Research, Vol.14, pp. 626-632.</para>

    <para>Costa, J.E. (1983) Palaeohydraulic reconstruction or flashflood
    peaks from boulder deposits in the Colorado Front Range. Geol. Soc.
    America Bulletin, Vol. 94, AP. 986-1004.</para>

    <para>Costa, J.E. (1986) A history of paleoflood hydrology in the United
    States, 1800-1970. EOS Trans. Aoler Geophysical Union, Vol. 67, No. 17,
    pp. 425-430.</para>

    <para>Cunnane, C. (1978) Unbiased plotting positions - a review. Jour. of
    Hydrology, Vol. 37, pp. 205-222.</para>

    <para>Cunnane, C. (1985) Factors affecting choice of distribution for
    flood series. Hydrological Sciences Journal, Vol. 30, pp. 25-36.</para>

    <para>Dalrymple, T. (1960) Flood-frequency analyses. Manual of Hydrology:
    Section 3. Flood-flow Techniques. U.S. Geological Survey Water Supply
    Paper 1543-A, 79 p.</para>

    <para>DeGroot, M.H., Optimal statistcal decisions, McGraw-Hill,
    1970.</para>

    <para>Doran, D.G. and Irish, J.L. (1980) On the nature and extent of bias
    in flood damage estimation. Hydrol. and Water Resources Symposium 1980,
    Inst. Engrs Aust, Natl Conf. Publ. No. 80/9, pp. 135-139.</para>

    <para>Duan, Q., Sorooshian, S. and V. Gupta, Effective and efficient
    global optimization for conceptual rainfall-runoff models, Water Resources
    Research, 28(4), 1015-1031, 1992.</para>

    <para>Erskine, W. D., and Warner, R.F. (1988), Geomorphic effects of
    alternating flood and drought dominated regimes on a NSW coastal river, in
    Fluvial Geomorphology of Australia, edited by R.F. Warner, pp. 223-244,
    Academic Press, Sydney.</para>

    <para>Fiering, M.B. (1963) Use of correlation to improve estimates of the
    mean and variance. U.S. Geological estimates of the mean and variance.
    U.S. Geological Survey Professional Paper 434-C.</para>

    <para>Fiorentino, M., Versace, P. and Rossi, F. (1985) Regional flood
    frequency estimation using the two-component extreme value distribution.
    Hydrol. Sciences Jour., Vol. 30, pp. 51-64.</para>

    <para>Flavell, D.J. (1983) The Rational Method applied to small rural
    catchments in the south west of Western Australia Civ. Engg Trans., Inst.
    Engrs Aust., Vol. CE25, pp. 121-127.</para>

    <para>Folland, C. K., Renwick, J.A., Salinger, M.J. and Mullan, A.B.
    (2002), Relative influences of the Interdecadal Pacific Oscillation and
    ENSO on the South Pacific Convergence Zone, Geophys. Res. Lett., 29(13),
    doi:10.1029/2001GL014201.</para>

    <para>Franks, S.W. and Kuczera, G. (2002) Flood Frequency Analysis:
    Evidence and Implications of Secular Climate Variability, New South Wales,
    Water Resources Research, 38(5), 10.1029/2001WR000232.</para>

    <para>Franks, S.W. (2002a), Identification of a change in climate state
    using regional flood data, Hydrol. Earth Sys. Sci., 6(1), 11-16.</para>

    <para>Franks, S.W. (2002b), Assessing hydrological change: deterministic
    general circulation models or spurious solar correlation? Hydrol. Proc.,
    16, 559-564.</para>

    <para>Gelman, A., Carlin, J.B., Stren, H.S. and Rubin, D.B. (1997)
    Bayesian data analysis, Chapman and Hall, p.526.</para>

    <para>Hosking, J.R.M. (1990) L-moments: Analysis and estimation of
    distributions using linear combinations of order statistics, J. Roy.
    Statist. Soc., Ser. B 52(2), 105-124.</para>

    <para>Hosking, J.R.M. and Wallis, J.R (1986) Paleoflood hydrology and
    flood frequency analysis. Water Resources Research, Vol. 22, pp.
    543-550.</para>

    <para>Houghton, J.C. (1978) Birth of a parent: The Wakeby distribution for
    modeling flood flows. Water Resources Research, Vol. 14, pp.
    1105-1109.</para>

    <para>Interagency Advisory Committee on Water Data (1982) Guidelines for
    determining flood flow frequency. Bulletin 17B of the Hydrology
    Sub-committee, Office of Water Data Coordination, Geological Survey, U.S.
    Dept of the Interior.</para>

    <para>Jayasuriya, M.D.A. and Mein, RG. (1985) Frequency analysis using the
    partial series. Hydrol. and Water Resources Symposium 1985, Inst. Engrs
    Aust., Natl Conf. Publ. No. 85/2, pp. 81-85.</para>

    <para>Kiem, A. S., and Franks, S.W. (2004) Multidecadal variability of
    drought risk - eastern Australia, Hydrol. Proc., 18,
    doi:10.1002/hyp.1460.</para>

    <para>Kiem, A.S., Franks, S.W. and Kuczera, G. (2003) Multi-decadal
    variability of flood risk, Geophysical Research Letters, 30(2), 1035,
    DOI:10.1029/2002GL015992.</para>

    <para>Kochel. RC., Baker, V.R and Patton, P.C. (1982) Paleohydrology of
    southwestern Texas. Water Resources Research, Vol. 18, pp.
    1165-1183.</para>

    <para>Kopittke, RA., Stewart, B.J. and Tickle, K.S. (1976) Frequency
    analysis of flood data in Queensland. Hydrol. Symposium 1976, Inst Engrs
    Aust., Natl Conf. Publ. No. 76/2, pp. 20-24.</para>

    <para>Kuczera, G., Correlated rating curve error in flood frequency
    inference, Water Resources Research, 32(7), 2119-2128, 1996.</para>

    <para>Kuczera, G. (1999) Comprehensive at-site flood frequency analysis
    using Monte Carlo Bayesian inference, Water Resources Research, 35(5),
    1551-1558.</para>

    <para>Kuczera, G., Lambert, M.F., Heneker, T. Jennings, S., Frost, A. and
    Coombes, P. (2006) Joint probability and design storms at the crossroads,
    Australian Journal of Water Resources, 10(2), 5-21.</para>

    <para>Lee, P.M. (1989) Bayesian statistics: An introduction, Oxford
    University Press (NY).</para>

    <para>Laurenson, E.M. (1987) Back to basics on flood frequency analysis.
    Civ. Engg Trans., Inst Engrs Aust, Vol. CE29, pp. 47-53.</para>

    <para>Mantua, N. J., S. R. Hare, Y. Zhang, J. M. Wallace, and R. C.
    Francis (1997), A Pacific interdecadal climate oscillation with impacts on
    salmon production, Bull. Amer. Meteorol. Soc., 78(6), 1069-1079.</para>

    <para>Matalas, N.C. and Jacobs, B. (1964) A correlation procedure for
    augmenting hydrologic data. U. S. Geological Survey Professional Paper
    434-E.</para>

    <para>McDermott, G.E. and Pilgrim, D. H. (1982) Design flood estimation
    for small catchments in New South Wales. Dept of National Development and
    Energy, Aust Water Resources Council Tech. Paper No. 73, 233 p.</para>

    <para>McDermott, G.E. and Pilgrim, D.H. (1983) A design flood method for
    arid western New South Wales based on bankfull estimates. Civ. Engg
    Trans., Inst Engrs Aust, Vol. CE25, pp. 114-120.</para>

    <para>McIllwraith, J.F. (1953) Rainfall intensity-frequency data for New
    South Wales stations. Jour. Inst Engrs Aust, Vol. 25, pp. 133-139.</para>

    <para>McMahon, T.A. (1979) Hydrologic characteristics of Australian
    streams. Civ. Engg Research Reports, Monash Univ., Report No.
    3/1979.</para>

    <para>McMahon, T.A. and Srikanthan, R (1981) Log Pearson III distribution-
    is it applicable to flood frequency analysis of Australian streams? Jour.
    of Hydrology, Vol.52, pp. 139-147.</para>

    <para>Micevski, T., Kiem, A.S., Franks, S.W. and Kuczera, G. (2003)
    Multidecadal Variability in New South Wales Flood Data, Hydrology and
    Water Resources Symposium, Institution of Engineers, Australia,
    Wollongong.</para>

    <para>Natural Environment Research Council (1975) Flood Studies Report,
    Vol. 1, Hydrological Studies. London</para>

    <para>O’Connell, D.R., Ostemaa, D.A., Levish, D.R. and Klinger, R.E.
    (2002) Bayesian flood frequency analysis with paleohydrologic bound data,
    Water Resources Research, 38(5), 1058, DOI:10.1029/2000WRR000028.</para>

    <para>Pedruco, P., Nielsen, C., Kuczera, G. and Rahman, A. (2014)
    Combining regional flood frequency estimates with an at site flood
    frequency analysis using a Bayesian framework: Practical considerations,
    Hydrology and Water Resources Symp., Perth, Engineers Australia.</para>

    <para>Pilgrim, D.H. and Doran, D.G. (1987) Flood frequency analysis, in
    Australian Rainfall and Runoff: A guide to flood estimation, Pilgrim, D.H.
    (ed), The Institution of Engineers, Australia, Canberra.</para>

    <para>Pilgrim, D.H. and McDermott, G.E. (1982) Design floods for small
    rural catchments in eastern New South Wales. Civ. Engg Trans., Inst Engrs
    Aust., Vol. CE24, pp. 226-234.</para>

    <para>Potter, D.J. and Pilgrim, D.H. (1971) Flood estimation using a
    regional flood frequency approach. Final Report, Vol. 2, Report on
    Analysis Components. Aust. Water Resources Council, Research Project 68/1,
    Hydrology of Small Rural Catchments. Snowy Mountains Engg Corporation,
    April.</para>

    <para>Potter, K.W. and Walker, J.F. (1981) A model of discontinuous
    measurement error and its effects on the probability distribution of flood
    discharge measurements, Water Resources Research, 17(5), 1505-1509.</para>

    <para>Potter, K.W. and Walker, J.F. (1985) An empirical study of flood
    measurement error, Water Resources. Research, 21(3), 403-406.</para>

    <para>Power, S., F. Tseitkin, S. Torok, B. Lavery, R. Dahni, and B.
    McAvaney (1998), Australian temperature, Australian rainfall and the
    Southern Oscillation, 1910-1992: coherent variability and recent changes,
    Aust. Met. Mag., 47(2), 85-101.</para>

    <para>Power, S., T. Casey, C. Folland, A. Colman, and V. Mehta (1999),
    Inter-decadal modulation of the impact of ENSO on Australia, Climate
    Dynamics,15(5), 319-324.</para>

    <para>Rossi, F., Fiorentino, M. and Versace, P. (1984) Two-component
    extreme value distribution for flood frequency analysis. Water Resources
    Research, Vol.20, pp.847-856.</para>

    <para>Slack, J.R., Wallis, J.R. and Matalas, N.C. (1975) On the value of
    information in flood frequency analysis, , Water Resources. Research,
    11(5), 629-648.</para>

    <para>Stedinger, J.R. (1983) Design events with specified flood risk,
    Water Resources Research, 19(2), 511-522.</para>

    <para>Stedinger, J.R., Vogel, R.M. and Foufoula-Georgiou, E. (1993)
    Frequency analysis of extreme events in Handbook of Hydrology, Maidment,
    D.R. (ed.), McGraw-Hill, NY.</para>

    <para>Stedinger, J.R and Cohn, T.A. (1986) Flood frequency analysis with
    historical and paleoflood information. Water Resources Research, Vol. 22,
    pp. 785-793.</para>

    <para>Tavares, L.V. and da Silva, J.E. (1983) Partial series method
    revisited. Jour. of Hydrology, Vol. 64, pp. 1-14.</para>

    <para>Wallis, J.R and Wood, E.F. (1985) Relative accuracy log Pearson III
    procedures. Proc. Amer. Soc. Civ. Engrs. Jour. of Hydraulic Engg, Vol.
    lll, No.7, pp.1043-10</para>

    <para>Wang, Q. J. (1996) Direct sample estimators of L-moments, Water
    Resources Research, 32(12), 3617-3619, 1996.</para>

    <para>Wang, Q. J. (1997) LH moments for statistical analysis of extreme
    events, Water Resources Research, 33(12), 2841-2848.</para>

    <para>Wang, Q. J. (1998) Approximate goodness-of-fit tests of fitted
    generalized extreme value distributions using LH moments, Water Resources
    Research, 34(12), 3497-3502.</para>

    <para>Wang, Q.J. (2001) A Bayesian joint probability approach for flood
    record augmentation, Water Resources Research, 37(6), pp.
    1707-1712.</para>
  </section>

  <section>
    <title>SUPPLEMENTARY INFORMATION Box 1: Theory of Peak-Over-Threshold and
    Annual Maximum Series</title>

    <section>
      <title>Annual exceedance probability AEP</title>

      <para>The objective is to derive the distribution of the maximum flood
      peak within a specified interval of time. Referring to the continuous
      streamflow times series Figure B1-1, let the random variable q be a
      local peak discharge defined as a discharge which has lower discharge on
      either side of the peak. This presents an immediate problem as any bump
      on the hydrograph would produce a local peak. To circumvent this problem
      we focus on peaks greater than some threshold defined as
      q<subscript>o</subscript>. The threshold is selected so that the peaks
      above the threshold are sufficiently separated in time to be
      statistically independent of each other.</para>

      <figure>
        <title>Peak-over-threshold series</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureB1_1.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>It is assumed that all peaks above the threshold
      q<subscript>o</subscript> are sampled from the same distribution denoted
      by the pdf p(q|q&gt;q<subscript>o</subscript>).</para>

      <para>Suppose over a time interval of length t years, there are n peaks
      over the threshold q<subscript>o</subscript>. This defines the POT time
      series {q<subscript>1</subscript>,…,q<subscript>n</subscript>} which
      consists of n independent realizations sampled from the pdf
      p(q|q&gt;q<subscript>o</subscript>).</para>

      <para>Let w be the maximum value in the POT time series; that is,</para>

      <para>w = max
      {q<subscript>1</subscript>,…,q<subscript>n</subscript>}</para>

      <para>For w to be the maximum value, each peak within the POT series
      must be less than or equal to w. In probability theory this condition is
      expressed by the compound event consisting of the intersection of the
      following n events</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mrow>
              <m:mo>{</m:mo>

              <m:mrow>
                <m:mrow>
                  <m:mo>(</m:mo>

                  <m:mrow>
                    <m:msub>
                      <m:mi>q</m:mi>

                      <m:mi>1</m:mi>
                    </m:msub>

                    <m:mo>≤ w</m:mo>
                  </m:mrow>

                  <m:mo>)</m:mo>
                </m:mrow>

                <m:mo>⋂</m:mo>

                <m:mrow>
                  <m:mo>(</m:mo>

                  <m:mrow>
                    <m:msub>
                      <m:mi>q</m:mi>

                      <m:mi>2</m:mi>
                    </m:msub>

                    <m:mo>≤ w</m:mo>
                  </m:mrow>

                  <m:mo>)</m:mo>
                </m:mrow>

                <m:mo>⋂</m:mo>

                <m:mi>....</m:mi>

                <m:mo>⋂</m:mo>

                <m:mrow>
                  <m:mo>(</m:mo>

                  <m:mrow>
                    <m:msub>
                      <m:mi>q</m:mi>

                      <m:mi>n</m:mi>
                    </m:msub>

                    <m:mo>≤ w</m:mo>
                  </m:mrow>

                  <m:mo>)</m:mo>
                </m:mrow>
              </m:mrow>

              <m:mo>}</m:mo>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>Because the peaks are assumed to be statistically independent, the
      probability of the compound event is the product of the probabilities of
      the individual events. Therefore the probability that the random
      variable W ≤ w in a POT series with n events occurring over the interval
      t simplifies to</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mrow>
              <m:mi>P(W≤w∣n,T)</m:mi>
            </m:mrow>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mi>P[(</m:mi>

              <m:msub>
                <m:mi>x</m:mi>

                <m:mi>i</m:mi>
              </m:msub>

              <m:mo>≤</m:mo>

              <m:mo>w)</m:mo>

              <m:mrow>
                <m:mo>⋂</m:mo>

                <m:mo>.... ⋂</m:mo>

                <m:mo>(</m:mo>

                <m:msub>
                  <m:mi>q</m:mi>

                  <m:mi>n</m:mi>
                </m:msub>
              </m:mrow>

              <m:mo>≤</m:mo>

              <m:mi>w)]</m:mi>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mo>=</m:mo>

            <m:mrow>
              <m:mi>P(</m:mi>

              <m:msub>
                <m:mi>q</m:mi>

                <m:mi>1</m:mi>
              </m:msub>

              <m:mi>≤w)P(</m:mi>

              <m:msub>
                <m:mi>q</m:mi>

                <m:mi>2</m:mi>
              </m:msub>

              <m:mi>≤</m:mi>

              <m:mo>w)....P(</m:mo>

              <m:mrow>
                <m:msub>
                  <m:mi>q</m:mi>

                  <m:mi>n</m:mi>
                </m:msub>

                <m:mo>≤ w )</m:mo>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mi>=</m:mi>

            <m:mo>P</m:mo>

            <m:mrow>
              <m:mo>(</m:mo>

              <m:mi>q≤w</m:mi>

              <m:mo>)</m:mo>
            </m:mrow>

            <m:mo>ⁿ</m:mo>
          </m:mrow>
        </m:math>
      </equation>

      <para>The number of POT events n occurring over an interval t is random.
      Suppose that the random variable n follows a Poisson distribution with ν
      being the average number of POT events per year; that is,</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mi>P(n|v,t)</m:mi>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mfrac>
                <m:mrow>
                  <m:msup>
                    <m:mi>(vt)</m:mi>

                    <m:mi>n</m:mi>
                  </m:msup>

                  <m:mrow>
                    <m:mi>exp</m:mi>

                    <m:mo>(-vt)</m:mo>
                  </m:mrow>
                </m:mrow>

                <m:mi>n!</m:mi>
              </m:mfrac>

              <m:mo>, n =</m:mo>

              <m:mi>0,1,2....</m:mi>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>Application of the total probability theorem yields the
      distribution of the largest peak magnitude over the time interval with
      length t</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mi>P(W≤w|t)</m:mi>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mrow>
                <m:mrow>
                  <m:munderover>
                    <m:mo>∑</m:mo>

                    <m:mi>n=0</m:mi>

                    <m:mi>∞</m:mi>
                  </m:munderover>

                  <m:mi>P(W≤w|n,t)P(n|v,t)</m:mi>
                </m:mrow>
              </m:mrow>

              <m:mo>=</m:mo>

              <m:mi>exp[-(vt)P(q&gt;w)</m:mi>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>where P(W≤w|t) is the probability that the largest peak over time
      interval t is less than or equal to w. When the time interval t is set
      to one year, eqn (B1-4) defines the distribution of the AM
      series.</para>

      <para>ARR defines annual exceedance probability as</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mi>AEP(w)</m:mi>

            <m:mo>=</m:mo>

            <m:mi>1-P(W≤w| t=1</m:mi>
          </m:mrow>
        </m:math>
      </equation>

      <para>where AEP(w) is the probability of the largest peak in a year
      exceeding magnitude w.</para>
    </section>

    <section>
      <title>Exceedances per year EY</title>

      <para>We now derive the probability distribution of the time to the next
      flood peak which has a magnitude in excess of w. With regard to eqn
      (B1-4), if the largest peak during the interval t is less than or equal
      to w, then the time to the next peak with magnitude in excess of w must
      be greater than t. It therefore follows that the distribution of the
      time to the next peak with magnitude exceeding w is</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mi>P(Time to next peak exceeding w≤t)</m:mi>

            <m:mo>=</m:mo>

            <m:mi>1- exp[-vP(q&gt;w)t]</m:mi>
          </m:mrow>
        </m:math>
      </equation>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mo>=</m:mo>

            <m:mi>1-exp[-EY(w)t]</m:mi>
          </m:mrow>
        </m:math>
      </equation>

      <para>This is recognized as an exponential distribution with parameter
      vP(q&gt;w) which is the expected number of peaks exceeding w per
      year.</para>

      <para>ARR defines this parameter as EY(w) which stands for exceedances
      per year, but more strictly, is the expected number of peaks that exceed
      w in a year.</para>
    </section>

    <section>
      <title>Linking AEP and EY</title>

      <para>If we select a particular peak magnitude w, combining eqns (4),
      (5) and (6) yields the following relationship between EY(w) and
      AEP(w)</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mi>AEP(w)</m:mi>

            <m:mo>=</m:mo>

            <m:mi>1 - P (W≤w | t=1 )</m:mi>
          </m:mrow>
        </m:math>
      </equation>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mo>=</m:mo>

            <m:mi>1- exp[-vP(q&gt;w)]</m:mi>
          </m:mrow>
        </m:math>
      </equation>

      <equation>
        <m:math display="block">
          <m:mi>= 1 - exp[-EY(w)]</m:mi>
        </m:math>
      </equation>

      <para>If we express AEP(w) as 1/Y(w) then eqn (B1-7) can be rewritten
      as</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mi>EY(w)</m:mi>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:msub>
                <m:mi>-log</m:mi>

                <m:mi>e</m:mi>
              </m:msub>

              <m:mo>[1-AEP(w)]</m:mo>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mo>=</m:mo>

            <m:mrow>
              <m:msub>
                <m:mi>-log</m:mi>

                <m:mi>e</m:mi>
              </m:msub>

              <m:mrow>
                <m:mo>[</m:mo>

                <m:mrow>
                  <m:mi>1</m:mi>

                  <m:mo>-</m:mo>

                  <m:mfrac>
                    <m:mi>1</m:mi>

                    <m:mi>Y(w)</m:mi>
                  </m:mfrac>
                </m:mrow>

                <m:mo>]</m:mo>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>This relationship assumes peaks in the POT series are
      statistically independent and that there is no seasonality in the sense
      that the probability density of the POT peak above a threshold
      p(q|q&gt;q<subscript>o</subscript>) does not change over the year. While
      the no-seasonality assumption appears questionable on first inspection,
      in practice the threshold q<subscript>0</subscript> is selected so that
      the expected number of peaks exceeding the threshold
      q<subscript>0</subscript> in any year is of the order of 1. This is done
      to ensure the POT peaks are genuine floods and statistically
      independent. As a consequence of the high threshold selected in
      practice, the impact of seasonality is diminished.</para>
    </section>

    <section>
      <title>Box 2: Formal Definition of Zero-Threshold Mixture
      Distribution</title>

      <para>The zero-threshold mixture model has a distribution
      function</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mi>P(Q≤q|θ)</m:mi>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mo>{</m:mo>

              <m:mtable>
                <m:mtr>
                  <m:mtd>
                    <m:mrow>
                      <m:msub>
                        <m:mi>P</m:mi>

                        <m:mi>0</m:mi>
                      </m:msub>

                      <m:mo>if q =</m:mo>

                      <m:msub>
                        <m:mi>q</m:mi>

                        <m:mi>0</m:mi>
                      </m:msub>
                    </m:mrow>
                  </m:mtd>
                </m:mtr>

                <m:mtr>
                  <m:mtd>
                    <m:mrow>
                      <m:msub>
                        <m:mi>P</m:mi>

                        <m:mi>0</m:mi>
                      </m:msub>

                      <m:mrow>
                        <m:mi>+(1-</m:mi>

                        <m:msub>
                          <m:mi>P</m:mi>

                          <m:mi>0</m:mi>
                        </m:msub>

                        <m:mi>)</m:mi>

                        <m:mfrac>
                          <m:mrow>
                            <m:mi>P(Q≤q∣</m:mi>

                            <m:mo>θ) -</m:mo>

                            <m:mi>P(Q≤</m:mi>

                            <m:msub>
                              <m:mi>q</m:mi>

                              <m:mi>0</m:mi>
                            </m:msub>

                            <m:mi>∣θ)</m:mi>
                          </m:mrow>

                          <m:mrow>
                            <m:mi>P(Q&gt;</m:mi>

                            <m:msub>
                              <m:mi>q</m:mi>

                              <m:mi>0</m:mi>
                            </m:msub>

                            <m:mo>|</m:mo>

                            <m:mi>θ)</m:mi>
                          </m:mrow>
                        </m:mfrac>

                        <m:mrow>
                          <m:mi>if q&gt;</m:mi>

                          <m:msub>
                            <m:mi>q</m:mi>

                            <m:mi>0</m:mi>
                          </m:msub>
                        </m:mrow>
                      </m:mrow>
                    </m:mrow>
                  </m:mtd>
                </m:mtr>
              </m:mtable>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>where q<subscript>0</subscript> is the zero-threshold flow,
      P<subscript>0</subscript> is the probability of the AM peak equaling
      q<subscript>0</subscript> and P(Q≤q|θ) is a probability model such as
      described in Table 1.</para>

      <para>The pdf of the mixture model can be expressed using the
      generalized probability density which allows the random variable to take
      discrete values as well as continuous values</para>

      <equation>
        <m:math display="block">
          <m:mi>P(q|θ)</m:mi>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mo>{</m:mo>

            <m:mtable>
              <m:mtr>
                <m:mtd>
                  <m:mrow>
                    <m:msub>
                      <m:mi>P</m:mi>

                      <m:mi>0</m:mi>
                    </m:msub>

                    <m:mo>if q =</m:mo>

                    <m:msub>
                      <m:mi>q</m:mi>

                      <m:mi>0</m:mi>
                    </m:msub>
                  </m:mrow>
                </m:mtd>
              </m:mtr>

              <m:mtr>
                <m:mtd>
                  <m:mrow>
                    <m:mrow>
                      <m:mfrac>
                        <m:mrow>
                          <m:mi>1</m:mi>

                          <m:mo>-</m:mo>

                          <m:msub>
                            <m:mi>P</m:mi>

                            <m:mi>0</m:mi>
                          </m:msub>
                        </m:mrow>

                        <m:mrow>
                          <m:mi>P(q&gt;</m:mi>

                          <m:msub>
                            <m:mi>q</m:mi>

                            <m:mi>0</m:mi>
                          </m:msub>

                          <m:mo>|</m:mo>

                          <m:mi>θ)</m:mi>
                        </m:mrow>
                      </m:mfrac>

                      <m:mrow>
                        <m:mrow>
                          <m:mrow>
                            <m:mi>p(q|θ)/(q,</m:mi>

                            <m:msub>
                              <m:mi>q</m:mi>

                              <m:mi>0</m:mi>
                            </m:msub>
                          </m:mrow>

                          <m:mo>) if q&gt;</m:mo>
                        </m:mrow>

                        <m:msub>
                          <m:mi>q</m:mi>

                          <m:mi>0</m:mi>
                        </m:msub>
                      </m:mrow>
                    </m:mrow>
                  </m:mrow>
                </m:mtd>
              </m:mtr>
            </m:mtable>
          </m:mrow>
        </m:math>
      </equation>

      <para>where I() is an indicator function defined as</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mrow>
              <m:mi>I(q,</m:mi>

              <m:mrow>
                <m:msub>
                  <m:mi>q</m:mi>

                  <m:mi>0</m:mi>
                </m:msub>
              </m:mrow>
            </m:mrow>

            <m:mo>) =</m:mo>

            <m:mrow>
              <m:mo>{</m:mo>

              <m:mtable>
                <m:mtr>
                  <m:mtd>
                    <m:mrow>
                      <m:mi>1</m:mi>

                      <m:mo>if q&gt;</m:mo>

                      <m:msub>
                        <m:mi>q</m:mi>

                        <m:mi>0</m:mi>
                      </m:msub>
                    </m:mrow>
                  </m:mtd>
                </m:mtr>

                <m:mtr>
                  <m:mtd>
                    <m:mrow>
                      <m:mi>0</m:mi>

                      <m:mo>if</m:mo>

                      <m:msub>
                        <m:mi>q≤q</m:mi>

                        <m:mi>0</m:mi>
                      </m:msub>
                    </m:mrow>
                  </m:mtd>
                </m:mtr>
              </m:mtable>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>
    </section>

    <section>
      <title>Box 3: Likelihood function: No-error-discharge case</title>

      <para>The likelihood function is, by definition, the joint pdf of D
      given the parameter vector θ.</para>

      <para>The likelihood function for the gauged data is the joint pdf of
      the n gauged floods. Given the AM flood peaks are statistically
      independent, the likelihood can be simplified to (Stedinger and Cohn,
      1986)</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mrow>
              <m:mi>p(</m:mi>

              <m:msub>
                <m:mi>q</m:mi>

                <m:mi>1</m:mi>
              </m:msub>

              <m:mi>,...,</m:mi>

              <m:msub>
                <m:mi>q</m:mi>

                <m:mi>n</m:mi>
              </m:msub>

              <m:mi>|θ)</m:mi>
            </m:mrow>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mrow>
                <m:munderover>
                  <m:mo>∏</m:mo>

                  <m:mi>i=1</m:mi>

                  <m:mi>n</m:mi>
                </m:munderover>

                <m:mi>p</m:mi>
              </m:mrow>

              <m:msub>
                <m:mi>(q</m:mi>

                <m:mi>i</m:mi>
              </m:msub>

              <m:mi>|</m:mi>

              <m:mo>θ)</m:mo>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>The likelihood of the binomial censored data relies on the fact
      that the probability of observing exactly x exceedances in n years is
      given by the binomial distribution</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mi>P(X|n,∏)=</m:mi>

            <m:msubsup>
              <m:mi>C</m:mi>

              <m:mi>x</m:mi>

              <m:mi>n</m:mi>
            </m:msubsup>

            <m:mi>(1-</m:mi>

            <m:msup>
              <m:mi>∏)</m:mi>

              <m:mi>n-x</m:mi>
            </m:msup>

            <m:msup>
              <m:mi>∏</m:mi>

              <m:mi>x</m:mi>
            </m:msup>
          </m:mrow>
        </m:math>
      </equation>

      <para>where ∏ is the probability of an exceedance.</para>

      <para>Provided each censoring threshold does not overlap over time with
      any other censoring threshold, the likelihood of the censored data
      becomes</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mi>p(censored data∣</m:mi>

            <m:mrow>
              <m:mi>θ)</m:mi>

              <m:mo>=</m:mo>

              <m:mrow>
                <m:munderover>
                  <m:mo>∏</m:mo>

                  <m:mi>i=1</m:mi>

                  <m:mi>m</m:mi>
                </m:munderover>

                <m:mi>[1-P(Q≤</m:mi>
              </m:mrow>
            </m:mrow>

            <m:msub>
              <m:mi>s</m:mi>

              <m:mi>i</m:mi>
            </m:msub>

            <m:mo>∣θ</m:mo>

            <m:msup>
              <m:mi>)]</m:mi>

              <m:msub>
                <m:mi>a</m:mi>

                <m:mi>0</m:mi>
              </m:msub>
            </m:msup>

            <m:mrow>
              <m:mi>P(Q≤</m:mi>

              <m:msub>
                <m:mi>s</m:mi>

                <m:mi>i</m:mi>
              </m:msub>

              <m:msup>
                <m:mi>∣θ)</m:mi>

                <m:msub>
                  <m:mi>b</m:mi>

                  <m:mi>0</m:mi>
                </m:msub>
              </m:msup>

              <m:mrow>
                <m:mo>=</m:mo>

                <m:mrow>
                  <m:munderover>
                    <m:mo>∏</m:mo>

                    <m:mi>i=1</m:mi>

                    <m:mi>m</m:mi>
                  </m:munderover>

                  <m:mi>P(</m:mi>
                </m:mrow>
              </m:mrow>

              <m:mrow>
                <m:msub>
                  <m:mi>a</m:mi>

                  <m:mi>i</m:mi>
                </m:msub>

                <m:msub>
                  <m:mi>,b</m:mi>

                  <m:mi>i</m:mi>
                </m:msub>

                <m:mi>|</m:mi>

                <m:msub>
                  <m:mi>s</m:mi>

                  <m:mi>i</m:mi>
                </m:msub>

                <m:mi>,</m:mi>
              </m:mrow>
            </m:mrow>

            <m:mi>θ)</m:mi>
          </m:mrow>
        </m:math>
      </equation>

      <para>where
      P(a<subscript>i</subscript>,b<subscript>i</subscript>|s<subscript>i</subscript>,θ)
      is the binomial probability of observing exactly
      a<subscript>i</subscript> exceedances above the threshold discharge
      s<subscript>i</subscript> in
      (a<subscript>i</subscript>+b<subscript>i</subscript>).</para>
    </section>

    <section>
      <title>Box 4: Likelihood function: Error-in-discharge case</title>

      <para>Figure B4-1 presents a rating error space diagram. In zone 1, the
      interpolation zone it is assumed the rating error multiplier
      e<subscript>1</subscript> equals 1 – that is, errors within the rated
      part of the rating curve are deemed negligible. As a result the
      estimated flow w equals the true flow q. However, in zone 2, the
      extension zone, the rating error multiplier e<subscript>2</subscript> is
      assumed to be a random variable with mean of 1. The anchor point
      (q<subscript>1</subscript>,w<subscript>1</subscript>) separates the
      interpolation and extension zones. The rating error model can
      represented mathematically as</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mi>w</m:mi>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mo>{</m:mo>

              <m:mtable>
                <m:mtr>
                  <m:mtd>
                    <m:mrow>
                      <m:mi>q</m:mi>

                      <m:mrow>
                        <m:msub>
                          <m:mi>if q ≤x</m:mi>

                          <m:mi>i</m:mi>
                        </m:msub>
                      </m:mrow>
                    </m:mrow>
                  </m:mtd>
                </m:mtr>

                <m:mtr>
                  <m:mtd>
                    <m:mrow>
                      <m:mrow>
                        <m:msub>
                          <m:mi>w</m:mi>

                          <m:mi>1</m:mi>
                        </m:msub>

                        <m:mo>+</m:mo>

                        <m:msub>
                          <m:mi>θ</m:mi>

                          <m:mi>2</m:mi>
                        </m:msub>

                        <m:mo>(q-</m:mo>

                        <m:msub>
                          <m:mi>q</m:mi>

                          <m:mi>1</m:mi>
                        </m:msub>
                      </m:mrow>

                      <m:mrow>
                        <m:mi>)</m:mi>

                        <m:mo>if q&gt;</m:mo>

                        <m:msub>
                          <m:mi>q</m:mi>

                          <m:mi>1</m:mi>
                        </m:msub>
                      </m:mrow>
                    </m:mrow>
                  </m:mtd>
                </m:mtr>
              </m:mtable>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>The rating error multiplier e<subscript>2</subscript> is sampled
      only once at the time of extending the rating curve. Therefore, all
      flood discharge estimates exceeding the anchor value of
      q<subscript>1</subscript> (which equals w<subscript>1</subscript>) are
      corrupted by the same rating error multiplier. It must be stressed that
      the error e<subscript>2</subscript> is not known – at best, only its
      probability distribution can be estimated. For practical applications
      one can assume e<subscript>2</subscript> is distributed as either a
      log-normal or normal distribution with mean 1 and standard deviation
      σ<subscript>2</subscript>.</para>

      <figure>
        <title>Rating error multiplier space diagram for rating curve shown in
        Figure 5</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureB4_1.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>Data are assigned to each of the two zones, i=1,2, in the rating
      error space diagram. The rating error multiplier standard deviation for
      the extension zone σ<subscript>2</subscript> is assigned a value with
      σ<subscript>1</subscript> = 0. There are n<subscript>i</subscript>
      annual flood peak estimates wji satisfying the zone constraint
      w<subscript>i-1</subscript> ≤ w<subscript>ji</subscript> &lt;
      w<subscript>i</subscript>, j=1,..,n<subscript>i</subscript> where
      w<subscript>0</subscript>=0 and w<subscript>2</subscript>=∞. In
      addition, there are mi threshold discharge estimates
      W<subscript>ji</subscript> for which there are
      a<subscript>ji</subscript> exceedances in
      (a<subscript>ji</subscript>+b<subscript>ji</subscript>) years,
      j=1,..,m<subscript>i</subscript>. Collectively this data is represented
      as</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mi>D</m:mi>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:msub>
                <m:mi>{D</m:mi>

                <m:mi>i</m:mi>
              </m:msub>

              <m:mo>, i=1,2}</m:mo>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mo>=</m:mo>

            <m:mrow>
              <m:msub>
                <m:mi>{[w</m:mi>

                <m:mi>ji</m:mi>
              </m:msub>

              <m:mo>,j=1,...</m:mo>

              <m:msub>
                <m:mi>n</m:mi>

                <m:mi>i</m:mi>
              </m:msub>

              <m:msub>
                <m:mi>;W</m:mi>

                <m:mi>ji</m:mi>
              </m:msub>

              <m:msub>
                <m:mi>,a</m:mi>

                <m:mi>ji</m:mi>
              </m:msub>

              <m:msub>
                <m:mi>,b</m:mi>

                <m:mi>ji</m:mi>
              </m:msub>

              <m:mrow>
                <m:mi>,j=1,...,</m:mi>

                <m:msub>
                  <m:mi>m</m:mi>

                  <m:mi>i</m:mi>
                </m:msub>

                <m:mi>],i=1,2}</m:mi>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>Following Kuczera (1999) it can be shown for the two-zone rating
      error model of Figure B4-1 the likelihood reduces to</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mrow>
              <m:mi>p(</m:mi>

              <m:msub>
                <m:mi>D</m:mi>

                <m:mi>1</m:mi>
              </m:msub>

              <m:msub>
                <m:mi>,D</m:mi>

                <m:mi>2</m:mi>
              </m:msub>

              <m:mrow>
                <m:mi>∣</m:mi>

                <m:msub>
                  <m:mi>θ</m:mi>

                  <m:mi>1</m:mi>
                </m:msub>
              </m:mrow>

              <m:mrow>
                <m:msub>
                  <m:mi>,σ</m:mi>

                  <m:mi>2</m:mi>
                </m:msub>

                <m:mo>)</m:mo>
              </m:mrow>
            </m:mrow>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mrow>
                <m:mi>p(</m:mi>

                <m:msub>
                  <m:mi>D</m:mi>

                  <m:mi>1</m:mi>
                </m:msub>

                <m:msub>
                  <m:mi>,e</m:mi>

                  <m:mi>1</m:mi>
                </m:msub>

                <m:mo>=1|θ</m:mo>

                <m:mi>)</m:mi>
              </m:mrow>

              <m:mrow>
                <m:mrow>
                  <m:mo>[</m:mo>

                  <m:mrow>
                    <m:mrow>
                      <m:munderover>
                        <m:mo>∫p(</m:mo>

                        <m:mi>0</m:mi>

                        <m:mi mathvariant="normal">∞</m:mi>
                      </m:munderover>
                    </m:mrow>

                    <m:msub>
                      <m:mi>D</m:mi>

                      <m:mi>2</m:mi>
                    </m:msub>

                    <m:msub>
                      <m:mi>,e</m:mi>

                      <m:mi>2</m:mi>
                    </m:msub>

                    <m:mo>| θ)g(</m:mo>

                    <m:mrow>
                      <m:msub>
                        <m:mi>e</m:mi>

                        <m:mi>2</m:mi>
                      </m:msub>

                      <m:msub>
                        <m:mi>|σ</m:mi>

                        <m:mi>2</m:mi>
                      </m:msub>
                    </m:mrow>

                    <m:msub>
                      <m:mi>)de</m:mi>

                      <m:mi>2</m:mi>
                    </m:msub>
                  </m:mrow>

                  <m:mo>]</m:mo>
                </m:mrow>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>where</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mrow>
              <m:mi>p(</m:mi>

              <m:msub>
                <m:mi>D</m:mi>

                <m:mi>i</m:mi>
              </m:msub>

              <m:msub>
                <m:mi>,e</m:mi>

                <m:mi>i</m:mi>
              </m:msub>

              <m:mo>|</m:mo>

              <m:mi>θ)</m:mi>
            </m:mrow>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mrow>
                <m:munderover>
                  <m:mo>∏</m:mo>

                  <m:mi>j=1</m:mi>

                  <m:msub>
                    <m:mi>n</m:mi>

                    <m:mi>i</m:mi>
                  </m:msub>
                </m:munderover>

                <m:mfrac>
                  <m:mi>1</m:mi>

                  <m:msub>
                    <m:mi>e</m:mi>

                    <m:mi>i</m:mi>
                  </m:msub>
                </m:mfrac>
              </m:mrow>

              <m:mo>p(</m:mo>

              <m:msub>
                <m:mi>q</m:mi>

                <m:mi>i-1</m:mi>
              </m:msub>

              <m:mo>+</m:mo>

              <m:mrow>
                <m:mfrac>
                  <m:mrow>
                    <m:msub>
                      <m:mi>w</m:mi>

                      <m:mi>ji</m:mi>
                    </m:msub>

                    <m:mo>-</m:mo>

                    <m:msub>
                      <m:mi>w</m:mi>

                      <m:mi>i-1</m:mi>
                    </m:msub>
                  </m:mrow>

                  <m:msub>
                    <m:mi>e</m:mi>

                    <m:mi>i</m:mi>
                  </m:msub>
                </m:mfrac>

                <m:mo>| θ)</m:mo>

                <m:mrow>
                  <m:munderover>
                    <m:mo>∏</m:mo>

                    <m:mi>j=1</m:mi>

                    <m:msub>
                      <m:mi>m</m:mi>

                      <m:mi>i</m:mi>
                    </m:msub>
                  </m:munderover>

                  <m:mi>P[</m:mi>
                </m:mrow>

                <m:msub>
                  <m:mi>a</m:mi>

                  <m:mi>ji</m:mi>
                </m:msub>

                <m:msub>
                  <m:mi>,b</m:mi>

                  <m:mi>ji</m:mi>
                </m:msub>

                <m:msub>
                  <m:mi>|q</m:mi>

                  <m:mi>i-1</m:mi>
                </m:msub>

                <m:mi>+</m:mi>
              </m:mrow>

              <m:mfrac>
                <m:mrow>
                  <m:msub>
                    <m:mi>w</m:mi>

                    <m:mi>ji</m:mi>
                  </m:msub>

                  <m:mo>-</m:mo>

                  <m:msub>
                    <m:mi>w</m:mi>

                    <m:mi>i-1</m:mi>
                  </m:msub>
                </m:mrow>

                <m:msub>
                  <m:mi>e</m:mi>

                  <m:mi>i</m:mi>
                </m:msub>
              </m:mfrac>

              <m:mi>,θ]</m:mi>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>g(e<subscript>i</subscript>|σ<subscript>i</subscript>) is the
      rating error multiplier pdf with mean 1 and standard deviation
      σ<subscript>i</subscript> and P(a,b|s,θ) is the binomial probability of
      observing exactly a exceedances above the threshold discharge s in
      (a+b). This is a complex expression which can only be evaluated
      numerically. However, it makes the fullest use of information on annual
      flood peaks and binomial-censored data in the presence of rating curve
      error. Section 3.7 offers limited guidance on the choice of
      σ<subscript>2</subscript>.</para>
    </section>

    <section>
      <title>Box 5: Importance sampling from the posterior
      distribution</title>

      <para>Importance sampling is a widely used method [Gelman et al., 1995]
      for sampling parameters from a target probability model for which there
      is no algorithm to draw random samples.. The basic idea is to sample
      from a probability model for which a sampling algorithm exists – the
      probability model is called the importance distribution and the samples
      are called particles. The particles are then weighted so that they
      represent samples from the target distribution. The closer the
      importance distribution approximates the target, the more efficient the
      sampling.</para>

      <para>Three steps are involved:</para>

      <para>Step 1: Find most probable parameters of the target
      distribution</para>

      <para>Any robust search method can be used to locate the value of θ
      which maximizes the logarithm of the posterior probability density; that
      is,</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mi>θ</m:mi>

            <m:mo>←</m:mo>

            <m:mi>max</m:mi>

            <m:mo>log</m:mo>

            <m:mi>p</m:mi>

            <m:mo>(θ|D)</m:mo>
          </m:mrow>
        </m:math>
      </equation>

      <para>where θ is the most probable value of θ. The shuffled complex
      evolution algorithm of Duan et al. (1992) is a recommended search
      method.</para>

      <para>Step 2: Obtain the importance distribution using a multinormal
      approximation to the target distribution</para>

      <para>Almost always, the log of posterior pdf p(θ|D) can be approximated
      by a second-order Taylor series expansion about the most probable
      parameter to yield the multivariate normal approximation</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mi>θ|</m:mi>

            <m:mo>D~N(θ</m:mo>

            <m:mi>,</m:mi>

            <m:mo>Σ</m:mo>

            <m:mi>)</m:mi>
          </m:mrow>
        </m:math>
      </equation>

      <para>where θ is interpreted as the mean and the posterior covariance Σ
      is defined as the inverse of the Hessian</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mi>Σ</m:mi>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mo>(</m:mo>

              <m:mrow>
                <m:mi>-</m:mi>

                <m:mfrac>
                  <m:mrow>
                    <m:msup>
                      <m:mi>δ</m:mi>

                      <m:mi>2</m:mi>
                    </m:msup>

                    <m:msub>
                      <m:mi>log</m:mi>

                      <m:mi>e</m:mi>
                    </m:msub>

                    <m:mi>p(θ</m:mi>

                    <m:mo>| D)</m:mo>
                  </m:mrow>

                  <m:mrow>
                    <m:msup>
                      <m:mi>δ</m:mi>

                      <m:mi>2</m:mi>
                    </m:msup>

                    <m:mi>θ</m:mi>
                  </m:mrow>
                </m:mfrac>
              </m:mrow>

              <m:msup>
                <m:mi>)</m:mi>

                <m:mi>-1</m:mi>
              </m:msup>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>An adaptive difference scheme should be used to evaluate the
      Hessian. Particular care needs to be exercised when selecting finite
      difference perturbations for the GEV and LP3 distributions when upper or
      lower bounds are close to the observed data.</para>

      <para>Step 3: Importance sampling of target distribution</para>

      <para>The importance sampling algorithm proceeds as follows:</para>

      <orderedlist>
        <listitem>
          <para>Sample N particles according to <inlineequation>
              <m:math display="inline">
                <m:msub>
                  <m:mi>θ</m:mi>

                  <m:mi>i</m:mi>
                </m:msub>

                <m:mo>←</m:mo>

                <m:msub>
                  <m:mi>p</m:mi>

                  <m:mi>N</m:mi>
                </m:msub>

                <m:mo>(θ)</m:mo>

                <m:mi>,i=1,...,N</m:mi>

                <m:mi> </m:mi>
              </m:math>
            </inlineequation>where pN(θ) is the pdf of the multinormal
          approximation obtained in Step 2.</para>
        </listitem>

        <listitem>
          <para>Calculate particle probability weights according to
          <inlineequation>
              <m:math display="inline">
                <m:mrow>
                  <m:mi>P(</m:mi>

                  <m:msub>
                    <m:mi>θ)</m:mi>

                    <m:mi>i</m:mi>
                  </m:msub>
                </m:mrow>

                <m:mo>=</m:mo>

                <m:mfrac>
                  <m:mrow>
                    <m:msub>
                      <m:mi>p(θ</m:mi>

                      <m:mi>i</m:mi>
                    </m:msub>

                    <m:mrow>
                      <m:mi>|</m:mi>

                      <m:mo>D)</m:mo>
                    </m:mrow>
                  </m:mrow>

                  <m:mrow>
                    <m:msub>
                      <m:mi>p</m:mi>

                      <m:mi>N</m:mi>
                    </m:msub>

                    <m:mrow>
                      <m:msub>
                        <m:mi>(θ</m:mi>

                        <m:mi>i</m:mi>
                      </m:msub>

                      <m:mo>)</m:mo>
                    </m:mrow>
                  </m:mrow>
                </m:mfrac>
              </m:math>
            </inlineequation>,i=1,...,N </para>
        </listitem>

        <listitem>
          <para>Scale the particle weights so they sum to 1.</para>
        </listitem>
      </orderedlist>
    </section>

    <section>
      <title>Box 6: LH moments for fitting the GEV distribution</title>

      <para>LH moments are based on linear combinations of higher
      order-statistics. A shift parameter η=0,1,2,3… is introduced to give
      more emphasis on higher ranked flows. LH moments are defined as:</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:msubsup>
              <m:mi>λ</m:mi>

              <m:mi>1</m:mi>

              <m:mi>η</m:mi>
            </m:msubsup>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mi>E[</m:mi>

              <m:mrow>
                <m:msub>
                  <m:mi>X</m:mi>

                  <m:mi>(η+1):(η+1)</m:mi>
                </m:msub>

                <m:mo>]</m:mo>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:msubsup>
              <m:mi>λ</m:mi>

              <m:mi>2</m:mi>

              <m:mi>η</m:mi>
            </m:msubsup>

            <m:mo>=</m:mo>

            <m:mfrac>
              <m:mi>1</m:mi>

              <m:mi>2</m:mi>
            </m:mfrac>

            <m:mo>E</m:mo>

            <m:mrow>
              <m:mo>[</m:mo>

              <m:mrow>
                <m:msub>
                  <m:mi>X</m:mi>

                  <m:mi>(η+2):(η+2)</m:mi>
                </m:msub>

                <m:mo>-</m:mo>

                <m:msub>
                  <m:mi>X</m:mi>

                  <m:mi>(η+1):(η+3)</m:mi>
                </m:msub>
              </m:mrow>

              <m:mo>]</m:mo>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:msubsup>
              <m:mi>λ</m:mi>

              <m:mi>3</m:mi>

              <m:mi>η</m:mi>
            </m:msubsup>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mfrac>
                <m:mi>1</m:mi>

                <m:mi>3</m:mi>
              </m:mfrac>

              <m:mo>E</m:mo>

              <m:mrow>
                <m:mo>[</m:mo>

                <m:mrow>
                  <m:msub>
                    <m:mi>X</m:mi>

                    <m:mi>(η+3):(η+3)</m:mi>
                  </m:msub>

                  <m:mo>-</m:mo>

                  <m:mrow>
                    <m:msub>
                      <m:mi>2X</m:mi>

                      <m:mi>(η+2):(η+3)</m:mi>
                    </m:msub>

                    <m:mo>+</m:mo>

                    <m:msub>
                      <m:mi>X</m:mi>

                      <m:mi>(η+1):(η+3)</m:mi>
                    </m:msub>
                  </m:mrow>
                </m:mrow>

                <m:mo>]</m:mo>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:msubsup>
              <m:mi>λ</m:mi>

              <m:mi>4</m:mi>

              <m:mi>η</m:mi>
            </m:msubsup>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mfrac>
                <m:mi>1</m:mi>

                <m:mi>4</m:mi>
              </m:mfrac>

              <m:mo>E</m:mo>

              <m:mrow>
                <m:mo>[</m:mo>

                <m:mrow>
                  <m:msub>
                    <m:mi>X</m:mi>

                    <m:mi>(η+4):(η+4)</m:mi>
                  </m:msub>

                  <m:mo>-</m:mo>

                  <m:mrow>
                    <m:msub>
                      <m:mi>3X</m:mi>

                      <m:mi>(η+3):(η+4)</m:mi>
                    </m:msub>

                    <m:mo>+</m:mo>

                    <m:mrow>
                      <m:msub>
                        <m:mi>3X</m:mi>

                        <m:mi>(η+2):(η+4)</m:mi>
                      </m:msub>

                      <m:mo>-</m:mo>

                      <m:msub>
                        <m:mi>X</m:mi>

                        <m:mi>(η+1):(η+4)</m:mi>
                      </m:msub>
                    </m:mrow>
                  </m:mrow>
                </m:mrow>

                <m:mo>]</m:mo>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>Table B6-1 presents the relationship between the first four LH
      moments and the parameters of the GEV and Gumbel distributions.</para>

      <para>Table B6-1. LH moments for GEV and Gumbel distributions (from
      Wang, 1997)</para>

      <informaltable>
        <tgroup cols="2">
          <tbody>
            <row>
              <entry>Family</entry>

              <entry>LH Moments</entry>
            </row>

            <row>
              <entry>Generalized extreme value (GEV)</entry>

              <entry><inlineequation>
                  <m:math display="inline">
                    <m:mtable>
                      <m:mtr>
                        <m:mtd>
                          <m:mrow>
                            <m:msubsup>
                              <m:mi>λ</m:mi>

                              <m:mi>1</m:mi>

                              <m:mi>η</m:mi>
                            </m:msubsup>

                            <m:mo>=</m:mo>

                            <m:mrow>
                              <m:mi>τ +</m:mi>

                              <m:mfrac>
                                <m:mi>α</m:mi>

                                <m:mi>κ</m:mi>
                              </m:mfrac>

                              <m:mi>[1-Γ(1+κ)(η+1</m:mi>

                              <m:msup>
                                <m:mi>)</m:mi>

                                <m:mi>-κ</m:mi>
                              </m:msup>

                              <m:mi>]</m:mi>

                              <m:mrow>
                                <m:mrow>
                                  <m:msubsup>
                                    <m:mi>λ</m:mi>

                                    <m:mi>2</m:mi>

                                    <m:mi>η</m:mi>
                                  </m:msubsup>

                                  <m:mo>=</m:mo>

                                  <m:mfrac>
                                    <m:mi>(η+2)αΓ(1+κ)</m:mi>

                                    <m:mi>2!κ</m:mi>
                                  </m:mfrac>
                                </m:mrow>

                                <m:mo>[- (η+2</m:mo>

                                <m:msup>
                                  <m:mi>)</m:mi>

                                  <m:mi>-κ</m:mi>
                                </m:msup>

                                <m:mo>+(η +</m:mo>

                                <m:msup>
                                  <m:mi>1 )</m:mi>

                                  <m:mi>-κ</m:mi>
                                </m:msup>
                              </m:mrow>
                            </m:mrow>
                          </m:mrow>
                        </m:mtd>
                      </m:mtr>

                      <m:mtr>
                        <m:mtd>
                          <m:mrow>
                            <m:msubsup>
                              <m:mi>λ</m:mi>

                              <m:mi>3</m:mi>

                              <m:mi>η</m:mi>
                            </m:msubsup>

                            <m:mo>=</m:mo>

                            <m:mrow>
                              <m:mfrac>
                                <m:mi>(η+3)αΓ(1+κ)</m:mi>

                                <m:mi>3!κ</m:mi>
                              </m:mfrac>

                              <m:mo>[ - (η+4)(η+</m:mo>

                              <m:msup>
                                <m:mi>3)</m:mi>

                                <m:mi>-κ</m:mi>
                              </m:msup>

                              <m:mo>+2(η+3)(η+2</m:mo>

                              <m:msup>
                                <m:mi>)</m:mi>

                                <m:mi>-κ</m:mi>
                              </m:msup>

                              <m:mo>- (</m:mo>

                              <m:mrow>
                                <m:mi>η+2)(η+1</m:mi>

                                <m:msup>
                                  <m:mi>)</m:mi>

                                  <m:mi>-κ</m:mi>
                                </m:msup>

                                <m:mi>]</m:mi>
                              </m:mrow>
                            </m:mrow>
                          </m:mrow>
                        </m:mtd>
                      </m:mtr>

                      <m:mtr>
                        <m:mtd>
                          <m:mrow>
                            <m:mtable>
                              <m:mtr>
                                <m:mtd>
                                  <m:mrow>
                                    <m:msubsup>
                                      <m:mi>λ</m:mi>

                                      <m:mi>4</m:mi>

                                      <m:mi>η</m:mi>
                                    </m:msubsup>

                                    <m:mo>=</m:mo>

                                    <m:mrow>
                                      <m:mfrac>
                                        <m:mi>(η+4)αΓ(1+κ)</m:mi>

                                        <m:mi>4!κ</m:mi>
                                      </m:mfrac>

                                      <m:mo>[ -(η+6)(η+5)(η+4</m:mo>

                                      <m:msup>
                                        <m:mi>)</m:mi>

                                        <m:mi>-κ</m:mi>
                                      </m:msup>

                                      <m:mo>+3(η+5)(η+4)(η+3</m:mo>

                                      <m:msup>
                                        <m:mi>)</m:mi>

                                        <m:mi>-κ</m:mi>
                                      </m:msup>

                                      <m:mo>]</m:mo>
                                    </m:mrow>
                                  </m:mrow>
                                </m:mtd>
                              </m:mtr>

                              <m:mtr>
                                <m:mtd>
                                  <m:mrow>
                                    <m:mtable>
                                      <m:mtr>
                                        <m:mtd>
                                          <m:mrow>
                                            <m:mi>-3(η+4)(η+3)(η+2</m:mi>

                                            <m:mrow>
                                              <m:msup>
                                                <m:mi>)</m:mi>

                                                <m:mi>-κ</m:mi>
                                              </m:msup>

                                              <m:mo>+ (η+3)(η+2)(η+1</m:mo>

                                              <m:msup>
                                                <m:mi>)</m:mi>

                                                <m:mi>-κ</m:mi>
                                              </m:msup>
                                            </m:mrow>
                                          </m:mrow>
                                        </m:mtd>
                                      </m:mtr>

                                      <m:mtr>
                                        <m:mtd>
                                          <m:mrow>
                                            <m:mi>where κ≠</m:mi>

                                            <m:mo>0</m:mo>
                                          </m:mrow>
                                        </m:mtd>
                                      </m:mtr>
                                    </m:mtable>
                                  </m:mrow>
                                </m:mtd>
                              </m:mtr>
                            </m:mtable>
                          </m:mrow>
                        </m:mtd>
                      </m:mtr>
                    </m:mtable>
                  </m:math>
                </inlineequation></entry>
            </row>

            <row>
              <entry>Gumbel</entry>

              <entry><inlineequation>
                  <m:math display="inline">
                    <m:mtable>
                      <m:mtr>
                        <m:mtd>
                          <m:mrow>
                            <m:msubsup>
                              <m:mi>λ</m:mi>

                              <m:mi>1</m:mi>

                              <m:mi>η</m:mi>
                            </m:msubsup>

                            <m:mo>=</m:mo>

                            <m:mrow>
                              <m:mi>τ+α[0.5772+ln(η+1]</m:mi>

                              <m:msubsup>
                                <m:mi>λ</m:mi>

                                <m:mi>2</m:mi>

                                <m:mi>η</m:mi>
                              </m:msubsup>

                              <m:mi>=</m:mi>

                              <m:mfrac>
                                <m:mi>(η+2)α</m:mi>

                                <m:mi>2!</m:mi>
                              </m:mfrac>

                              <m:mi>[ln(η+2) - ln (η+1)</m:mi>
                            </m:mrow>
                          </m:mrow>
                        </m:mtd>
                      </m:mtr>

                      <m:mtr>
                        <m:mtd>
                          <m:mrow>
                            <m:msubsup>
                              <m:mi>λ</m:mi>

                              <m:mi>3</m:mi>

                              <m:mi>η</m:mi>
                            </m:msubsup>

                            <m:mo>=</m:mo>

                            <m:mrow>
                              <m:mfrac>
                                <m:mi>(η+3)α</m:mi>

                                <m:mi>3!</m:mi>
                              </m:mfrac>

                              <m:mo>[
                              (η+4)ln(η+3)-2(η+3)ln(η+2)+(η+2)ln(η+1)]</m:mo>
                            </m:mrow>
                          </m:mrow>
                        </m:mtd>
                      </m:mtr>

                      <m:mtr>
                        <m:mtd>
                          <m:mrow>
                            <m:mtable>
                              <m:mtr>
                                <m:mtd>
                                  <m:mrow>
                                    <m:msubsup>
                                      <m:mi>λ</m:mi>

                                      <m:mi>4</m:mi>

                                      <m:mi>η</m:mi>
                                    </m:msubsup>

                                    <m:mo>=</m:mo>

                                    <m:mrow>
                                      <m:mfrac>
                                        <m:mi>(η+4)α</m:mi>

                                        <m:mi>4!</m:mi>
                                      </m:mfrac>

                                      <m:mo>[(η+6)(η+5)ln(η+4)-3(η+5)(η+4)ln(η+3)</m:mo>
                                    </m:mrow>
                                  </m:mrow>
                                </m:mtd>
                              </m:mtr>

                              <m:mtr>
                                <m:mtd>
                                  <m:mrow>
                                    <m:mi>+3(η+4)(η+3)ln(η+2)-(η+3)(η+2)ln(η+1)]</m:mi>
                                  </m:mrow>
                                </m:mtd>
                              </m:mtr>
                            </m:mtable>
                          </m:mrow>
                        </m:mtd>
                      </m:mtr>
                    </m:mtable>
                  </m:math>
                </inlineequation></entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>

      <para>For ease of computation Wang (1997) derived the following
      approximation for the shape parameter κ:</para>

      <para><inlineequation>
          <m:math display="inline">
            <m:mi>κ</m:mi>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:msub>
                <m:mi>a</m:mi>

                <m:mi>0</m:mi>
              </m:msub>

              <m:mo>+</m:mo>

              <m:mrow>
                <m:mrow>
                  <m:msub>
                    <m:mi>a</m:mi>

                    <m:mi>1</m:mi>
                  </m:msub>

                  <m:msubsup>
                    <m:mi>[τ</m:mi>

                    <m:mi>3</m:mi>

                    <m:mi>η</m:mi>
                  </m:msubsup>
                </m:mrow>

                <m:mo>]+</m:mo>

                <m:mrow>
                  <m:mrow>
                    <m:msub>
                      <m:mi>a</m:mi>

                      <m:mi>2</m:mi>
                    </m:msub>

                    <m:msubsup>
                      <m:mi>[τ</m:mi>

                      <m:mi>3</m:mi>

                      <m:mi>η-2</m:mi>
                    </m:msubsup>
                  </m:mrow>

                  <m:mo>]+</m:mo>

                  <m:mrow>
                    <m:msub>
                      <m:mi>a</m:mi>

                      <m:mi>3</m:mi>
                    </m:msub>

                    <m:mrow>
                      <m:msubsup>
                        <m:mi>[τ</m:mi>

                        <m:mi>3</m:mi>

                        <m:mi>η-3</m:mi>
                      </m:msubsup>

                      <m:msup>
                        <m:mi>]</m:mi>

                        <m:mi/>
                      </m:msup>
                    </m:mrow>
                  </m:mrow>
                </m:mrow>
              </m:mrow>
            </m:mrow>
          </m:math>
        </inlineequation></para>

      <para>where the polynomial coefficients vary with η according to Table
      B6-2.</para>

      <para>Table B6-2. Polynomial coefficients for use with eqn (B6-2)</para>

      <informaltable>
        <tgroup cols="5">
          <tbody>
            <row>
              <entry>η</entry>

              <entry>a<subscript>0</subscript></entry>

              <entry>a<subscript>1</subscript></entry>

              <entry>a<subscript>2</subscript></entry>

              <entry>a<subscript>3</subscript></entry>
            </row>

            <row>
              <entry>0</entry>

              <entry>0.2849</entry>

              <entry>-1.8213</entry>

              <entry>0.8140</entry>

              <entry>-0.2835</entry>
            </row>

            <row>
              <entry>1</entry>

              <entry>0.4823</entry>

              <entry>-2.1494</entry>

              <entry>0.7269</entry>

              <entry>-0.2103</entry>
            </row>

            <row>
              <entry>2</entry>

              <entry>0.5914</entry>

              <entry>-2.3351</entry>

              <entry>0.6442</entry>

              <entry>-0.1616</entry>
            </row>

            <row>
              <entry>3</entry>

              <entry>0.6618</entry>

              <entry>-2.4548</entry>

              <entry>0.5733</entry>

              <entry>-0.1273</entry>
            </row>

            <row>
              <entry>4</entry>

              <entry>0.7113</entry>

              <entry>-2.5383</entry>

              <entry>0.5142</entry>

              <entry>-0.1027</entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>

      <para>Wang (1997) derived the following estimators for LH moments with
      shift parameter η:</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:msubsup>
              <m:mi>λ</m:mi>

              <m:mi>1</m:mi>

              <m:mi>η</m:mi>
            </m:msubsup>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mfrac>
                <m:mi>1</m:mi>

                <m:msubsup>
                  <m:mi>C</m:mi>

                  <m:mi>η+1</m:mi>

                  <m:mi>n</m:mi>
                </m:msubsup>
              </m:mfrac>

              <m:mrow>
                <m:munderover>
                  <m:mo>∑</m:mo>

                  <m:mi>i=1</m:mi>

                  <m:mi>n</m:mi>
                </m:munderover>

                <m:msubsup>
                  <m:mi>C</m:mi>

                  <m:mi>η</m:mi>

                  <m:mi>j-1</m:mi>
                </m:msubsup>
              </m:mrow>

              <m:msub>
                <m:mi>x</m:mi>

                <m:mi>(i)</m:mi>
              </m:msub>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:msubsup>
              <m:mi>λ</m:mi>

              <m:mi>2</m:mi>

              <m:mi>η</m:mi>
            </m:msubsup>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mfrac>
                <m:mi>1</m:mi>

                <m:mi>2</m:mi>
              </m:mfrac>

              <m:mfrac>
                <m:mi>1</m:mi>

                <m:msubsup>
                  <m:mi>C</m:mi>

                  <m:mi>η+2</m:mi>

                  <m:mi>n</m:mi>
                </m:msubsup>
              </m:mfrac>

              <m:mrow>
                <m:munderover>
                  <m:mo>∑</m:mo>

                  <m:mi>i=1</m:mi>

                  <m:mi>n</m:mi>
                </m:munderover>

                <m:mrow>
                  <m:mo>(</m:mo>

                  <m:mrow>
                    <m:msubsup>
                      <m:mi>C</m:mi>

                      <m:mi>η+1</m:mi>

                      <m:mi>i-1</m:mi>
                    </m:msubsup>

                    <m:mo>-</m:mo>

                    <m:mrow>
                      <m:msubsup>
                        <m:mi>C</m:mi>

                        <m:mi>η</m:mi>

                        <m:mi>i-1</m:mi>
                      </m:msubsup>

                      <m:msubsup>
                        <m:mi>C</m:mi>

                        <m:mi>1</m:mi>

                        <m:mi>n-i</m:mi>
                      </m:msubsup>
                    </m:mrow>
                  </m:mrow>

                  <m:mo>)</m:mo>
                </m:mrow>
              </m:mrow>

              <m:msub>
                <m:mi>q</m:mi>

                <m:mi>(i)</m:mi>
              </m:msub>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:msubsup>
              <m:mi>λ</m:mi>

              <m:mi>3</m:mi>

              <m:mi>η</m:mi>
            </m:msubsup>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mfrac>
                <m:mi>1</m:mi>

                <m:mi>3</m:mi>
              </m:mfrac>

              <m:mfrac>
                <m:mi>1</m:mi>

                <m:msubsup>
                  <m:mi>C</m:mi>

                  <m:mi>η+3</m:mi>

                  <m:mi>n</m:mi>
                </m:msubsup>
              </m:mfrac>

              <m:mrow>
                <m:munderover>
                  <m:mo>∑</m:mo>

                  <m:mi>i=1</m:mi>

                  <m:mi>n</m:mi>
                </m:munderover>

                <m:mrow>
                  <m:mo>(</m:mo>

                  <m:mrow>
                    <m:msubsup>
                      <m:mi>C</m:mi>

                      <m:mi>η+2</m:mi>

                      <m:mi>i-1</m:mi>
                    </m:msubsup>

                    <m:mo>-2</m:mo>

                    <m:mrow>
                      <m:mrow>
                        <m:msubsup>
                          <m:mi>C</m:mi>

                          <m:mi>η+1</m:mi>

                          <m:mi>i-1</m:mi>
                        </m:msubsup>

                        <m:msubsup>
                          <m:mi>C</m:mi>

                          <m:mi>1</m:mi>

                          <m:mi>n-i</m:mi>
                        </m:msubsup>
                      </m:mrow>

                      <m:mo>+</m:mo>

                      <m:mrow>
                        <m:msubsup>
                          <m:mi>C</m:mi>

                          <m:mi>η</m:mi>

                          <m:mi>i-1</m:mi>
                        </m:msubsup>

                        <m:msubsup>
                          <m:mi>C</m:mi>

                          <m:mi>2</m:mi>

                          <m:mi>n-i</m:mi>
                        </m:msubsup>
                      </m:mrow>
                    </m:mrow>
                  </m:mrow>

                  <m:mo>)</m:mo>
                </m:mrow>
              </m:mrow>

              <m:msub>
                <m:mi>q</m:mi>

                <m:mi>(i)</m:mi>
              </m:msub>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:msubsup>
              <m:mi>λ</m:mi>

              <m:mi>4</m:mi>

              <m:mi>η</m:mi>
            </m:msubsup>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mfrac>
                <m:mi>1</m:mi>

                <m:mi>4</m:mi>
              </m:mfrac>

              <m:mfrac>
                <m:mi>1</m:mi>

                <m:msubsup>
                  <m:mi>C</m:mi>

                  <m:mi>η+4</m:mi>

                  <m:mi>n</m:mi>
                </m:msubsup>
              </m:mfrac>

              <m:mrow>
                <m:munderover>
                  <m:mo>∑</m:mo>

                  <m:mi>i=1</m:mi>

                  <m:mi>n</m:mi>
                </m:munderover>

                <m:mrow>
                  <m:mo>(</m:mo>

                  <m:mrow>
                    <m:msubsup>
                      <m:mi>C</m:mi>

                      <m:mi>η+3</m:mi>

                      <m:mi>i-1</m:mi>
                    </m:msubsup>

                    <m:mo>-</m:mo>

                    <m:mrow>
                      <m:mrow>
                        <m:msubsup>
                          <m:mi>3C</m:mi>

                          <m:mi>η+2</m:mi>

                          <m:mi>i-1</m:mi>
                        </m:msubsup>

                        <m:msubsup>
                          <m:mi>C</m:mi>

                          <m:mi>1</m:mi>

                          <m:mi>n-i</m:mi>
                        </m:msubsup>
                      </m:mrow>

                      <m:mo>+</m:mo>

                      <m:mrow>
                        <m:mrow>
                          <m:msubsup>
                            <m:mi>3C</m:mi>

                            <m:mi>η+1</m:mi>

                            <m:mi>i-1</m:mi>
                          </m:msubsup>

                          <m:msubsup>
                            <m:mi>C</m:mi>

                            <m:mi>2</m:mi>

                            <m:mi>n-i</m:mi>
                          </m:msubsup>
                        </m:mrow>

                        <m:mo>-</m:mo>

                        <m:mrow>
                          <m:msubsup>
                            <m:mi>C</m:mi>

                            <m:mi>η</m:mi>

                            <m:mi>i-1</m:mi>
                          </m:msubsup>

                          <m:msubsup>
                            <m:mi>C</m:mi>

                            <m:mi>3</m:mi>

                            <m:mi>n-i</m:mi>
                          </m:msubsup>
                        </m:mrow>
                      </m:mrow>
                    </m:mrow>
                  </m:mrow>

                  <m:mo>)</m:mo>
                </m:mrow>
              </m:mrow>

              <m:msub>
                <m:mi>q</m:mi>

                <m:mi>(i)</m:mi>
              </m:msub>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>The selection of the best shift parameter requires some form of
      goodness-of-fit test. Wang (1998) argued that the first three LH moments
      are used to fit the GEV model leaving the fourth LH moment available for
      testing the adequacy of the fit. He proposed the following approximate
      test statistic:</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mi>z</m:mi>

            <m:mo>=</m:mo>

            <m:mfrac>
              <m:mrow>
                <m:msubsup>
                  <m:mi>τ</m:mi>

                  <m:mi>4</m:mi>

                  <m:mi>η</m:mi>
                </m:msubsup>

                <m:mo>-</m:mo>

                <m:msubsup>
                  <m:mi>τ</m:mi>

                  <m:mi>4</m:mi>

                  <m:mi>η</m:mi>
                </m:msubsup>
              </m:mrow>

              <m:mrow>
                <m:mi>σ</m:mi>

                <m:mrow>
                  <m:mo>(</m:mo>

                  <m:mrow>
                    <m:mrow>
                      <m:msubsup>
                        <m:mi>τ</m:mi>

                        <m:mi>4</m:mi>

                        <m:mi>η</m:mi>
                      </m:msubsup>

                      <m:msubsup>
                        <m:mi>|τ</m:mi>

                        <m:mi>3</m:mi>

                        <m:mi>η</m:mi>
                      </m:msubsup>
                    </m:mrow>

                    <m:mo>=</m:mo>

                    <m:msubsup>
                      <m:mi>τ</m:mi>

                      <m:mi>3</m:mi>

                      <m:mi>η</m:mi>
                    </m:msubsup>
                  </m:mrow>

                  <m:mo>)</m:mo>
                </m:mrow>
              </m:mrow>
            </m:mfrac>
          </m:mrow>
        </m:math>
      </equation>

      <para>where τ<subscript>4</subscript><superscript>η</superscript> is the
      sample estimate of the LH-kurtosis,
      τ<subscript>4</subscript><superscript>η</superscript> is the LH-kurtosis
      derived from the GEV parameters fitted to the first three LH moments,
      and σ(τ<subscript>4</subscript><superscript>η</superscript>
      |τ<subscript>3</subscript><superscript>η</superscript>=τ<subscript>3</subscript><superscript>η</superscript>
      ) is the standard deviation of
      τ<subscript>4</subscript><superscript>η</superscript> assuming the
      sample LH-skewness equals the LH-skewness derived from the GEV
      parameters fitted to the first three LH moments. Under the hypothesis
      that the underlying distribution is GEV, the test statistic z is
      approximately normal distributed with mean 0 and variance 1. Wang (1998)
      describes a simple relationship to estimate
      σ(τ<subscript>4</subscript><superscript>η</superscript>
      |τ<subscript>3</subscript><superscript>η</superscript>=τ<subscript>3</subscript><superscript>η</superscript>)
      .</para>
    </section>

    <section>
      <title>Box 7: Parametric bootstrap</title>

      <para>The sampling distribution of an estimator can be approximated
      using the Monte Carlo method known as the parametric bootstrap:</para>

      <orderedlist>
        <listitem>
          <para>Fit the probability model to n years of gauged flows using L
          or LH moments to yield the parameter estimate θ.</para>
        </listitem>

        <listitem>
          <para>Set i=1</para>
        </listitem>

        <listitem>
          <para>Randomly sample n flows from the fitted distribution; that is,
          q<subscript>ji</subscript> ← p(q|θ),j=1,...,n</para>
        </listitem>

        <listitem>
          <para>Fit the model to the sampled flows
          {q<subscript>ji</subscript>,j=1,..,n}using L or LH moments to yield
          the parameter estimate θ<subscript>i</subscript></para>
        </listitem>

        <listitem>
          <para>Increment i. Go to step 3 if i does not exceed N.</para>
        </listitem>
      </orderedlist>

      <para>This procedure yields N equi-weighted samples that approximate the
      sampling distribution p(θ|D). As a result, they can be used to quantify
      parameter uncertainty and estimate quantile confidence limits. However,
      because the parametric bootstrap assumes θ is the true parameter, it
      underestimates the uncertainty and therefore should not be used to
      estimate expected probabilities.</para>
    </section>

    <section>
      <title>Example 1: Extrapolation and Process Understanding</title>

      <para>The importance of process understanding when extrapolating beyond
      the observed record is illustrated by a simple Monte Carlo experiment. A
      Poisson rectangular pulse rainfall model is used to generate a long
      record of high resolution rainfall. This is routed through a
      rainfall-runoff model to generate runoff into the stream system. The
      storage-discharge relationship for the stream is depicted by the
      bilinear relationship shown in Figure E1-1. A feature of this
      relationship is the activation of significant flood terrace storage once
      a threshold discharge is exceeded.</para>

      <figure>
        <title>Bilinear channel storage-discharge relationship</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE1_1.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>The routing model parameters were selected so that major flood
      terrace storage is activated by floods with an AEP less than 1 in 100.
      This situation was chosen to represent a river with multiple flood
      terraces with the lowest terraces accommodating the majority of floods
      and the highest terrace only inundated by extreme floods.</para>

      <para>Figure E1-2 presents the flood frequency curve based on 30000
      simulated years – it shows a clear break in slope around the 1 in 100
      AEP corresponding to the activation of major flood terrace storage.
      Indeed the flood frequency curve displays downward curvature despite
      that the fact the rainfall frequency curve displays upward curvature in
      the 1 in 100 to 1000 AEP range. In contrast the flood frequency curve
      based on 100 years of “data” shows no evidence of downward curvature.
      This is because in a 100-year record there is little chance of the major
      flood terrace storage being activated. Indeed without knowledge of the
      underlying hydraulics one would be tempted to extrapolate the 100-year
      flood record using a straight line extrapolation. Such an extrapolation
      would rapidly diverge from the “true” frequency curve.</para>

      <figure>
        <title>Simulated rainfall and flood frequency curves with major
        floodplain storage activated at a threshold discharge of 3500
        m3/s.</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE1_2.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>Although the example idealizes the dominant rainfall-runoff
      dynamics it delivers a very strong message. Extrapolation of flood
      frequency curves fitted to gauged flow records requires the exercise of
      hydrologic judgment backed up by appropriate modelling. The problem of
      extrapolation is much more general. For example, in this example, if a
      rainfall-runoff approach were used with the rainfall-runoff model
      calibrated to small events the simulated flood frequency curve is likely
      to be compromised in a similar way.</para>
    </section>

    <section>
      <title>Example 2: Accuracy of Daily Gauged Flows</title>

      <para>The use of daily discharge readings in flood frequency analysis is
      most problematic for smaller catchments, which can be “flashy” in the
      sense that the hydrograph can rise and subside within a twenty four hour
      period. This effect can be quite significant, even for reasonably large
      catchments.</para>

      <para>Figures E2-1 and E2-2, taken from Micevski et al. (2003), compare
      instantaneous annual maximum discharge against the discharge recorded at
      9am on the same day for two gauging stations in the Hunter Valley:
      Goulburn River at Coggan with area 3340 km<superscript>2</superscript>
      and Hunter River at Singleton with area 16400
      km<superscript>2</superscript>. The dashed line represents equality.
      Figure E2-1 demonstrates that the true peak flow can be up to 10 times
      the 9am flow. In contrast the estimation error is much smaller for the
      larger catchment shown in Figure E2-2.</para>

      <figure>
        <title>Comparison between true peak flow and 9 am flow for Goulburn
        River at Coggan.</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE2_1.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <figure>
        <title>Comparison between true peak flow and 9 am flow for Hunter
        River at Singleton.</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE2_2.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>The example demonstrates the need to check the representativeness
      of daily readings by comparing instantaneous peak flows against daily
      readings.</para>
    </section>

    <section>
      <title>Example 3: Fitting a probability model to gauged data</title>

      <para>This example illustrates fitting a probability model to gauged
      annual maximum flood data. The following table lists 31 years of gauged
      annual maximum flows (m3/s) for the Hunter River at Singleton:</para>

      <para/>

      <informaltable>
        <tgroup cols="4">
          <colspec/>

          <colspec/>

          <colspec align="center"/>

          <tbody>
            <row>
              <entry>Year</entry>

              <entry>AM discharge (m³/s)</entry>

              <entry>Year</entry>

              <entry>AM discharge (m³/s)</entry>
            </row>

            <row>
              <entry>1938</entry>

              <entry>76.26</entry>

              <entry>1954</entry>

              <entry>1391.43</entry>
            </row>

            <row>
              <entry>1939</entry>

              <entry>171.87</entry>

              <entry>1955</entry>

              <entry>12525.66</entry>
            </row>

            <row>
              <entry>1940</entry>

              <entry>218.21</entry>

              <entry>1956</entry>

              <entry>1099.54</entry>
            </row>

            <row>
              <entry>1941</entry>

              <entry>668.79</entry>

              <entry>1957</entry>

              <entry>447.75</entry>
            </row>

            <row>
              <entry>1942</entry>

              <entry>1374.42</entry>

              <entry>1958</entry>

              <entry>478.92</entry>
            </row>

            <row>
              <entry>1943</entry>

              <entry>124.12</entry>

              <entry>1959</entry>

              <entry>180.52</entry>
            </row>

            <row>
              <entry>1944</entry>

              <entry>276.3</entry>

              <entry>1960</entry>

              <entry>164.36</entry>
            </row>

            <row>
              <entry>1945</entry>

              <entry>895.5</entry>

              <entry>1961</entry>

              <entry>229.54</entry>
            </row>

            <row>
              <entry>1946</entry>

              <entry>1374.42</entry>

              <entry>1962</entry>

              <entry>2125.4</entry>
            </row>

            <row>
              <entry>1947</entry>

              <entry>280.18</entry>

              <entry>1963</entry>

              <entry>966.35</entry>
            </row>

            <row>
              <entry>1948</entry>

              <entry>202.62</entry>

              <entry>1964</entry>

              <entry>2751.68</entry>
            </row>

            <row>
              <entry>1949</entry>

              <entry>4052.42</entry>

              <entry>1965</entry>

              <entry>49.03</entry>
            </row>

            <row>
              <entry>1950</entry>

              <entry>2323.77</entry>

              <entry>1966</entry>

              <entry>79.51</entry>
            </row>

            <row>
              <entry>1951</entry>

              <entry>2536.31</entry>

              <entry>1967</entry>

              <entry>912.5</entry>
            </row>

            <row>
              <entry>1952</entry>

              <entry>3315.62</entry>

              <entry>1968</entry>

              <entry>926.67</entry>
            </row>

            <row>
              <entry>1953</entry>

              <entry>1232.73</entry>

              <entry/>

              <entry/>
            </row>
          </tbody>
        </tgroup>
      </informaltable>

      <para>The data was imported into FLIKE using the “import” control in the
      following dialog:</para>

      <figure>
        <title/>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\Example3.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>The log Pearson 3 distribution was selected to be fitted using the
      Bayesian inference method in the following dialog:</para>

      <figure>
        <title/>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE2_2.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>The following table presents the posterior mean, standard
      deviation and correlation for the LP3 parameters: m, s and g which are
      respectively the mean, standard deviation and skewness of
      log<subscript>e</subscript> q:</para>

      <informaltable>
        <tgroup cols="6">
          <colspec align="center"/>

          <tbody>
            <row>
              <entry>LP3 parameter</entry>

              <entry>Mean</entry>

              <entry>Std deviation</entry>

              <entry>Correlation</entry>

              <entry/>

              <entry/>
            </row>

            <row>
              <entry>m</entry>

              <entry>6.433</entry>

              <entry>0.262</entry>

              <entry>1.000</entry>

              <entry/>

              <entry/>
            </row>

            <row>
              <entry>log<subscript>e</subscript> s</entry>

              <entry>0.353</entry>

              <entry>0.144</entry>

              <entry>0.111</entry>

              <entry>1.000</entry>

              <entry/>
            </row>

            <row>
              <entry>g</entry>

              <entry>0.131</entry>

              <entry>0.479</entry>

              <entry>0.033</entry>

              <entry>0.123</entry>

              <entry>1.000</entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>

      <para>Figure E5-1 displays the log normal probability plot of the gauged
      flows, the 1 in Y AEP quantile curve (derived using the posterior mean
      parameters), the 90% quantile confidence limits and the expected
      probability curve.</para>

      <figure>
        <title/>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE5_1.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>Figure E5-1. Bayesian LP3 fit to 31 years of gauged annual maximum
      floods with prior information on skewness.</para>

      <para>The good fit to the gauged data and the tight confidence limits
      needs to be tempered by the fact that the figure plots the logarithm of
      the flood peaks. The following table of selected 1 in Y AEP quantiles
      q<subscript>Y</subscript> and their 90% confidence limits presents a
      more sobering perspective. For example, for the 1 in 100 AEP flood, the
      5% and 95% confidence limits are respectively 37% and 546% of the
      quantile q<subscript>Y</subscript>! The 1 in 500 AEP confidence limits
      are so wide as to render estimation meaningless. Note the expected AEP
      for the quantile q¬Y consistently exceeds the nominal 1 in Y AEP. For
      example, the 1 in 100 AEP quantile of 19572
      m<superscript>3</superscript>/s has an expected AEP of 1 in 74.</para>

      <informaltable>
        <tgroup cols="5">
          <colspec/>

          <colspec/>

          <colspec/>

          <colspec align="center"/>

          <tbody>
            <row>
              <entry>1 in Y AEP</entry>

              <entry>Quantile estimate q<subscript>Y</subscript></entry>

              <entry>Quantile confidence limits 5% limit</entry>

              <entry>Quantile confidence limits 95% limit</entry>

              <entry>Expected 1 in Y AEP for q<subscript>Y</subscript></entry>
            </row>

            <row>
              <entry>10</entry>

              <entry>3928</entry>

              <entry>2228</entry>

              <entry>8408</entry>

              <entry>9.9</entry>
            </row>

            <row>
              <entry>50</entry>

              <entry>12786</entry>

              <entry>5502</entry>

              <entry>51009</entry>

              <entry>43</entry>
            </row>

            <row>
              <entry>100</entry>

              <entry>19572</entry>

              <entry>7188</entry>

              <entry>106933</entry>

              <entry>74</entry>
            </row>

            <row>
              <entry>500</entry>

              <entry>47033</entry>

              <entry>11507</entry>

              <entry>570619</entry>

              <entry>208</entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>
    </section>

    <section>
      <title>Example 4: Use of binomial censored historical data</title>

      <para>This example is a continuation of Example 3. It illustrates the
      benefit of using historical flood information. The gauged record spanned
      1938 to 1969. The biggest flood in that record occurred in 1955. An
      examination of historic records indicates that during the ungauged
      period 1820 to 1937 there was only one flood that exceeded the 1955
      flood – this flood occurred in 1820. This represents valuable
      information even though the magnitude of the 1820 flood is not reliably
      known. This is an example of censored data. Over the ungauged period
      1820 to 1937 there was one flood above and 117 floods below the
      threshold discharge corresponding to the 1955 flood. This information is
      entered into FLIKE as follows:</para>

      <figure>
        <title/>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE5_2.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>The log Pearson 3 distribution was fitted to gauged and censored
      data using the Bayesian approach.</para>

      <para>The following table presents the posterior mean, standard
      deviation and correlation for the LP3 parameters: m, s and g which are
      respectively the mean, standard deviation and skewness of
      log<subscript>e</subscript> q. Comparison with Example 3 reveals the
      censored data have reduced by almost 17% the uncertainty in the skewness
      g, the parameter that controls the shape of the distribution,
      particularly in the tail region.</para>

      <informaltable>
        <tgroup cols="6">
          <colspec/>

          <colspec/>

          <colspec/>

          <colspec/>

          <colspec align="center"/>

          <tbody>
            <row>
              <entry>LP3 parameter</entry>

              <entry>Mean</entry>

              <entry>Std deviation</entry>

              <entry>Correlation</entry>

              <entry/>

              <entry/>
            </row>

            <row>
              <entry>m</entry>

              <entry>6.365</entry>

              <entry>0.237</entry>

              <entry>1.000</entry>

              <entry/>

              <entry/>
            </row>

            <row>
              <entry>log<subscript>e</subscript> s</entry>

              <entry>0.303</entry>

              <entry>0.120</entry>

              <entry>-0.236</entry>

              <entry>1.000</entry>

              <entry/>
            </row>

            <row>
              <entry>g</entry>

              <entry>-0.004</entry>

              <entry>0.405</entry>

              <entry>-0.227</entry>

              <entry>-0.409</entry>

              <entry>1.000</entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>

      <para>The following figure displays on a log normal probability plot the
      gauged flows, the 1 in Y AEP quantile curve (derived using the posterior
      mean parameters), the 90% quantile confidence limits and the expected
      probability curve. Compared with Example 3 the tightening of the
      confidence limits is most noticeable.</para>

      <figure>
        <title/>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE5_3.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>The following table of selected 1 in Y AEP quantiles
      q<subscript>Y</subscript> and their 90% confidence limits illustrates
      the benefit of the information contained in the historic data. For
      example, for the 1 in 100 AEP flood the 5% and 95% confidence limits are
      respectively 58% and 205% of the quantile qY! This represents a major
      reduction in quantile uncertainty compared with Example 3 which yielded
      limits of 38% and 553%.</para>

      <para/>

      <informaltable>
        <tgroup cols="5">
          <colspec/>

          <colspec/>

          <colspec/>

          <colspec align="center"/>

          <tbody>
            <row>
              <entry>1 in Y AEP</entry>

              <entry>Quantile estimate q<subscript>Y</subscript></entry>

              <entry>Quantile confidence limits 5% limit</entry>

              <entry>Quantile confidence limits 95% limit</entry>

              <entry>Expected 1 in Y AEP for q<subscript>Y</subscript></entry>
            </row>

            <row>
              <entry>10</entry>

              <entry>3293</entry>

              <entry>2181</entry>

              <entry>4946</entry>

              <entry>9.6</entry>
            </row>

            <row>
              <entry>50</entry>

              <entry>9350</entry>

              <entry>5777</entry>

              <entry>16511</entry>

              <entry>48</entry>
            </row>

            <row>
              <entry>100</entry>

              <entry>13510</entry>

              <entry>7784</entry>

              <entry>27685</entry>

              <entry>92</entry>
            </row>

            <row>
              <entry>500</entry>

              <entry>28451</entry>

              <entry>12966</entry>

              <entry>85586</entry>

              <entry>362</entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>

      <para>This example highlights the significant reductions in uncertainty
      that historical data can offer. However, care must be exercised ensuring
      the integrity of the historic information – see Section 3.8 for more
      details.</para>
    </section>

    <section>
      <title>Example 5: Use of regional information</title>

      <para>This is a continuation of Example 3. In Example 3 the posterior
      mean of the skewness was estimated to be 0.131 with a posterior standard
      of 0.479. The uncertainty in the 1 in 100 AEP quantile was large.
      Suppose hypothetically that a regional analysis of skewness was
      conducted. Furthermore suppose the expected regional skew is 0.00 with a
      standard deviation of 0.30. This information is entered into FLIKE by
      selecting the Gaussian prior distributions button and clicking on “edit”
      control:</para>

      <figure>
        <title/>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE5_4.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>The prior information was directly entered into the following
      dialog. Note that very large prior standard deviations are assigned to
      the mean and standard deviation parameters to ensure there is no prior
      information about theses parameters. If the log Pearson III distribution
      has been selected, the option to import the prior information from the
      ARR regional frequency method is available.</para>

      <figure>
        <title/>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE5_5.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>Figure E5-1 presents the probability plot for the LP3 model fitted
      to the gauged data with prior information on the skewness. Comparison
      with Figure E3-1 reveals substantially improved accuracy in the right
      hand tail.</para>

      <figure>
        <title/>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE5_6.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>Figure E5-1. Bayesian LP3 fit to 31 years of gauged annual maximum
      floods with prior information on skewness.</para>

      <para>The table compares the LP3 fitted with and without prior
      information on skewness. The posterior uncertainty on the skewness is
      about 87% of the prior standard deviation indicating the gauged data are
      not very informative about the shape parameter of the flood
      distribution.</para>

      <informaltable>
        <tgroup cols="5">
          <colspec/>

          <colspec/>

          <colspec/>

          <colspec align="center"/>

          <tbody>
            <row>
              <entry>LP3 parameter</entry>

              <entry>No prior information Mean</entry>

              <entry>No prior information Std deviation</entry>

              <entry>With prior information Mean</entry>

              <entry>With prior information Std deviation</entry>
            </row>

            <row>
              <entry>m</entry>

              <entry>6.433</entry>

              <entry>0.262</entry>

              <entry>6.421</entry>

              <entry>0.251</entry>
            </row>

            <row>
              <entry>log<subscript>e</subscript> s</entry>

              <entry>0.353</entry>

              <entry>0.144</entry>

              <entry>0.320</entry>

              <entry>0.131</entry>
            </row>

            <row>
              <entry>g</entry>

              <entry>0.131</entry>

              <entry>0.479</entry>

              <entry>0.019</entry>

              <entry>0.260</entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>

      <para>The table of selected 1 in Y AEP quantiles
      q<subscript>Y</subscript> and their 90% confidence limits further
      illustrates the benefit of incorporating regional information. For
      example, for the 1 in 100 AEP flood the 5% and 95% confidence limits are
      respectively 37% and 546% of the quantile q100 when no prior information
      is used. These limits are reduced to 46% and 292% using prior regional
      information.</para>

      <informaltable>
        <tgroup cols="7">
          <colspec/>

          <colspec/>

          <colspec/>

          <colspec/>

          <colspec/>

          <colspec align="center"/>

          <tbody>
            <row>
              <entry>1 in Y AEP</entry>

              <entry>No prior information Quantile
              q<subscript>Y</subscript></entry>

              <entry>No prior information Quantile confidence limits 5%
              limit</entry>

              <entry>No prior information Quantile confidence limits 95%
              limit</entry>

              <entry>With prior information Quantile
              q<subscript>Y</subscript></entry>

              <entry>With prior information Quantile confidence limits 5%
              limit</entry>

              <entry>With prior information Quantile confidence limits 95%
              limit</entry>
            </row>

            <row>
              <entry>10</entry>

              <entry>3928</entry>

              <entry>2228</entry>

              <entry>8408</entry>

              <entry>3597</entry>

              <entry>2171</entry>

              <entry>6702</entry>
            </row>

            <row>
              <entry>50</entry>

              <entry>12786</entry>

              <entry>5502</entry>

              <entry>51009</entry>

              <entry>10534</entry>

              <entry>5310</entry>

              <entry>26633</entry>
            </row>

            <row>
              <entry>100</entry>

              <entry>19572</entry>

              <entry>7188</entry>

              <entry>106933</entry>

              <entry>15412</entry>

              <entry>7092</entry>

              <entry>45086</entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>
    </section>

    <section>
      <title>Example 6: Censoring PILFs using multiple Grubbs-Beck
      test</title>

      <para>The multiple Grubbs-Beck test is recommended in all flood
      frequency analyses to identify potentially influential low flows
      (PILFs). This example is taken from Pedruco et al. (2013). The following
      table lists 56 years of annual maximum discharges for the Wimmera
      river:</para>

      <informaltable>
        <tgroup cols="7">
          <tbody>
            <row>
              <entry>464.35</entry>

              <entry>167.72</entry>

              <entry>119.63</entry>

              <entry>71.4</entry>

              <entry>32.18</entry>

              <entry>14.16</entry>

              <entry>8.52</entry>
            </row>

            <row>
              <entry>395.65</entry>

              <entry>155.22</entry>

              <entry>110.56</entry>

              <entry>69.67</entry>

              <entry>25.91</entry>

              <entry>12.64</entry>

              <entry>3.22</entry>
            </row>

            <row>
              <entry>285.92</entry>

              <entry>147</entry>

              <entry>102.62</entry>

              <entry>67.49</entry>

              <entry>24.83</entry>

              <entry>11.9</entry>

              <entry>2.28</entry>
            </row>

            <row>
              <entry>278.01</entry>

              <entry>143.99</entry>

              <entry>97.32</entry>

              <entry>61.64</entry>

              <entry>23.95</entry>

              <entry>11.79</entry>

              <entry>2.13</entry>
            </row>

            <row>
              <entry>235.22</entry>

              <entry>143.62</entry>

              <entry>96.78</entry>

              <entry>54.4</entry>

              <entry>22.76</entry>

              <entry>11.41</entry>

              <entry>1.9</entry>
            </row>

            <row>
              <entry>211.91</entry>

              <entry>142.66</entry>

              <entry>87.98</entry>

              <entry>38.62</entry>

              <entry>19.04</entry>

              <entry>10.8</entry>

              <entry>1.43</entry>
            </row>

            <row>
              <entry>173.79</entry>

              <entry>134.36</entry>

              <entry>79.15</entry>

              <entry>36.62</entry>

              <entry>17.37</entry>

              <entry>10.31</entry>

              <entry>1.16</entry>
            </row>

            <row>
              <entry>170.13</entry>

              <entry>123.8</entry>

              <entry>77.03</entry>

              <entry>34.07</entry>

              <entry>14.87</entry>

              <entry>10.08</entry>

              <entry>0.01</entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>

      <para>The following figure presents the probability plot for GEV
      distribution. The fit to the right-hand tail is problematic.</para>

      <figure>
        <title/>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE5_7.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>In FLIKE the multiple Grubbs-Beck test is implemented by clicking
      on the “censor” control as shown below. The dialog advises the multiple
      Grubbs-Beck test has identified 27 PILFs.</para>

      <figure>
        <title/>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE5_8.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>On agreeing to censor these flows, FLIKE automatically performs
      two changes to the inference setup:</para>

      <orderedlist>
        <listitem>
          <para>The 27 lowest flows are excluded from the calibration.</para>
        </listitem>

        <listitem>
          <para>The “censored data” dialog is populated with the information
          that there are 27 annual maximum flows that lie below the threshold
          of 54.399 which corresponds the rank-28 flow.</para>
        </listitem>
      </orderedlist>

      <para>The following two dialogs illustrate these changes:</para>

      <figure>
        <title/>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE5_9.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para/>

      <figure>
        <title/>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE5_10.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>The following probability plot demonstrates the substantially
      improved fit to the right-hand tail along with significantly tighter
      confidence limits:</para>

      <figure>
        <title/>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE5_11.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para/>
    </section>

    <section>
      <title>Example 7: Improving poor fits using censoring of low flow
      data</title>

      <para>The standard probability models such as GEV and LP3 may not
      adequately fit flood data for a variety of reasons. Often the poor fit
      is associated with a sigmoidal probability plot as illustrated in Figure
      E6-1. In such cases one can employ four or five-parameter distributions
      which have sufficient degrees of freedom to track the data in both upper
      and lower tails of the sigmoidal curve. Alternatively one can adopt a
      calibration approach that gives less weight to smaller floods. The
      latter approach is illustrated in this example which considers 50 annual
      maximum floods (m<superscript>3</superscript>/s) for the Albert River at
      Broomfleet presented in the following table:</para>

      <informaltable>
        <tgroup cols="10">
          <tbody>
            <row>
              <entry>13.02</entry>

              <entry>15.57</entry>

              <entry>15.85</entry>

              <entry>16.70</entry>

              <entry>22.36</entry>

              <entry>36.51</entry>

              <entry>72.73</entry>

              <entry>78.11</entry>

              <entry>87.73</entry>

              <entry>88.30</entry>
            </row>

            <row>
              <entry>95.65</entry>

              <entry>99.90</entry>

              <entry>113.77</entry>

              <entry>116.88</entry>

              <entry>124.52</entry>

              <entry>131.03</entry>

              <entry>156.22</entry>

              <entry>156.50</entry>

              <entry>190.74</entry>

              <entry>210.55</entry>
            </row>

            <row>
              <entry>220.74</entry>

              <entry>249.61</entry>

              <entry>249.61</entry>

              <entry>271.68</entry>

              <entry>285.83</entry>

              <entry>302.81</entry>

              <entry>305.64</entry>

              <entry>362.24</entry>

              <entry>384.88</entry>

              <entry>461.29</entry>
            </row>

            <row>
              <entry>466.95</entry>

              <entry>676.37</entry>

              <entry>752.78</entry>

              <entry>761.27</entry>

              <entry>761.27</entry>

              <entry>860.32</entry>

              <entry>863.15</entry>

              <entry>865.98</entry>

              <entry>1086.72</entry>

              <entry>1177.28</entry>
            </row>

            <row>
              <entry>1185.77</entry>

              <entry>1214.07</entry>

              <entry>1273.50</entry>

              <entry>1327.27</entry>

              <entry>1341.42</entry>

              <entry>1364.06</entry>

              <entry>1468.77</entry>

              <entry>1652.72</entry>

              <entry>1689.51</entry>

              <entry>1765.92</entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>

      <para>Figure E7-1 displays the GEV Bayesian fit on a Gumbel probability
      plot. Although the observed floods are largely contained within the 90%
      confidence limits, the fit, nonetheless, is poor – the data exhibit a
      sigmoidal trend with reverse curvature developing for floods with an AEP
      less than 1 in 2. It appears that the confidence limits have been
      inflated because the GEV fit represents a poor compromise. Figure E7-2
      displays the fit after censoring the 5 low outliers identified by the
      multiple Grubbs-Beck test. The improvement in fit is marginal at
      best.</para>

      <figure>
        <title>Bayesian fit to all gauged data</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE5_12.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para/>

      <figure>
        <title>Bayesian fit with 5 low outliers censored after application of
        multiple Grubbs-Beck test.</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE6_13.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>To deal with this poor fit, a trial-and-error approach based on
      censoring low flows can be used to obtain a fit that favours the right
      hand tail of the distribution. Figure E7-3 illustrates one such fit. To
      de-emphasize the left hand tail the floods below the threshold of 250
      m<superscript>3</superscript>/s were censored. This means the GEV
      distribution was fitted to:</para>

      <itemizedlist>
        <listitem>
          <para>A gauged record consisting of the 27 floods above 250
          m<superscript>3</superscript>/s; and</para>
        </listitem>

        <listitem>
          <para>A censored record consisting of 23 floods below the threshold
          of 250 m<superscript>3</superscript>/s and 0 floods above this
          threshold.</para>
        </listitem>
      </itemizedlist>

      <para>The censored record provides an anchor point for the GEV
      distribution – it ensures that the chance of an annual maximum flood
      being less than 250 m<superscript>3</superscript>/s is about 23/50
      without forcing the GEV to fit the peaks below the 250
      m<superscript>3</superscript>/s threshold. The fit effectively
      disregards floods with an AEP greater than 1 in 2 and provides a good
      fit to the upper tail. Another benefit is the substantially reduced 90%
      confidence range</para>

      <figure>
        <title>Bayesian fit with floods below 250 m3/s threshold treated as
        censored observations.</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE6_14.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>An alternative to this manual method for censoring is illustrated
      in Example 10 which presents the LH moments procedure for de-emphasizing
      low flows.</para>
    </section>

    <section>
      <title>Example 8: A Non-Homogeneous Flood Probability Model</title>

      <para>The work of Micevski et al. (2003) illustrates an example of a
      non-homogeneous model. An indicator time series based on the IPO time
      series (Figure 7) was used to create the exogeneous vector x</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mi>x</m:mi>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:msub>
                <m:mi>{I</m:mi>

                <m:mi>t</m:mi>
              </m:msub>

              <m:mo>, t = 1,...,n}</m:mo>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>where the indicator</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:msub>
              <m:mi>I</m:mi>

              <m:mi>t</m:mi>
            </m:msub>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mo>{</m:mo>

              <m:mtable>
                <m:mtr>
                  <m:mtd>
                    <m:mrow>
                      <m:mi>1 if</m:mi>

                      <m:msub>
                        <m:mi>IPO</m:mi>

                        <m:mi>t</m:mi>
                      </m:msub>

                      <m:mrow>
                        <m:mi>≥</m:mi>

                        <m:msub>
                          <m:mi>IPO</m:mi>

                          <m:mi>thresh</m:mi>
                        </m:msub>
                      </m:mrow>
                    </m:mrow>
                  </m:mtd>
                </m:mtr>

                <m:mtr>
                  <m:mtd>
                    <m:mrow>
                      <m:mi>0 if</m:mi>

                      <m:msub>
                        <m:mi>IPO</m:mi>

                        <m:mi>t</m:mi>
                      </m:msub>

                      <m:msub>
                        <m:mi>&lt; IPO</m:mi>

                        <m:mi>thresh</m:mi>
                      </m:msub>
                    </m:mrow>
                  </m:mtd>
                </m:mtr>
              </m:mtable>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>IPO<subscript>t</subscript> is the IPO index for year t and
      IPO<subscript>thresh</subscript> is a threshold value equal to
      -0.125.</para>

      <para>At each of the 33 NSW sites considered by Micevski et al. the AM
      peak flows were stratified according to the indicator It. A 2-parameter
      log-normal distribution was fitted to the gauged flows with indicator
      equal to 1 – this is the IPO+ distribution. Likewise, a 2-parameter
      log-normal distribution was fitted to the gauged flows with indicator
      equal to 0 – this is the IPO- distribution. Figure E3-1 presents the
      histogram for the ratio of the IPO- and IPO+ floods for selected 1 in Y
      AEPs. If the the IPO+ and IPO- distributions were homogeneous then about
      half of the sites should have a flood ratio &lt; 1 – Figure E8-1 shows
      otherwise.</para>

      <para>Figures E8-2 and E8-3 present log normal fits to the IPO+ and IPO-
      annual maximum flood data for the Clarence river at Lilydale
      respectively. Though the adequacy of the log normal model to fit high
      floods may be questioned, in the AEP range 1 in 2 to 1 in 10 years, the
      IPO- floods are about 2.6 times the IPO+ floods with the same
      AEP.</para>

      <figure>
        <title>Histogram of IPO- and IPO+ flood ratios.</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE6_15.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para/>

      <figure>
        <title>Log-normal fit to 43 years of IPO+ data for the Clarence river
        at Lilydale (units ML/day).</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE6_16.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para/>

      <figure>
        <title>Log-normal fit to 33 years of IPO- data for the Clarence river
        at Lilydale (units ML/day).</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE6_17.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <figure>
        <title>Log-normal fit to 76 years of data for the Clarence river at
        Lilydale (units ML/day).</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE6_18.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>To avoid bias in estimating long-term flood risk it is essential
      that the gauged record adequately span both IPO+ and IPO- years. In this
      example, the IPO+ record is 43 years and the IPO- record is 33 years in
      length. With reference to Figure 7 this length of record appears to
      adequately sample both IPO epochs. This suggests that fitting to all the
      data will yield a largely unbiased estimate of the long-term flood risk.
      Figure E8-4 illustrates a log normal fit to all the data.</para>

      <para>A better appreciation of the differences in flood risk can be
      gleaned by considering Figure E8-5 which presents the fitted log normal
      distributions to the IPO+, IPO- and total data. During an IPO+ period a
      flood peak of 100 m<superscript>3</superscript>/s has a 1 in 20 AEP
      while during an IPO- period it has a 1 in 4 AEP. Likewise a flood peak
      of 200 m<superscript>3</superscript> /s has 1 in 100 and 1 in 10 AEPs
      for IPO+ and IPO- periods respectively. The differences in flood risk
      are considerable. If a short gauged record falling largely in the IPO+
      period was used, a standard flood frequency analysis could seriously
      underestimate the long-term or marginal flood risk.</para>

      <para>The marginal flood risk can be derived by combining the IPO+ and
      IPO- distribution using eqn (8) to give</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mrow>
              <m:mi>P(Q≤</m:mi>

              <m:mo>q)</m:mo>

              <m:mi>=</m:mi>

              <m:mo>P(x</m:mo>
            </m:mrow>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mi>0)</m:mi>

              <m:mrow>
                <m:munderover>
                  <m:mo>∫</m:mo>

                  <m:mi>0</m:mi>

                  <m:mi>q</m:mi>
                </m:munderover>

                <m:mi>p(z|</m:mi>
              </m:mrow>

              <m:mi>θ(x=0))dz + P (x=1)</m:mi>

              <m:mrow>
                <m:munderover>
                  <m:mo>∫</m:mo>

                  <m:mi>0</m:mi>

                  <m:mi>q</m:mi>
                </m:munderover>

                <m:mi>p(z|</m:mi>
              </m:mrow>

              <m:mi>θ(x=1))dz</m:mi>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>The exogenous variable x can take two values, 0 or 1, depending on
      the IPO epoch. P(x=0), the probability of being in an IPO- epoch, is
      assigned the value 33/76 based on the observation that 33 of the 76
      years of record were in the IPO- epoch. Likewise P(x=1), the probability
      of being in an IPO+ epoch, is assigned the value 43/76. It follows that
      p(z|θ,x=0) and p(z|θ,x=1) are the log normal pdfs fitted to IOP- and
      IPO+ data respectively</para>

      <para>The derived marginal distribution is plotted in Figure E8-5. It
      almost exactly matches the log normal distribution fitted to all the
      data.</para>

      <figure>
        <title>Marginal, IPO+ and IPO+ log-normal distributions for the
        Clarence river at Lilydale</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE6_19.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>
    </section>

    <section>
      <title>Example 9: L moments fit to gauged data</title>

      <para>This example illustrates fitting a GEV distribution to gauged data
      using L moments. The following table lists 47 ranked annual maximum
      flood for the Styx River at Jeogla:</para>

      <informaltable>
        <tgroup cols="8">
          <tbody>
            <row>
              <entry>878</entry>

              <entry>541</entry>

              <entry>521</entry>

              <entry>513</entry>

              <entry>436</entry>

              <entry>411</entry>

              <entry>405</entry>

              <entry>315</entry>
            </row>

            <row>
              <entry>309</entry>

              <entry>300</entry>

              <entry>294</entry>

              <entry>258</entry>

              <entry>255</entry>

              <entry>235</entry>

              <entry>221</entry>

              <entry>220</entry>
            </row>

            <row>
              <entry>206</entry>

              <entry>196</entry>

              <entry>194</entry>

              <entry>190</entry>

              <entry>186</entry>

              <entry>177</entry>

              <entry>164</entry>

              <entry>126</entry>
            </row>

            <row>
              <entry>117</entry>

              <entry>111</entry>

              <entry>108</entry>

              <entry>105</entry>

              <entry>92.2</entry>

              <entry>88.6</entry>

              <entry>79.9</entry>

              <entry>74</entry>
            </row>

            <row>
              <entry>71.9</entry>

              <entry>62.6</entry>

              <entry>61.2</entry>

              <entry>60.3</entry>

              <entry>58</entry>

              <entry>53.5</entry>

              <entry>39.1</entry>

              <entry>26.7</entry>
            </row>

            <row>
              <entry>26.1</entry>

              <entry>23.8</entry>

              <entry>22.4</entry>

              <entry>22.1</entry>

              <entry>18.6</entry>

              <entry>13</entry>

              <entry>8.18</entry>

              <entry/>
            </row>
          </tbody>
        </tgroup>
      </informaltable>

      <para>The following table reports the results of estimating GEV
      parameters by substituting the L moment estimates in eqn (31) to obtain
      κ and then using the equations in Table 3 to estimate τ and α. The
      standard deviation and correlation were derived from 5000 bootstrapped
      samples following the procedure described in Section 6.4.6.</para>

      <informaltable>
        <tgroup cols="8">
          <tbody>
            <row>
              <entry>L moment estimates</entry>

              <entry>L moment estimates</entry>

              <entry>GEV parameter</entry>

              <entry>Parameter estimate</entry>

              <entry>Standard deviation</entry>

              <entry>Correlation</entry>

              <entry>Correlation</entry>

              <entry>Correlation</entry>
            </row>

            <row>
              <entry>λ<subscript>1</subscript></entry>

              <entry>189.238</entry>

              <entry>τ</entry>

              <entry>100.660</entry>

              <entry>17.657</entry>

              <entry>1.000</entry>

              <entry/>

              <entry/>
            </row>

            <row>
              <entry>λ<subscript>2</subscript></entry>

              <entry>92.476</entry>

              <entry>α</entry>

              <entry>104.157</entry>

              <entry>15.554</entry>

              <entry>0.597</entry>

              <entry>1.000</entry>

              <entry/>
            </row>

            <row>
              <entry>λ<subscript>3</subscript></entry>

              <entry>29.264</entry>

              <entry>κ</entry>

              <entry>-0.219</entry>

              <entry>0.130</entry>

              <entry>0.358</entry>

              <entry>0.268</entry>

              <entry>1.000</entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>

      <para>The following figure presents a probability plot of the gauged
      data along with GEV 1 in Y AEP quantiles and their 90% confidence
      limits. The confidence limits widen appreciably for the bigger floods –
      this is largely due to there being insufficient information to
      accurately infer the shape parameter κ.</para>

      <figure>
        <title/>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE6_20.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para/>
    </section>

    <section>
      <title>Example 10: Improving poor fits using LH moments</title>

      <para>This example is a continuation of Example 7. The GEV distribution
      was fitted to the gauged data for the Albert River at Broomfleet using
      LH moments.</para>

      <para>Figure E10-1 displays the GEV L moment fit on a Gumbel probability
      plot. Although the observed floods are largely contained within the 90%
      confidence limits, the fit, nonetheless, is poor with systematic
      departures from the data which exhibit reverse curvature.</para>

      <para>To deal with this poor fit, a LH moment search was conducted to
      find the optimal shift parameter η using the procedure described in
      Section 6.4.5. The optimal shift was found to be 4. Figure E10-2
      presents the LH moment fit with shift η equal to 4. The fit effectively
      disregards floods with an AEP in excess of 1 in 2 and provides a very
      good fit to upper tail.</para>

      <figure>
        <title>L moment fit</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE6_21.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para/>

      <figure>
        <title>LH moment fit with shift η=4</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE6_22.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>The very significant reduction in the width of the quantile
      confidence intervals is largely due to the shape parameter κ changing
      from –0.17 to 0.50. The L moment fit in Figure E10-1 was a compromise
      with the bulk of the small and medium-sized floods suggesting an upward
      curvature in the probability plot – as a result the GEV shape parameter
      κ had to be negative to enable upward curvature. In contrast, the LH
      moment fit favoured the large-sized floods which exhibit a downward
      curvature resulting in a positive shape parameter. For positive κ the
      GEV has an upper bound. In this case the upper bound is about 2070
      m<superscript>3</superscript>/s which is only 17% greater than the
      largest observed flood.</para>
    </section>

    <section>
      <title>Example 11: Fitting a probability model to POT data</title>

      <para>This example is a continuation of Example 9 which considers the
      Styx River at Jeogla. It illustrates fitting an exponential distribution
      to POT data. The table lists all the independent peak flows recorded
      over a 47 year period that exceeded a threshold of 74
      m<superscript>3</superscript>/s – the total number of peaks was 47.
      Comparison with the annual maximum flood peaks in Example 9 reveals that
      in 15 of the 47 years of record the annual maximum peak were below the
      threshold of 74 m<superscript>3</superscript>/s.</para>

      <informaltable>
        <tgroup cols="8">
          <tbody>
            <row>
              <entry>878</entry>

              <entry>541</entry>

              <entry>521</entry>

              <entry>513</entry>

              <entry>436</entry>

              <entry>411</entry>

              <entry>405</entry>

              <entry>315</entry>
            </row>

            <row>
              <entry>309</entry>

              <entry>301</entry>

              <entry>300</entry>

              <entry>294</entry>

              <entry>283</entry>

              <entry>258</entry>

              <entry>255</entry>

              <entry>255</entry>
            </row>

            <row>
              <entry>238</entry>

              <entry>235</entry>

              <entry>221</entry>

              <entry>220</entry>

              <entry>206</entry>

              <entry>196</entry>

              <entry>194</entry>

              <entry>190</entry>
            </row>

            <row>
              <entry>186</entry>

              <entry>164</entry>

              <entry>150</entry>

              <entry>149</entry>

              <entry>134</entry>

              <entry>129</entry>

              <entry>129</entry>

              <entry>126</entry>
            </row>

            <row>
              <entry>119</entry>

              <entry>118</entry>

              <entry>117</entry>

              <entry>117</entry>

              <entry>111</entry>

              <entry>108</entry>

              <entry>105</entry>

              <entry>98</entry>
            </row>

            <row>
              <entry>92.2</entry>

              <entry>92.2</entry>

              <entry>91.7</entry>

              <entry>88.6</entry>

              <entry>85.2</entry>

              <entry>79.9</entry>

              <entry>74</entry>

              <entry/>
            </row>
          </tbody>
        </tgroup>
      </informaltable>

      <para>The first two L moments were estimated as 226.36 and 79.2. Noting
      that the exponential distribution is a special case of the generalised
      Pareto when κ = 0, it follows from Table 3 that the exponential
      parameters are related to the L moments by</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:msub>
              <m:mi>λ</m:mi>

              <m:mi>1</m:mi>
            </m:msub>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:msub>
                <m:mi>q</m:mi>

                <m:mi>*</m:mi>
              </m:msub>

              <m:mo>+</m:mo>

              <m:mrow>
                <m:mi>β</m:mi>

                <m:mrow>
                  <m:msub>
                    <m:mi>λ</m:mi>

                    <m:mi>2</m:mi>
                  </m:msub>

                  <m:mo>=</m:mo>

                  <m:mfrac>
                    <m:mi>β</m:mi>

                    <m:mi>2</m:mi>
                  </m:mfrac>
                </m:mrow>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>which yields values for q* and β of 68.11 and 158.24 respectively.
      Using eqn (B1-7), the expected number of peaks that exceed w in a
      yea</para>

      <para>r is</para>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mi>EY (w)</m:mi>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mi>vP(q&gt;w)</m:mi>

              <m:mrow>
                <m:mo>=</m:mo>

                <m:mrow>
                  <m:mi>v exp</m:mi>

                  <m:mrow>
                    <m:mo>(</m:mo>

                    <m:mrow>
                      <m:mi>-</m:mi>

                      <m:mfrac>
                        <m:mi>w-q</m:mi>

                        <m:mi>β</m:mi>
                      </m:mfrac>
                    </m:mrow>

                    <m:mo>)</m:mo>
                  </m:mrow>
                </m:mrow>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <equation>
        <m:math display="block">
          <m:mrow>
            <m:mrow>
              <m:msub>
                <m:mi>log</m:mi>

                <m:mi>e</m:mi>
              </m:msub>

              <m:mo>EY(w)</m:mo>
            </m:mrow>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mrow>
                <m:msub>
                  <m:mi>log</m:mi>

                  <m:mi>e</m:mi>
                </m:msub>

                <m:mo>v</m:mo>
              </m:mrow>

              <m:mo>+</m:mo>

              <m:mrow>
                <m:mfrac>
                  <m:mi>q</m:mi>

                  <m:mi>β</m:mi>
                </m:mfrac>

                <m:mo>-</m:mo>

                <m:mfrac>
                  <m:mi>w</m:mi>

                  <m:mi>β</m:mi>
                </m:mfrac>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>where v is the average number of flood peaks above the threshold
      q* per year.</para>

      <para>Given that 47 peaks above the threshold occurred in 47 years, v
      equals 1.0. The following figure presents a plot of the fitted POT
      exponential model against the observed POT series.</para>

      <figure>
        <title/>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures\FigureE6_23.JPG"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para/>
    </section>
  </section>
</chapter>

