<?xml version="1.0" encoding="UTF-8"?>
<section status="In Preparation" version="5.0" xml:id="b3_ch2_s3"
         xmlns="http://docbook.org/ns/docbook"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:svg="http://www.w3.org/2000/svg"
         xmlns:m="http://www.w3.org/1998/Math/MathML"
         xmlns:html="http://www.w3.org/1999/xhtml"
         xmlns:db="http://docbook.org/ns/docbook">
  <title>Selection and Preparation of Data</title>

  <section xml:id="b3_ch2_s_tz98n">
    <title>Requirements of Data for Valid Analysis</title>

    <para>For a valid frequency analysis, the data used should constitute a random sample of
      independent values, ideally from a homogeneous population. Streamflow data are collected as a
      continuous record, and discrete values must be extracted from this record as the events to be
      analysed. The problem of assessing independence of events, and of selecting all independent
      events, is illustrated by the streamflow record for a 1000 km<superscript>2</superscript>
      catchment in <xref linkend="b3_ch2_f_m34sp"/>. It is clear that peaks A and B are not
      independent of each other but are serially correlated, while peak D is independent of A and B.
      However, the independence of peak C in regards to A and B is open to question, as it is
      difficult to determine the independent peaks in the record  - B and D, or B, C and D. Methods
      for selecting the peaks included in the analysis are described in the following
      subsections.</para>

    <figure xml:id="b3_ch2_f_m34sp">
      <title>Hydrograph for a 1000 km<superscript>2</superscript> Catchment Illustrating Difficulty
        of Assessing Independence of Floods</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3003.png"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>Lack of homogeneity of the population of floods is another practical problem, especially
      if the data sample from the past is used to derive flood estimates applicable to the design
      life of the structure or works in future. Examples of changes in collection of data or in the
      nature of the catchment that lead to lack of homogeneity are:</para>

    <orderedlist>
      <listitem>
        <para>Inability to allow for change of station rating curve, for example, resulting from
          insufficient high-stage gauging;</para>
      </listitem>

      <listitem>
        <para>Change of gauging station site;</para>
      </listitem>

      <listitem>
        <para>Construction of large storages, levees and channel
        improvements;</para>
      </listitem>

      <listitem>
        <para>Growth in the number of farm dams on the catchment; and</para>
      </listitem>

      <listitem>
        <para>Changes in land use such as clearing, different farming
        practices, soil conservation works, re-forestation, and
        urbanisation.</para>
      </listitem>
    </orderedlist>

    <para>The record should be carefully examined for these and other causes of lack of homogeneity.
      In some cases, recorded values can be adjusted by means such as routing pre-dam floods through
      the storage to adjust them to equivalent present values, correcting rating errors wherever
      possible, or making some adjustment for urbanisation. Such decisions must be made largely by
      judgement. As with all methods of flood estimation, it is important that likely conditions
      during the design life are considered, instead of existing conditions at the time of design.
      Some arbitrary adjustment of derived values for likely changes in the catchment may be
      possible, but the recorded data must generally be accepted for analysis and design.
      Fortunately, the available evidence indicates that unless changes to the catchment involve
      large proportions of the total area or large changes in the storage on the catchment, the
      effects on flood magnitudes are likely to be low. In addition, the effects are likely to be
      larger for frequent floods than for the rare floods that are of primary interest in
      design.</para>
  </section>

  <section xml:id="b3_ch2_s_h8d0j">
    <title>Types of Flood Data</title>

    <para>In the most general sense, flood peak data can be classified as
    either being gauged or censored.</para>

    <section xml:id="b3_ch2_s_decod">
      <title>Gauged Data</title>

      <para>Gauged data consists of a time series of flood discharge estimates. Such estimates are
        based on observed peak (or instantaneous) stages (or water levels). A rating curve is used
        to transform stage observations to discharge estimates. When extrapolated, the rating curve
        can introduce large systematic errors into discharge estimates.</para>

      <para>It is important to check how the peak discharges were obtained from the gauged record.
        Peak discharges may be derived from daily readings, possibly with some intermediate readings
        during some floods, for part of the record, and continuous readings from the remainder of
        the record. If part of the record consists of daily readings, it is necessary to assess
        whether daily readings adequately approximate the instantaneous peak discharge (refer to
          <xref linkend="b3_ch2_s_cli4f"/> for instances of adequate and inadequate approximations).
        If the daily reading is deemed as an unreliable estimate of the peak discharge during that
        day, the reading need not be discarded but treated as a censored discharge.</para>
    </section>

    <section xml:id="b3_ch2_s_2c66l">
      <title>Censored Data</title>

      <para>Censored data consists of a time series of indicator values
      defined as:</para>

      <equation xml:id="b3_ch2_e_dds1u">
        <math display="block" xmlns="http://www.w3.org/1998/Math/MathML">
          <semantics>
            <mrow>
              <msub>
                <mi>I</mi>
                <mi>t</mi>
              </msub>
              <mrow>
                <mo>(</mo>
                <mi>q</mi>
                <mo>)</mo>
              </mrow>
              <mo>=</mo>
              <mrow>
                <mo>{</mo>
                <mrow>
                  <mtable>
                    <mtr>
                      <mtd>
                        <mrow>
                          <mn>1</mn>
                          <msup>
                            <mrow>
                              <mtext>&#x00A0;if&#x00A0;t</mtext>
                            </mrow>
                            <mrow>
                              <mi>t</mi>
                              <mi>h</mi>
                            </mrow>
                          </msup>
                          <mtext>&#x00A0;flood&#x00A0;peak&#x00A0;&#x003E;&#x00A0;threshold&#x00A0;&#x00A0;</mtext>
                          <mi>q</mi>
                        </mrow>
                      </mtd>
                    </mtr>
                    <mtr>
                      <mtd>
                        <mrow>
                          <mo>&#x2212;</mo>
                          <mn>1</mn>
                          <msup>
                            <mrow>
                              <mtext>&#x00A0;if&#x00A0;t</mtext>
                            </mrow>
                            <mrow>
                              <mi>t</mi>
                              <mi>h</mi>
                            </mrow>
                          </msup>
                          <mtext>&#x00A0;flood&#x00A0;peak&#x00A0;</mtext>
                          <mo>&#x2264;</mo>
                          <mtext>&#x00A0;threshold&#x00A0;&#x00A0;</mtext>
                          <mi>q</mi>
                        </mrow>
                      </mtd>
                    </mtr>
                  </mtable>
                  <mtext>&#x00A0;</mtext>
                </mrow>
                <mo>}</mo>
              </mrow>
            </mrow>
          </semantics>
        </math>
      </equation>

      <para>They arise in a number of ways. For example, prior to gauging, water level records may
        be kept only for rare floods above some perception threshold. Therefore, all we may know is
        that there were n<subscript>a</subscript> flood peaks above the threshold and
          n<subscript>b</subscript> peaks below the threshold. Sometimes, frequent floods below a
        certain threshold may be deliberately excluded, since the overall fit gets unduly influenced
        by small floods.</para>

      <para><xref linkend="b3_ch2_f_ujoua"/> presents a graphical depiction of gauged and censored
        time series data. In the first part of the record, all the peaks are below a threshold,
        while in the second part, daily readings define a lower threshold for the peak. Finally, in
        the third part, continuous gauging yields instantaneous peaks.</para>

      <figure xml:id="b3_ch2_f_ujoua">
        <title>Depiction of Censored and Gauged Flow Time Series Data</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="../../figures/3004.png" scalefit="1"
                       width="100%"/>
          </imageobject>
        </mediaobject>
      </figure>
    </section>
  </section>

  <section xml:id="b3_ch2_s_0lquj">
    <title>Annual Maximum Flood Gauged Series</title>

    <para>This is the most common method of selecting the floods to be analysed. The series
      comprised of the highest instantaneous rate of discharge in each year of record. The year may
      either be a calendar year or a water year, the latter usually commencing at the end of the
      period of lowest average flow during the year. Where flows are highly seasonal, especially
      with a wet summer, use of the water year is preferable. The highest flow in each year is
      selected, whether it is a major flood or not, and all other floods are neglected, even though
      some will be much larger than the maximum discharges selected from some other years. For
        <emphasis>n</emphasis> years of data, the annual flood series will consist of
        <emphasis>n</emphasis> values.</para>

    <para>The Annual Maximum series has at least two advantages:</para>

    <orderedlist>
      <listitem>
        <para>As the individual annual maximum discharges are likely to be separated by considerable
          intervals of time, it is probable that the values will be independent. Checking the dates
          of the annual maxima to ensure that they are likely to be independent, is a simple
          procedure that should be followed. If the highest annual value occurred at the start of a
          year and was judged to be dependent on the annual maximum at the end of the previous year,
          the lower of these two values should be discarded and the second highest discharge in that
          year substituted.</para>
      </listitem>

      <listitem>
        <para>The series is easily and unambiguously extracted. Most data
        collection agencies have annual maxima on computer file and/or hard
        copy.</para>
      </listitem>
    </orderedlist>
  </section>

  <section xml:id="b3_ch2_s_5sti1">
    <title>Peak-Over-Threshold Gauged Series</title>

    <para>A POT flood series consists of all floods with peak discharges above a selected base
      value, regardless of the number of such floods occurring each year. The POT series is also
      referred to as the partial duration series or basic stage series. The number of floods
        <emphasis>m</emphasis> generally will be different to the number of years of record
        <emphasis>n</emphasis>, and will depend on the selected base discharge.
        <citation>b3_c2_r5+1</citation> recommended that the base discharge should be selected so
      that <emphasis>m</emphasis> is greater than <emphasis>n</emphasis>, but that there should not
      be more than 3 or 4 floods above the base in any one year. These two requirements can be
      incompatible. The U.S. Geological Survey <citation>b3_c2_r23</citation> recommended that
        <emphasis>m</emphasis> should equal 3<emphasis>n</emphasis>. If a probability distribution
      is to be fitted to the POT series, the desirable base discharge and average number of floods
      per year selected depend on the type of distribution. These distributions are discussed
      further in <xref linkend="b3_ch2_s_r1114"/>. For the compound model using a Poisson
      distribution of occurrences and an exponential distribution of magnitudes,
        <citation>b3_c2_r72+1</citation>, and <citation>b3_c2_r39+1</citation> found that
        <emphasis>m</emphasis> should equal 2<emphasis>n</emphasis> or greater, and the U.K Flood
      Studies Report <citation>b3_c2_r57</citation> recommended that m should equal
        3<emphasis>n</emphasis> to 5<emphasis>n</emphasis>. For fitting the Log Pearson III (LP III)
      distribution, the values of the moments depend on the number of floods selected and the base
      discharge. <citation>b3_c2_r51+1</citation> and <citation>b3_c2_r39+1</citation> found that
      best results were obtained in this case when <emphasis>m</emphasis> equalled
        <emphasis>n</emphasis>.</para>

    <para>An important advantage of the POT series is that when the selected base value is
      sufficiently high, small events that are not really floods are excluded. With the AM series,
      non-floods in dry years may have an undue influence on shape of the distribution. This is
      particularly important for Australia, where both the range of flows and the non-occurrence of
      floods are greater than in many other countries such as the United States and the United
      Kingdom. For this reason it would also be expected that the desirable ratio of
        <emphasis>m</emphasis> to <emphasis>n</emphasis> would be lower in Australia than in these
      countries (refer to <xref linkend="b3_ch2_s_5sti1"/>).</para>

    <para>A criterion for independence of successive peaks must also be applied in selecting events.
      As discussed by <citation>b3_c2_r48+1</citation>, statistical independence requires physical
      independence of the causative factors of the flood, mainly rainfall and antecedent wetness.
      This type of independence is necessary if the POT series is used to estimate the distribution
      of annual floods. On the other hand, selection of POT series floods for design flood studies
      should consider the consequences of the flood peaks in assessing independence of events where
      damages or financial penalties are the most important design variables. Factors to be
      considered might include duration of inundation and the time required to repair flood damage.
      In both cases, the size or response time of the catchment will have some effect.</para>

    <para>The decision regarding a criterion for independence, therefore requires subjective
      judgement by the practitioner, designer or analyst in each case. There is often conflict that
      some flood effects are short-lived, perhaps only as long as inundation, while others, such as
      the destruction of an annual crop, may last as long as a year. It is thus not possible to
      recommend a simple and clear-cut criterion for independence. The circumstances and objectives
      of each study, and the characteristics of the catchment and flood data, should be considered
      in each case before a criterion is adopted. It is inevitable that the adopted criterion will
      be arbitrary to some extent.</para>

    <para>While no specific criterion can be recommended, it may be helpful to consider some
      criteria that were used in past studies:</para>

    <itemizedlist>
      <listitem>
        <para>Bulletin 17B of the <citation>b3_c2_r38+1</citation> states that no general criterion
          can be recommended and the decision should be based on the intended use in each case, as
          discussed above. However, in Appendix 14 of that document, a study by
            <citation>b3_c2_r12+1</citation> is summarised where the criterion is that it should use
          independent flood peaks should be separated by five days plus the natural logarithm of the
          square miles of drainage area, with the additional requirement that intermediate
          discharges must drop to below 75% of the lower of the two separate flood peaks. This may
          only be suitable for catchments larger than 1000 km<superscript>2</superscript>.
            <citation>b3_c2_r39+1</citation> used this criterion.</para>
      </listitem>

      <listitem>
        <para>The UK Flood Studies Report <citation>b3_c2_r57</citation> used a criterion that flood
          peaks should be separated by three times the time to peak and that the flow should
          decrease between peaks to two-thirds of the first peak.</para>
      </listitem>

      <listitem>
        <para><citation>b3_c2_r53+1</citation>, in developing design rainfall data for flood
          estimation, used the following criteria, based on the rainfall causing the floods:</para>

        <itemizedlist>
          <listitem>
            <para>For rainfalls of short duration up to two hours, only the
            one highest flood within a period of 24 hours.</para>
          </listitem>

          <listitem>
            <para>For longer rainfalls, a period of 24 hours in which no more
            than 5 mm of rain could occur between rain causing separate flood
            events.</para>
          </listitem>
        </itemizedlist>
      </listitem>
    </itemizedlist>

    <itemizedlist>
      <listitem>
        <para>In a study of small catchments, <citation>b3_c2_r62+1</citation> used a criterion of
          three calendar days between separate flood events but lesser events could occur in the
          intervening period. This was the most satisfactory of five criteria tested on data from
          seven small catchments located throughout eastern New South Wales. It also gave the
          closest approximation to the above criteria used by
          <citation>b3_c2_r53+1</citation>.</para>
      </listitem>

      <listitem>
        <para><citation>b3_c2_r60+1</citation> and <citation>b3_c2_r52+1</citation> adopted monthly
          maximum peak flows to give an effective criterion of independence in developing a design
          procedure for small to medium sized catchments. This was based primarily on the assumption
          that little additional damage would be caused by floods occurring within a month, and thus
          closer floods would not be independent in terms of their effects. This criterion was also
          used by <citation>b3_c2_r2+1</citation> and <citation>b3_c2_r1+1</citation>.</para>
      </listitem>
    </itemizedlist>

    <para>The criteria cited above represent a wide range and illustrate the difficult and
      subjective nature of the choice. It is stressed that these criteria have been described for
      illustrative purposes only. In each particular application the practitioner, designer or
      analyst should choose a criterion suitable to the analysis and relevant to all of the
      circumstances and objectives.</para>
  </section>

  <section xml:id="b3_ch2_s_2kxei">
    <title>Monthly and Seasonal Gauged Series</title>

    <para>In some circumstances, series other than the AM or POT series may be
    used. The monthly and seasonal series are the most useful.</para>

    <para>Maximum monthly flows are an approximation to the POT series in most parts of Australia,
      as the probability of two large independent floods occurring in the same month is low.
      Tropical northern Australia, the west coast of Tasmania and the south-west of Western
      Australia may be exceptions. It should be noted that not every monthly maximum flood will be
      selected, but only those large enough to exceed a selected base discharge, as is the case for
      the POT series. The monthly series has two important advantages over the POT series, which it
      approximates:</para>

    <orderedlist>
      <listitem>
        <para>It is more easily extracted, as most gauging authorities have monthly maximum
          discharges on file.</para>
      </listitem>

      <listitem>
        <para>It can be argued that a flood occurring within a month of a
        previous large flood is of little concern in design, as repairs will
        not have been undertaken and little additional damage will
        result.</para>
      </listitem>
    </orderedlist>

    <para>With the monthly series, care is required to check any floods selected in successive
      months for independence. Where the dates are close, the lower value should be discarded. The
      second highest flood in that month could then be checked from the records, but this would
      generally not be worthwhile. An example of use of the monthly series is described by
        <citation>b3_c2_r61+1</citation>.</para>

    <para>Seasonal flood frequencies are sometimes required. For these cases,
    the data are selected for the particular month or season as for the annual
    series, and the flood frequency analysis is carried out in a similar
    fashion to that for the annual series.</para>
  </section>

  <section xml:id="b3_ch2_s_123dw">
    <title>Extension of Gauged Records</title>

    <para>It may sometimes be possible to extend the recorded data by values estimated from longer
      records on adjacent catchments, by use of a catchment rainfall-runoff model, or by use of
      historical data from before the commencement of records. If this can be done validly, the
      effective sample size of the data will be increased and the reliability of the analysis will
      be greater. However, care is necessary to ensure that the extended data is valid and real
      information has been added. Several procedures can be used and are outlined in the following
      sections:</para>
    <itemizedlist>
      <listitem>
        <para>Regression Relationship with Data from an Adjacent Catchment</para>
      </listitem>
      <listitem>
        <para>Use of a Catchment Rainfall-Runoff Model</para>
      </listitem>
      <listitem>
        <para>Station-Year Method</para>
      </listitem>
    </itemizedlist>

    <section xml:id="b3_ch2_s_dikhk">
      <title>Regression Relationship with Data from an Adjacent
      Catchment</title>

      <para>If a regression of flood peaks for the study catchment on peaks for an adjacent
        catchment can be established for the period of concurrent record, the relation can be used
        to estimate values for the study catchment for a longer period, when records are only
        available on the adjacent catchment. The data should first be plotted on linear and log-log
        scales. A regression equation can then be fitted to the values or alternatively, the
        graphical relation can be used directly with a smooth curve fitted by eye.</para>

      <para>The principal shortcoming of the regression approach is that uncertainty in the transfer
        process is ignored resulting in an overstatement of information content. To guard against
        this, an approximate criterion for deciding whether the regression should be used is that
        the correlation coefficient of the relation should exceed 0.85
          <citation>b3_c2_r28,b3_c2_r50</citation>. More rigorous criteria are discussed in ARR 1987
        Book 3 Section 2.6.5.</para>

      <para>Care is needed when annual floods are used. The dates of the corresponding annual floods
        on the adjacent catchments should be compared. Not infrequently, the dates are different,
        resulting in a lack of physical basis for the relation. Although relationships of this type
        seem to have been used in some regional flood frequency procedures, it is recommended that
        regressions should only be used when the corresponding floods result from the same storm.
        This problem is discussed further by <citation>b3_c2_r62+1</citation>.</para>

      <para>When floods resulting from the same storm on adjacent catchments are plotted against
        each other, there is often a large scatter. Frequently, a large flood occurs on one
        catchment but only a small flood occurs on the other. The scatter is generally greater than
        for the physically unrealistic relation using floods which are the maximum annual values on
        the two catchments but which may have occurred on different dates. The resulting relation
        using floods that occurred in the same storm is often so weak that it should not be used to
        extend records.</para>

      <para><citation>b3_c2_r77+1</citation> describes a Bayesian approach that rigorously makes
        allowance for the noise in the transfer process. This approach is considered superior to the
        traditional regression transfer.</para>
    </section>

    <section xml:id="b3_ch2_s_p0pug">
      <title>Use of a Catchment Rainfall-Runoff Model</title>

      <para>A catchment rainfall-runoff model can range from a simple rainfall-runoff regression to
        a catchment modelling system that simulates either continuous runoff hydrographs or single
        event hydrograph from rainfall data. This discussion relates primarily to the latter type of
        model. The calibration of such a model for a period with concurrent rainfall and runoff
        records and its subsequent use to extend streamflow records for the period when rainfall
        data are available, while an attractive approach, should only be used with great caution.
        Appreciable differences often occur between observed and modelled runoff, especially in
        periods not used in calibration and in periods with runoff not represented in the
        calibration. Estimation of model parameters involves considerable uncertainty. Greatest
        accuracy in modelling can be expected in calculating discharges around the mean value, and
        larger errors are likely in extreme values such as the large flood peaks required for
        frequency analysis. Overall, the use of catchment models to extend flood records should be
        adopted with caution.</para>
    </section>

    <section xml:id="b3_ch2_s_h1o3h">
      <title>Station-Year Method</title>

      <para>This method is included only to warn against its shortcomings. In this procedure,
        records from several adjacent catchments are joined "end-to-end" to give a single record
        equal in length to the sum of the lengths of the constituent records. As discussed by
          <citation>b3_c2_r15+1</citation> for rainfall data, spatial correlation between the
        records of the adjacent stations invalidates the procedure.</para>
    </section>
  </section>

  <section xml:id="b3_ch2_s_zlx6z">
    <title>Rating Curve Error in Gauged Discharges</title>

    <para>Though it is widely accepted that discharge estimates for large
    floods can be in considerable error, there is limited published
    information on these errors and how they can be allowed for in a Flood
    Frequency Analysis. Rating error can arise from a number of
    mechanisms:</para>

    <orderedlist>
      <listitem>
        <para>For large floods the rating curve typically is extrapolated or
        fitted to indirect discharge estimates. This can introduce a
        systematic but unknown bias.</para>
      </listitem>

      <listitem>
        <para>If the gauging station is located at a site with an unstable cross-section the rating
          curve may shift causing a systematic but unknown bias.</para>
      </listitem>
    </orderedlist>

    <para>The conceptual model of rating error presented in this section is based on
        <citation>b3_c2_r45+1</citation> and is considered to be rudimentary and subject to
      refinement. It is assumed the cross-section is stable with the primary source of rating error
      arising from extension of the rating curve to large floods.</para>

    <para><citation>b3_c2_r63+1</citation> and <citation>b3_c2_r64+1</citation> observe that flood discharge is inferred from a
      rating curve which is subject to discontinuous measurement error. Consider <xref
        linkend="b3_ch2_f_fms8f"/> which depicts a rating curve with two regions having different
      error characteristics. The interpolation zone consists of that part of the rating curve well
      defined by discharge-stage measurements; typically the error Coefficient of Variation (CV)
      would be small, say 1 to 5%. In the extension zone the rating curve is extended by methods
      such as slope-conveyance, log-log extrapolation or fitting to indirect discharge estimates.
      Typically such extensions are smooth and, therefore, can induce systematic under- or
      over-estimation of the true discharge over a range of stages. The extension error CV is not
      well known but <citation>b3_c2_r63,b3_c2_r64</citation> suggest it may be as high as
      30%.</para>

    <para><xref linkend="b3_ch2_f_fms8f"/> and <xref linkend="b3_ch2_f_j4g36"/> illustrate two cases
      of smooth rating curve extension wherein systematic error is introduced. In <xref
        linkend="b3_ch2_f_fms8f"/>, the estimate was below the true discharge. In the absence of any
      other information the rating curve is extended to pass smoothly through this point thereby
      introducing a systematic underestimate of large flood discharges. Even if more than one
      indirect discharge estimate were available, it is likely the errors will be correlated because
      the same biases in estimating Manning's n, conveyance and friction slope would be
      present</para>

    <para>In <xref linkend="b3_ch2_f_j4g36"/> the rating curve is extended
    using the slope-conveyance method. The method relies on extrapolating
    gauged estimates of the friction slope so that the friction slope
    asymptotes to a constant value. Depending on how well the approach to
    asymptotic conditions is defined by the data considerable systematic error
    in extrapolation may occur. Perhaps of greater concern is the assumption
    that Manning's n and conveyance can be reliably estimated in the overbank
    flow regime particularly when there are strong contrasts in roughness
    along the wetted perimeter.</para>

    <para>Though <xref linkend="b3_ch2_f_fms8f"/> represents an idealisation
    of actual rating curve extension two points of practical significance are
    noted:</para>

    <orderedlist>
      <listitem>
        <para>The error is systematic in the sense that the extended rating curve is likely to
          diverge from the true rating curve as discharge increases. The error, therefore, is likely
          to be highly correlated- in fact, it is perfectly correlated in the idealisation of <xref
            linkend="b3_ch2_f_fms8f"/>.</para>
      </listitem>

      <listitem>
        <para>The interpolation zone anchors the error in the extension zone.
        Therefore, the error in the extension zone depends on the distance
        from the anchor point and not from the origin. This error is termed
        incremental because it originates from the anchor point rather than
        the origin of the rating curve.</para>
      </listitem>
    </orderedlist>

    <figure xml:id="b3_ch2_f_fms8f">
      <title>Rating Curve Extension by Fitting to an Indirect Discharge Estimate</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3005.png"/>
        </imageobject>
      </mediaobject>
    </figure>

    <figure xml:id="b3_ch2_f_j4g36">
      <title>Rating Curve Extension by Slope-Conveyance Method</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3006.png"/>
        </imageobject>
      </mediaobject>
    </figure>
  </section>

  <section xml:id="b3_ch2_s_22h0g">
    <title>Historical and Paleo Flood Information</title>

    <para>A flood may have occurred before the period of gauged record and
    known to be the largest flood, or flood of other known rank, over a period
    longer than that of the gauged record. Such floods can provide valuable
    information and should be included in the analysis if possible.</para>

    <para>Care is needed in assessing historical floods. Only stages are
    usually available, and these may be determined by flood marks recorded on
    buildings or structures, by old newspaper reports, or from verbal
    evidence. Newspaper or other photographs can provide valuable information.
    Verbal evidence is often untrustworthy, and structures may have been
    moved. A further problem is that the channel morphology, and hence the
    stage-discharge relation of the stream, may have changed from those
    applying during the period of gauged record.</para>

    <para>It is desirable to carry out Flood Frequency Analyses both by
    including and excluding the historical data. The analysis including the
    historical data should be used unless in the comparison of the two
    analyses, the magnitudes of the observed peaks, uncertainty regarding the
    accuracy of the historical peaks, or other factors, suggest that the
    historical peaks are not indicative of the extended period or are not
    accurate. All decisions made should be thoroughly documented.</para>

    <para>Considerable work has been carried out in the United States on the assessment of
      paleofloods. These are major floods that have occurred outside the historical record, but
      which are evidenced by geological, geomorphological or botanical information. Techniques of
      paleohydrology have been described by <citation>b3_c2_r18+1</citation>, <citation>b3_c2_r19+1</citation>, <citation>b3_c2_r20+1</citation> and
        <citation>b3_c2_r42+1</citation> and more recently by <citation>b3_c2_r58+1</citation>, and
      a succinct summary is given by <citation>b3_c2_r71+1</citation>. Although high accuracy is not
      possible with these estimates, they may only be marginally less accurate than other estimates
      requiring extrapolation of rating curves, and they have the potential for greatly extending
      the database and providing valuable information on the tail of the underlying flood
      distribution. A procedure for assessing the value of paleoflood estimates of Flood Frequency
      Analysis is given by <citation>b3_c2_r36+1</citation>. Only a little work on this topic has
      been carried out in Australia, but its potential has been indicated by its use to identify the
      five largest floods in the last 700 years in the Finke River Gorge in central Australia
        <citation>b3_c2_r10,b3_c2_r9</citation>, and for more frequent floods, by identification of
      the six largest floods that occurred since a major flood in 1897 on the Katherine River in the
      Northern Territory <citation>b3_c2_r9</citation>. While the use of paleoflood data should be
      considered, it needs to be recognized that there are not many sites where paleofloods can be
      estimated and that climate changes may have affected the homogeneity of long-term flood
      data.</para>
  </section>

  <section xml:id="b3_ch2_s_6tc4c">
    <title>Data Characterising Long-Term Climate Persistence</title>

    <para>There is growing evidence that flood peaks are not identically distributed from year to
      year in some parts of Australia and that flood risk is dependent on long-term climate
      variability. The idea of alternating flood and drought dominated regimes that exist on decadal
      and longer timescales was first proposed by <citation>b3_c2_r27+1</citation>. More recently,
      analyses of changes in climate state affecting flood risk have been published (refer to
        <citation>b3_c2_r31+1</citation>, <citation>b3_c2_r32+1</citation>, and
        <citation>b3_c2_r33+1</citation>). The climate-dependence of flood risk is an important
      consideration when assessing flood risk. Most flood frequency applications will require
      assessment of long-term flood risk; that is, flood risk that is independent of a particular
      current climate state. If a flood record is sufficiently long to sample all climate states
      affecting flood risk, a traditional analysis assuming homogeneity will yield the long-term
      flood risk. Unfortunately many flood records are relatively short and may be dominated by one
      climate state. Blind use of such data can result in substantial bias in long-term flood risk
      estimates. For this reason it may be necessary to obtain climate index data which
      characterizes long-term persistence in climate and to investigate the homogeneity of the flood
      distribution.</para>

    <para>A number of known climate phenomena impact on Australian climate variability. Most well
      known is the inter-annual El Nino/Southern Oscillation (ENSO). The cold ENSO phase, La Nina,
      results in a marked increase in flood risk across Eastern Australia, whereas El Nino years are
      typically without large floods <citation>b3_c2_r41</citation>.</para>

    <para>There is also mounting evidence that longer-term climate processes also have a major
      impact on flood risk. The Interdecadal Pacific Oscillation (IPO) is a low frequency climate
      process related to the variable epochs of warming and cooling in the Pacific Ocean and is
      described by an index derived from low pass filtering of Sea Surface Temperature (SST)
      anomalies in the Pacific Ocean <citation>b3_c2_r65,b3_c2_r66,b3_c2_r4</citation>. The IPO is
      similar to the Pacific Decadal Oscillation (PDO) of <citation>b3_c2_r49+1</citation>, which is
      defined as the leading principal component of North Pacific monthly sea surface temperature
      variability.</para>

    <para>The IPO time series from 1870 is displayed in <xref linkend="b3_ch2_f_6x7dy"/>. It reveals
      extended periods where the index either lies below or above zero.
        <citation>b3_c2_r66+1</citation> have shown that the association between ENSO and Australian
      climate is modulated by the IPO- a strong association was found between the magnitude of ENSO
      impacts during negative IPO phases, whilst positive IPO phases showed a weaker, less
      predictable relationship. Additionally, <citation>b3_c2_r41+1</citation> and
        <citation>b3_c2_r40+1</citation> analysed New South Wales flood and drought data and
      demonstrated that the IPO negative state magnified the impact of La Nina events. Moreover,
      they demonstrated that the IPO negative phase, related to mid-latitude Pacific Ocean cooling,
      appears to result in an increased frequency of cold La Nina events. The net effect of the dual
      modulation of ENSO by IPO is the occurrence of multi-decadal periods of elevated and reduced
      flood risk. To place this in context, <xref linkend="b3_ch2_f_fy36g"/> shows regional flood
      index curves based on about 40 NSW sites for the different IPO states
        <citation>b3_c2_r41</citation> – the 1% AEP flood during years with a positive IPO index
      corresponds to the 1 in 6 AEP flood during years with a negative IPO index.
        <citation>b3_c2_r56+1</citation> investigating a range of sites in NSW found that floods
      occurring during IPO negative periods were, on average, about 1.8 times bigger than floods
      with the same frequency during IPO positive periods.</para>

    <para>A key area of current research is the spatial variability of ENSO and IPO impacts. The
      associations between ENSO, IPO and eastern Australian climate have been investigated from a
      mechanistic approach. <citation>b3_c2_r30+1</citation> showed that ENSO and IPO both affect
      the location of the South Pacific Convergence Zone (SPCZ) providing a mechanistic
      justification for the role of La Nina and IPO negative periods in enhancing flood risk in
      eastern Australia.</para>

    <para>Whilst the work to date has primarily focused on eastern Australia, a substantial step
      change in climate also occurred in Western Australia around the mid-1970’s, in line with the
      IPO and PDO indices <citation>b3_c2_r33</citation>, however the role of ENSO is less clear and
      is likely to be additionally complicated by the role of the Indian Ocean.</para>

    <para>The finding that flood risk in parts of Australia is modulated by low frequency climate
      variability is recent. Practitioners are reminded that this is an area of active research and
      therefore should keep abreast of future developments.</para>

    <figure xml:id="b3_ch2_f_6x7dy">
      <title>Annual Average Interdecadal Pacific Oscillation Time Series</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3007.png"/>
        </imageobject>
      </mediaobject>
    </figure>

    <figure xml:id="b3_ch2_f_fy36g">
      <title>NSW Regional Flood Index Frequency Curves for Positive and Negative Interdecadal
        Pacific Oscillation epochs <citation>b3_c2_r41</citation></title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3008.png"/>
        </imageobject>
      </mediaobject>
    </figure>
  </section>

  <section xml:id="b3_ch2_s_9gkdb">
    <title>Regional Flood Information</title>

    <para>Whereas the primary focus of this chapter is Flood Frequency
    Analysis using at-site information, the accuracy of the frequency analysis
    can be improved, substantially in some cases, by augmenting at-site
    information with regional information. Subsequent chapters in this Book
    describe methods for estimating flood frequency at ungauged sites.
    Provided such methods also provide estimates of uncertainty, the regional
    information can be pooled with the at-site information to yield more
    accurate results. <xref linkend="b3_ch2_s_xjch2"/> shows how regional
    information on flood probability model parameters can pooled with at-site
    information. When pooling at-site and regional information it is important
    to establish that both sources of information are consistent – that is,
    they yield statistically consistent results.</para>
  </section>

  <section xml:id="b3_ch2_s_fvb1b">
    <title>Missing Records</title>

    <para>Streamflow data frequently contain gaps for a variety of reasons
    including the malfunction of recording equipment. Rainfall records on the
    catchment and streamflow data from nearby catchments may indicate the
    likelihood of a large flood having occurred during the gap. A regression
    may be able to be derived to enable a missing flood to be estimated, but
    as discussed in <xref linkend="b3_ch2_s_dikhk"/>, the degree of
    correlation is often insufficient for a quantitative estimate.</para>

    <para>For AM series the missing record period is of no consequence and can
    be included in the period of record, if it can be determined that the
    largest discharge for the year occurred outside the gap, or that no large
    rainfall occurred during the gap. However the rainfall records and
    streamflow on nearby catchments might indicate that a large flood could
    have occurred during the period of missing record. If a regression with
    good correlation can be derived from concurrent records, the missing flood
    can be estimated and used as the annual flood for the year. If the flood
    cannot be estimated with reasonable certainty, the whole year should be
    excluded from the analysis.</para>

    <para>For POT series data, treatment of missing records is less clear.
        <citation>b3_c2_r51+1</citation> tested seven methods, leading to the following
      recommendations based on the assumption that the periods of missing data are random
      occurrences and are independent of the occurrence of flood peaks.</para>

    <orderedlist>
      <listitem>
        <para>Where a nearby station record exists covering the missing record
        period, and a good relation between the flood peaks on the two
        catchments can be obtained, then use this relation and the nearby
        station record to fill in the missing events of interest.</para>
      </listitem>

      <listitem>
        <para>Where a nearby station record exists covering the missing record
        period, and the relation between the flood peaks on the two catchments
        is such that only the occurrence of an event can be predicted but not
        its magnitude, then:</para>

        <itemizedlist>
          <listitem>
            <para>For record lengths less than 20 years, ignore the missing
            data and include the missing period in the overall period of
            record;</para>
          </listitem>

          <listitem>
            <para>For record lengths greater than 20 years, subtract an amount
            from each year with missing data proportional to the ratio of the
            number of peaks missed to the total number of ranked peaks in the
            year.</para>
          </listitem>
        </itemizedlist>
      </listitem>

      <listitem>
        <para>Where no nearby station record exists covering the missing
        record period, or where no relation between flood peaks on the
        catchment exists, then ignore the missing data and include the missing
        record period in the overall period of record.</para>
      </listitem>
    </orderedlist>
  </section>
</section>
