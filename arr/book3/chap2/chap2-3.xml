<?xml version="1.0" encoding="UTF-8"?>
<section version="5.0" xml:id="b3_ch2-3" xmlns="http://docbook.org/ns/docbook"
    xmlns:xlink="http://www.w3.org/1999/xlink"
    xmlns:xi="http://www.w3.org/2001/XInclude"
    xmlns:svg="http://www.w3.org/2000/svg"
    xmlns:m="http://www.w3.org/1998/Math/MathML"
    xmlns:html="http://www.w3.org/1999/xhtml"
    xmlns:db="http://docbook.org/ns/docbook">
    
    <title>Selection and Preparation of Data</title>
    
    <section>
        <title>Requirements of Data for Valid Analysis</title>
        
        <para>For valid frequency analysis, the data used should constitute a
            random sample of independent values, ideally from a homogeneous
            population. Streamflow data are collected as a continuous record, and
            discrete values must be extracted from this record as the events to be
            analysed. The problem of assessing independence of events, and of
            selecting all independent events, is illustrated by the streamflow
            record for a 1000 km<superscript>2</superscript> catchment shown in
            Figure 1.1.<emphasis role="bold"> "WPGeneratedID_TOC_1_11">3</emphasis>. There is
            little doubt that peaks A and B are not independent or that they are
            serially correlated, while peak D is independent of A and B. However,
            the independence of peak C from A and B is open to question, and there
            is doubt as to whether the independent peaks in the record are B and D,
            or B, C and D. Methods for selecting peak flows to be included in the
            analysis are described in the following subsections.</para>
        
        <figure>
            <title>Hydrograph for to 1000 km2 catchment illustrating difficulty of
                assessing independence of floods</title>
            
            <mediaobject>
                <imageobject>
                    <imagedata contentwidth="443" fileref="figures/figure1_1_3.jpg"/>
                </imageobject>
            </mediaobject>
        </figure>
        
        <para>Lack of homogeneity of the population of floods is also a
            practical problem, particularly as the data sample from the past is used
            to derive flood estimates applicable to the design life of the structure
            or works in the future. Examples of changes in the collection of the
            data or in the nature of the catchment that lead to lack of homogeneity
            are:</para>
        
        <orderedlist>
            <listitem>
                <para>undetected change in station rating curve;</para>
            </listitem>
            
            <listitem>
                <para>change of gauging station site;</para>
            </listitem>
            
            <listitem>
                <para>construction of large storages, levees and channel
                    improvements; and</para>
            </listitem>
            
            <listitem>
                <para>changes in land use such as clearing, growth in the number of
                    farm dams on the catchment, different farming practices, soil
                    conservation works, reafforestation, and urbanization.</para>
            </listitem>
        </orderedlist>
        
        <para>The record should be carefully examined for these and other causes
            of lack of homogeneity. In some cases recorded values can be adjusted by
            means such as routing pre-dam floods through the storage to adjust them
            to equivalent present values, correcting rating errors where this is
            possible, or making some adjustment for urbanization. Such decisions
            must be made largely by judgment. As with all methods of flood
            estimation, it is important that likely conditions during the design
            life be considered rather than those existing at the time of design.
            Some arbitrary adjustment of derived values for likely changes in the
            catchment may be possible, but the recorded data must generally be
            accepted for analysis and design. Fortunately, the available evidence
            indicates that unless changes to the catchment involve large proportions
            of the total area or large changes in the storage on the catchment, the
            effects on flood magnitudes are likely to be modest. Also, the effects
            are likely to be larger for small floods than for the large
            floods.</para>
    </section>
    
    <section>
        <title>Types of Flood Data</title>
        
        <para>It is convenient to classify the flood peak data used in a flood
            frequency analysis as either being gauged or censored.</para>
        
        <section>
            <title>Gauged Data</title>
            
            <para>Gauged data consist of a time series of flood discharge
                estimates. Such estimates are based on observed peak (or
                instantaneous) stages (or water levels). A rating curve is used to
                transform stage observations to discharge estimates. When
                extrapolated, the rating curve can introduce large systematic error
                into discharge estimates.</para>
            
            <para>It is important to check how the peak discharges were obtained
                from the gauged record. Peak discharges may be derived from daily
                readings, possibly with some intermediate readings during some floods
                for part of the record, and continuous readings from the remainder of
                the record. If the daily reading is deemed an unreliable estimate of
                the peak discharge during that day, the reading need not be discarded
                but treated as an imprecise measurement. Micevski <emphasis
                    role="italic">et al</emphasis>. (2005) present a likelihood-based
                method for dealing with such cases. The consequences of ignoring the
                error associated with daily readings is considered also.</para>
        </section>
        
        <section>
            <title>Censored Data</title>
            
            <para>Censored data refer to peak flows which are treated as being
                above or below a known threshold. They can be expressed as a time
                series of indicator values defined as</para>
            
            <para/>
            
            <equation>
                <title/>
                
                <m:math display="block">
                    <m:msub>
                        <m:mi>I</m:mi>
                        
                        <m:mi>t</m:mi>
                    </m:msub>
                    
                    <m:mo>(q) =</m:mo>
                    
                    <m:mrow>
                        <m:mo>{</m:mo>
                        
                        <m:mtable>
                            <m:mtr>
                                <m:mtd>
                                    <m:mrow>
                                        <m:msup>
                                            <m:mi>1 if the t</m:mi>
                                            
                                            <m:mi>th</m:mi>
                                        </m:msup>
                                        
                                        <m:mo>flood peak &gt; threshold discharge q</m:mo>
                                    </m:mrow>
                                </m:mtd>
                            </m:mtr>
                            
                            <m:mtr>
                                <m:mtd>
                                    <m:mrow>
                                        <m:msup>
                                            <m:mi>-1 if the t</m:mi>
                                            
                                            <m:mi>th</m:mi>
                                        </m:msup>
                                        
                                        <m:mo>flood peak â‰¤</m:mo>
                                        
                                        <m:mi>threshold discharge q</m:mi>
                                    </m:mrow>
                                </m:mtd>
                            </m:mtr>
                        </m:mtable>
                    </m:mrow>
                </m:math>
            </equation>
            
            <equation>
                <m:math display="block">
                    <m:mrow>
                        <m:msub>
                            <m:mi/>
                        </m:msub>
                    </m:mrow>
                </m:math>
            </equation>
            
            <para>Censored data can arise in a number of ways. For example, prior
                to gauging, water level records may have been kept only for large
                floods above some perception threshold. Therefore, all we may know is
                that there were n<subscript>a</subscript> flood peaks above the
                threshold and n<subscript>b</subscript> peaks below the
                threshold.</para>
            
            <para>Sometimes, we may deliberately exclude zero or small gauged
                floods below some threshold because the overall fit is unduly
                influenced by small floods. In such cases, even though the gauged
                flows are available, they are treated as censored data.</para>
        </section>
    </section>
    
    <section>
        <title>Annual Flood Gauged Series</title>
        
        <para>This is the most common method of selecting the flood peaks to be
            analysed. The series comprises the highest instantaneous rate of
            discharge in each year of record. The year may be a calendar year or a
            water year, the latter usually commencing at the end of the period of
            lowest average flow during the year. Where flows are highly seasonal,
            especially with a wet summer, use of the water year is preferable. The
            highest flow in each year is selected whether it is a major flood or
            not, and all other floods are neglected, even though some will be much
            larger than the maximum discharges selected from some other years. For N
            years of data, the annual flood series will consist of N values.</para>
        
        <para>The annual flood series has at least two advantages:</para>
        
        <orderedlist>
            <listitem>
                <para>As the individual annual maximum flows are likely to be
                    separated by considerable intervals of time, it is probable that the
                    values will be independent. Checking of dates of the annual maxima
                    to ensure that they are likely to be independent is a simple
                    procedure that should always be carried out. If the highest annual
                    value occurred at the start of a year and was judged to be strongly
                    related to the annual maximum at the end of the previous year, the
                    lower of these two values should be discarded, and the second
                    highest flow in that year substituted; and</para>
            </listitem>
            
            <listitem>
                <para>The series is easily and unambiguously extracted. Most data
                    collection agencies (see Book I, Chapter 2 for a list of major data
                    collection agencies) have annual maxima on computer file and/or hard
                    copy.</para>
            </listitem>
        </orderedlist>
    </section>
    
    <section>
        <title>Peak-Over-Threshold Gauged Series</title>
        
        <para>A POT flood series consists of all floods with peak discharges
            above a selected base value, regardless of the number of such floods
            occurring each year. The POT series may also be termed the partial
            duration series or basic stage series. The number of floods (K)
            generally will be different to the number of years of record (N), and
            will depend on the selected threshold discharge. The American Society of
            Civil Engineers (1949) recommended that the base discharge should be
            selected so that K is greater than N, but that there should not be more
            than 3 or 4 floods above the threshold in any one year. These two
            requirements can be incompatible. The US Geological Survey (Dalrymple,
            1960) recommended that K should equal 3N. If a probability distribution
            is to be fitted to the POT series the desirable threshold discharge and
            average number of floods per year selected depend on the type of
            distribution. These distributions are discussed further in Section <emphasis role="bold"> "WPGeneratedID_Xref_ChoiceofDistSection_1" </emphasis> of this Chapter in
            Australian Rainfall and Runoff. For the compound model using a Poisson
            distribution of occurrences and an exponential distribution of
            magnitudes, Tavares and da Silva (1983) and Jayasuriya and Mein (1985)
            found that K should equal 2N or greater, and the UK Flood Studies Report
            (Natural Environment Research Council, 1975) recommended that K should
            equal 3N to 5N. For fitting the log Pearson III distribution, the values
            of the moments depend on the number of floods selected and the base
            discharge. McDermott and Pilgrim (1982) and Jayasuriya and Mein (1985)
            found that best results were obtained in this case when K equalled N.
            Martins and Stedinger (2001) found that the precision of flood quantiles
            derived from a GEV-Poisson POT model is fairly insensitive for K â‰¥
            N.</para>
        
        <para>An important advantage of the POT series is that when the selected
            base value is sufficiently high, small events that are not really floods
            are excluded. With the annual series, non-floods in dry years may have
            an undue influence on shape of the distribution. This is particularly
            important for Australia, where both the range of flows and the
            non-occurrence of floods are greater than in many other countries such
            as the United States and the United Kingdom (Grayson <emphasis
                role="italic">et al</emphasis>., 1996). For this reason it would also be
            expected that the desirable ratio of K to N would be lower in Australia
            than in these countries.</para>
        
        <para>A criterion for independence of successive peaks must also be
            applied in selecting events. As discussed by Laurenson (1987),
            statistical independence requires physical independence of the causative
            factors of the flood, mainly rainfall and antecedent wetness. This type
            of independence is desirable if the POT series is used to estimate the
            distribution of annual floods. On the other hand, selection of POT
            series floods for design flood studies should consider the consequences
            of the flood peaks in assessing independence of events where damages or
            financial penalties are the most important design variables. Factors to
            be considered might include duration of inundation, and time required to
            repair flood damage. In both cases, the size or response time of the
            catchment will have some effect.</para>
        
        <para>The decision regarding a criterion for independence therefore
            requires subjective judgment by the designer or analyst in each case.
            There is often some conflict in that some flood effects are short-lived,
            perhaps only as long as inundation, while others such as the destruction
            of an annual crop may last as long as a year. It is thus not possible to
            recommend a simple and clear-cut criterion for independence. The
            circumstances and objectives of each study, and the characteristics of
            the catchment and flood data, should be considered in each case before a
            criterion is adopted. It is inevitable that the adopted criterion will
            be arbitrary to some extent.</para>
        
        <para>While no specific criterion can be recommended, it may be helpful
            to consider some criteria that have been used in past studies:</para>
        
        <itemizedlist>
            <listitem>
                <para>Bulletin 17B of the Interagency Advisory Committee on Water
                    Data (1982) states that no general criterion can be recommended and
                    the decision should be based on the intended use in each case, as
                    discussed above. However in Appendix 14 of that document, a study by
                    Beard (1974) is summarised where the criterion used is that
                    independent flood peaks should be separated by five days plus the
                    natural logarithm of the square miles of drainage area, with the
                    additional requirement that intermediate flows must drop to below
                    75% of the lower of the two separate flood peaks. This may be
                    suitable only for catchments larger than 1000
                    km<superscript>2</superscript>. Jayasuriya and Mein (1985) used this
                    criterion in their study.</para>
            </listitem>
        </itemizedlist>
        
        <itemizedlist>
            <listitem>
                <para>The UK Flood Studies Report (Natural Environment Research
                    Council, 1975) used a criterion that flood peaks should be separated
                    by three times the time to peak and that the flow should decrease
                    between peaks to two thirds of the first peak.</para>
            </listitem>
        </itemizedlist>
        
        <itemizedlist>
            <listitem>
                <para>M<superscript>c</superscript>Illwraith (1953), in developing
                    design rainfall data for flood estimation, used the following
                    criteria based on the rainfall causing the floods:</para>
            </listitem>
        </itemizedlist>
        
        <itemizedlist>
            <listitem>
                <itemizedlist>
                    <listitem>
                        <para>for rainfalls of short duration up to two hours, only the
                            one highest flood within a period of 24 hours; and</para>
                    </listitem>
                    
                    <listitem>
                        <para>for longer rains, a period of 24 hours in which no more
                            than 5 mm of rain could occur between rain causing separate
                            flood events.</para>
                    </listitem>
                </itemizedlist>
            </listitem>
            
            <listitem>
                <para>In a study of small catchments, Potter and Pilgrim (1971) used
                    a criterion of three calendar days between separate flood events but
                    lesser events could occur in the intervening period. This was the
                    most satisfactory of five criteria tested on data from seven small
                    catchments located throughout eastern New South Wales. It also gave
                    the closest approximation to the above criteria used by McIllwraith
                    (1953).</para>
            </listitem>
        </itemizedlist>
        
        <itemizedlist>
            <listitem>
                <para>Pilgrim and McDermott (1982) and McDermott and Pilgrim (1983)
                    adopted monthly maximum peak flows to give an effective criterion of
                    independence in developing a design procedure for small to medium
                    sized catchments. This was based primarily on the assumption that
                    little additional damage would be caused by floods occurring within
                    a month, and thus closer floods would not be independent in terms of
                    their effects. This criterion was also used by Adams and McMahon
                    (1985) and Adams (1987).</para>
            </listitem>
        </itemizedlist>
        
        <para>The criteria cited above represent a wide range, and illustrate
            the difficult and subjective nature of the choice. It is stressed that
            these criteria have been described for illustrative purposes only. In
            each particular application the designer or analyst should choose a
            criterion suitable to the analysis and relevant to all of the
            circumstances and objectives.</para>
    </section>
    
    <section>
        <title>Monthly and Seasonal Gauged Series</title>
        
        <para>In some circumstances, series other than the annual or POT series
            may be used. The monthly and seasonal series are the most useful.</para>
        
        <para>Maximum monthly flows are an approximation to the POT series in
            most parts of Australia, as the probability of two large independent
            floods occurring in the same month is low. Tropical northern Australia,
            the west coast Tasmania and the south west of Western Australia may be
            exceptions. While the monthly series is easier to compile than a POT
            series (most gauging authorities have monthly maximum flows on file)
            consideration needs to be given to significance of multiple floods in a
            month causing adverse events. It should be noted that not every monthly
            maximum flood will be selected, but only those large enough to exceed a
            selected base discharge, as is the case for the POT series. Care is
            required to check any floods selected in successive months for
            independence. Where the dates are close, the lower value should be
            discarded. The second highest flood in that month could then be checked
            from the records, but this would generally not be worthwhile. An example
            of use of the monthly series is described by Pilgrim and McDermott
            (1982).</para>
        
        <para>Seasonal flood frequencies are sometimes required. For these
            cases, the data are selected for the particular month or season as for
            the annual series, and the flood frequency analysis is carried out in a
            similar fashion to that for the annual series.</para>
    </section>
    
    <section>
        <title>Extension of Gauged Records</title>
        
        <section>
            <title>General</title>
            
            <para>It may sometimes be possible to extend the recorded data by
                values estimated from longer records on adjacent catchments, by use of
                a catchment rainfall-runoff model, or by historical data from before
                the commencement of records. If this can be done validly, the
                effective sample size of the data will be increased and the
                reliability of the analysis will be greater. However, care is
                necessary to ensure that the extended data are valid, and that real
                information has been added. Several procedures can be used. Some of
                these procedures are described in the following sections.</para>
        </section>
        
        <section>
            <title>Extension Using Data From An Adjacent Catchment</title>
            
            <para>Suppose there are n<subscript>1</subscript> years of record at
                site 1, the study catchment, and a longer record of length
                n<subscript>2</subscript> years at site 2, an adjacent catchment.
                Using the overlapping record a relationship can be developed between
                q<subscript>1</subscript> and q<subscript>2</subscript>, the peak
                flows at sites 1 and 2, and then used to extend the shorter record at
                site 1</para>
            
            <para>The most intuitive way to extend the site 1 record is to use the
                best fit relationship between q<subscript>1</subscript> and
                q<subscript>2</subscript> to obtain a smoothed estimate of
                q<subscript>1</subscript> given the observed
                q<subscript>2</subscript>. The best fit usually would be determined
                using regression methods. However, this approach is not recommended as
                it biases downward the variance of the extended record because the
                scatter about the regression line is ignored.</para>
            
            <para>This bias can be overcome by one of two methods:</para>
            
            <orderedlist>
                <listitem>
                    <para>A random error sampled from the regression error
                        distribution can be added to the smoothed estimate for
                        q<subscript>1</subscript> (Matalas and Jacobs, 1964). While this
                        will preserve the expected variance of the extended record it
                        produces an arbitrary extended record.</para>
                </listitem>
                
                <listitem>
                    <para>A maintenance of variance extension (MOVE) method can be
                        used to derive a relationship between q<subscript>1</subscript>
                        and q<subscript>2</subscript> which preserves the expected value
                        of selected statistics for q<subscript>1</subscript> such as the
                        variance. For example, the simplest MOVE method preserves the mean
                        and variance of q<subscript>1</subscript> using the following
                        relationship</para>
                </listitem>
            </orderedlist>
            
            <equation>
                <title/>
                
                <m:math display="block">
                    <m:mi/>
                    
                    <m:msub>
                        <m:mi>q</m:mi>
                        
                        <m:mi>1</m:mi>
                    </m:msub>
                    
                    <m:mrow>
                        <m:mrow>
                            <m:mo>=</m:mo>
                            
                            <m:mi>E</m:mi>
                        </m:mrow>
                        
                        <m:mrow>
                            <m:mrow>
                                <m:mo>(</m:mo>
                                
                                <m:msub>
                                    <m:mi>q</m:mi>
                                    
                                    <m:mi>1</m:mi>
                                </m:msub>
                                
                                <m:mo>)</m:mo>
                            </m:mrow>
                            
                            <m:mrow>
                                <m:mi>+ sign (r)</m:mi>
                                
                                <m:msqrt>
                                    <m:mfrac>
                                        <m:mrow>
                                            <m:mi>Var</m:mi>
                                            
                                            <m:mo>=</m:mo>
                                            
                                            <m:mrow>
                                                <m:mo>(</m:mo>
                                                
                                                <m:msub>
                                                    <m:mi>q</m:mi>
                                                    
                                                    <m:mi>1</m:mi>
                                                </m:msub>
                                                
                                                <m:mo>)</m:mo>
                                            </m:mrow>
                                        </m:mrow>
                                        
                                        <m:mrow>
                                            <m:mi>Var</m:mi>
                                            
                                            <m:mo>=</m:mo>
                                            
                                            <m:mrow>
                                                <m:mo>(</m:mo>
                                                
                                                <m:msub>
                                                    <m:mi>q</m:mi>
                                                    
                                                    <m:mi>2</m:mi>
                                                </m:msub>
                                                
                                                <m:mo>)</m:mo>
                                            </m:mrow>
                                        </m:mrow>
                                    </m:mfrac>
                                </m:msqrt>
                                
                                <m:mrow>
                                    <m:mrow>
                                        <m:mrow>
                                            <m:mo>[</m:mo>
                                            
                                            <m:mrow>
                                                <m:msub>
                                                    <m:mi>q</m:mi>
                                                    
                                                    <m:mi>2</m:mi>
                                                </m:msub>
                                                
                                                <m:mrow>
                                                    <m:mi>-</m:mi>
                                                    
                                                    <m:mrow>
                                                        <m:mi>E</m:mi>
                                                        
                                                        <m:mrow>
                                                            <m:mo>(</m:mo>
                                                            
                                                            <m:msub>
                                                                <m:mi>q</m:mi>
                                                                
                                                                <m:mi>2</m:mi>
                                                            </m:msub>
                                                            
                                                            <m:mo>)</m:mo>
                                                        </m:mrow>
                                                    </m:mrow>
                                                </m:mrow>
                                            </m:mrow>
                                            
                                            <m:mo>]</m:mo>
                                        </m:mrow>
                                    </m:mrow>
                                </m:mrow>
                            </m:mrow>
                        </m:mrow>
                    </m:mrow>
                </m:math>
            </equation>
            
            <para>where signÂ® is the correlation between q<subscript>1</subscript>
                and q<subscript>2</subscript> and E() and Var() are the mean and
                variance. More details are provided in Hirsch (1982) and Grygier
                <emphasis role="italic">et al</emphasis>. (1989).</para>
            
            <para>When annual floods are used, the dates of the corresponding
                annual floods may be different resulting in a lack of physical basis
                for the relation. It is a moot point whether this constitutes grounds
                for not using such data as the purpose of record extension is to
                exploit the association between the annual peaks at the two sites. The
                existence of a causal linkage is an extremely desirable prerequisite
                for use of an association between the peak flows at the two sites but
                is not an absolute prerequisite.</para>
            
            <para>Wang (2001) presents a Bayesian approach that exploits the
                useful information arising from the association of peak flows between
                sites 1 and 2. Though not a record extension method, it does augment
                the information beyond that in the site 1 record.</para>
        </section>
        
        <section>
            <title>Use of a Catchment Modelling System</title>
            
            <para>Suppose a rainfall record longer than the flow record is
                available at the study catchment. A model of the upstream catchment
                can be calibrated and used to extend the flow record; the model may
                range from a simple rainfall-runoff regression to the continuous flow
                prediction of the catchment response to rainfall using a system of
                relevant process models. As discussed in the previous section such an
                approach is likely to produce smoothed flow estimates which bias
                downwards the variability of the flow record. The use of smoothed
                estimates, therefore, is notÅ¸ recommended. If a catchment modelling
                approach is to be used the variability needs to be preserved, for
                example, by sampling from the error distribution describing the
                discrepancy between observed and predicted, or simulated, flows. This
                error distribution can be complex with the magnitude of errors growing
                with the magnitude of the flow. Care needs to be exercised to ensure
                that such error characteristics are replicated in the sampling
                scheme.</para>
        </section>
        
        <section>
            <title>Station-year Method</title>
            
            <para>This is included only to warn against its shortcomings. In this
                procedure, records from several adjacent catchments are joined
                "end-to-end" to give a single record equal in length to the sum of the
                lengths of the constituent records. As discussed by Clarke-Hafstad
                (1942) for rainfall data, spatial correlation between the records of
                the adjacent stations invalidates the procedure.</para>
        </section>
    </section>
    
    <section>
        <title>Rating Error in Gauged Flows</title>
        
        <para>Though it is widely accepted that discharge estimates for large
            floods can be in considerable error, there is limited published
            information on these errors and how they can be allowed for in a flood
            frequency analysis. Rating error can arise from a number of mechanisms
            including:</para>
        
        <itemizedlist>
            <listitem>
                <para>For large floods the rating curve typically is extrapolated or
                    fitted to indirect discharge estimates. This can introduce a
                    systematic but unknown bias.</para>
            </listitem>
        </itemizedlist>
        
        <itemizedlist>
            <listitem>
                <para>If the gauging station is located at a site with an unstable
                    cross section the rating curve may shift causing a systematic but
                    unknown bias.</para>
            </listitem>
        </itemizedlist>
        
        <para>The conceptual model of rating error presented in this section is
            based on Kuczera (1999) and is considered to be rudimentary and subject
            to refinement. It is assumed the cross section is stable with the
            primary source of rating error arising from extension of the rating
            curve to large floods. Measurement errors which may be systematic or
            random are not considered.</para>
        
        <para>Potter and Walker (1981, 1985) observe that flood discharge is
            inferred from a rating curve which is subject to discontinuous
            measurement error. Consider Figure 1.1.<emphasis role="bold"> "WPGeneratedID_TOC_1_13">4</emphasis> which depicts a rating curve
            with two regions having different error characteristics. The
            interpolation zone consists of that part of the rating curve well
            defined by discharge-stage measurements; typically the error coefficient
            of variation (CV) would be practically negligible, say 5%. In the
            extension zone the rating curve is extended by methods such as
            slope-conveyance, log-log extrapolation or fitting to indirect discharge
            estimates. Typically such extensions are smooth and, therefore, can
            induce systematic under- or over-estimation of the true discharge over a
            range of stage. In Figure 1.1.<emphasis role="bold"> "WPGeneratedID_TOC_1_13">4</emphasis>, the illustrated extension
            systematically underestimates the true discharge.</para>
        
        <para>The extension zone can be considerable. Hatfield and Muir (1984)
            report that the highest gauged flow at over 50% of NSW stations was less
            than 20% of the estimated highest recorded flow. The extension error CV
            is not well known but Potter and Walker (1981, 1985) suggest it may be
            as high as 30%. Brown (1983) concluded that the accuracy of high floods
            at most stations is probably not much better than 25% and in many cases
            much worse.</para>
        
        <figure>
            <title>Rating Curve Extension Error</title>
            
            <mediaobject>
                <imageobject>
                    <imagedata contentwidth="499" fileref="figures/figure1_1_4.jpg"/>
                </imageobject>
            </mediaobject>
        </figure>
        
        <para>Though Figure 1.1.<emphasis role="bold"> "WPGeneratedID_TOC_1_13">4</emphasis>
            represents an idealization of actual rating curve extension two points
            of practical significance are noted:</para>
        
        <orderedlist>
            <listitem>
                <para>The error is systematic in the sense that the extended rating
                    is likely to diverge from the true rating as the discharge
                    increases. The error, therefore, is likely to be highly correlated.
                    In the idealization of Figure 1.1.<emphasis role="bold"> "WPGeneratedID_TOC_1_13">4</emphasis> it is perfectly
                    correlated; this correlation, however, is a result of the
                    simplification adopted; and</para>
            </listitem>
            
            <listitem>
                <para>The interpolation zone anchors the error in the extension
                    zone. Therefore, the error in the extension zone depends on the
                    distance from the anchor point and not from the origin. This error
                    is termed incremental because it originates from the anchor point
                    rather than the origin of the rating curve.</para>
            </listitem>
        </orderedlist>
        
        <para>This conceptual rating curve error model is incorporated into the
            Bayesian fitting procedure described in Section <emphasis role="bold"> "WPGeneratedID_Xref_BayesianCalSect_1"</emphasis> of this Chapter in Book
            ? of Australian Rainfall and Runoff.</para>
    </section>
    
    <section>
        <title>Historical and Paleo Flood Information</title>
        
        <para>A flood may have occurred before, during or after the period of
            gauged record, and is known to be the largest flood, or flood of other
            known rank, over a period longer than that of the gauged record. Such
            floods can provide valuable information, and should be included in the
            analysis if possible.</para>
        
        <para>Care is needed in assessing historical floods. Only stages usually
            are available, and these may be determined by</para>
        
        <itemizedlist>
            <listitem>
                <para>Flood marks recorded on buildings or structures; care needs to
                    be taken, however, to ensure that buildings and structures have not
                    been moved in the intervening period;</para>
            </listitem>
        </itemizedlist>
        
        <itemizedlist>
            <listitem>
                <para>Old newspaper reports and photographs; and</para>
            </listitem>
        </itemizedlist>
        
        <itemizedlist>
            <listitem>
                <para>Verbal evidence. While verbal evidence often is untrustworthy,
                    it still warrants checking to assess its reliability</para>
            </listitem>
        </itemizedlist>
        
        <para>A further problem is that the channel morphology, and hence the
            stage-discharge relation of the stream, may be different to that
            applicable to the period of gauged record.</para>
        
        <para>It is desirable to carry out frequency analyses both by including
            and excluding the historical data. The analysis including the historical
            data should be used unless in the comparison of the two analyses, the
            magnitudes of the observed peaks, uncertainty regarding the accuracy of
            the historical peaks, or other factors, suggest that the historical
            peaks are not indicative of the extended period or are not accurate. All
            decisions made should be thoroughly documented.</para>
        
        <para>Paleofloods are major floods that have occurred outside the
            historical record, but which are evidenced by geological,
            geomorphological or botanical information. Techniques of paleohydrology
            have been described by Costa (1978, 1983, 1986), Kochel <emphasis
                role="italic">et al</emphasis>. (1982) and O'Connell <emphasis
                    role="italic">et al</emphasis>. (2002) with a succinct summary given by
            Stedinger and Cohn (1986). Although high accuracy is not possible with
            these estimates, they may only be marginally less accurate than other
            estimates requiring extrapolation of rating curves, and they have the
            potential for greatly extending the data base and providing valuable
            information on the right hand tail of the underlying flood probability
            distribution. Hosking and Wallis (1986) and Jin and Stedinger (1989)
            consider procedures for assessing the value of paleoflood estimates in
            flood frequency analysis. Only a little work on this topic has been
            carried out in Australia, but its potential has been indicated by its
            use to identify the five largest floods in the last 700 years in the
            Finke River Gorge in central Australia (Baker <emphasis role="italic">et
                al</emphasis>., 1983; Baker, 1984), and for more frequent floods, by
            identification of the six largest floods that occurred since a major
            flood in 1897 on the Katherine River in the Northern Territory (Baker,
            1984). The use of paleoflood data should be considered where this is
            possible in view of the potential benefits, and further development of
            the technique would be desirable. The two major problems in its use are
            that there are not many sites where it can be employed, and climate
            changes may have affected the homogeneity of long-term flood
            data.</para>
    </section>
    
    <section>
        <title>Data Characterizing Climate Long-Term Persistence</title>
        
        <para>There is growing evidence that flood peaks are not identically
            distributed from year to year in some parts of Australia and that flood
            risk is dependent on long-term climate variability. Much of this
            evidence arises from the idea of alternating flood and drought dominated
            regimes that exist on decadal and longer time-scales which was first
            proposed by Warner and Erskine (1988). The climate-dependence of flood
            risk is an important consideration when assessing flood risk.</para>
        
        <para>Most flood frequency applications will require assessment of the
            long-term flood risk; that is, the flood risk that is independent of a
            particular current climate state. If a flood record was sufficiently
            long to sample all climate states affecting flood risk, a traditional
            analysis assuming homogeneity would yield the long-term flood risk.
            Unfortunately many flood records are relatively short and may be
            dominated by one climate state. Blind use of such data can result in
            substantial bias in long-term flood risk estimates. For this reason it
            may be necessary to obtain climate data which characterizes long-term
            persistence in climate and to investigate the homogeneity of the flood
            distribution.</para>
        
        <para>A number of known climate phenomena impact on Australia climate
            variability. Most well known is the inter-annual El Nino/Southern
            Oscillation (ENSO). The cold ENSO phase, La Nina, results in a marked
            increase in flood risk across Eastern Australia, whereas El Nino years
            typically are periods without the occurrence of major floods
            (Kiem</para>
        
        <para>There is also mounting evidence that longer-term climate processes
            also have a major impact on flood risk. The Interdecadal Pacific
            Oscillation (IPO) is a low frequency climate process related to the
            variable epochs of warming and cooling in the Pacific Ocean and is
            described by an index derived from low pass filtering of sea surface
            temperature (SST) anomalies in the Pacific Ocean (Power <emphasis
                role="italic">et al</emphasis>., 1998, 1999; Allan, 2000). The IPO is
            similar to the Pacific Decadal Oscillation (PDO) of Mantua <emphasis
                role="italic">et al</emphasis>. (1997), which is defined as the leading
            principal component of North Pacific monthly sea surface temperature
            variability.</para>
        
        <para>The IPO time series from 1880 is displayed in Figure 1.1.<emphasis role="bold"> "WPGeneratedID_TOC_1_15">5</emphasis>. It reveals extended periods
            where the index either lies below or above zero. Power <emphasis
                role="italic">et al</emphasis>. (1999) have shown that the association
            between ENSO and Australian climate is modulated by the IPO. A strong
            association was found between the magnitude of ENSO impacts during
            negative IPO phases, whilst during positive IPO phases a weaker, less
            predictable relationship was observed. Additionally, Kiem <emphasis
                role="italic">et al</emphasis>. (2003) and Kiem and Franks (2004)
            analysed NSW flood and drought data and demonstrated that the IPO
            negative state magnified the impact of La Nina events. Moreover, they
            demonstrated that the IPO negative phase, related to midlatitude Pacific
            Ocean cooling, appears to result in an increased frequency of cold La
            Nina events. The net effect of the dual modulation of ENSO by IPO is the
            occurrence of multi-decadal periods of elevated and reduced flood
            risk.</para>
        
        <para>To place this in context, shown in Figure 1.1.<emphasis role="bold"> "WPGeneratedID_TOC_1_16">6</emphasis> are regional flood index
            curves based on about 40 NSW sites for the different IPO states (Kiem
            <emphasis role="italic">et al</emphasis>., 2003). As shown in that
            figure, the 1 in 100 AEP flood during years with a positive IPO index
            corresponds to the 1 in 6 AEP flood during years with a negative IPO
            index. Note that the dashed lines in this figure represent the
            confidence limits of the flood frequency curves. Micevski <emphasis
                role="italic">et al</emphasis>. (2003) investigating a range of sites in
            NSW found that floods occurring during IPO "negative" periods were, on
            average, about 1.8 times larger than floods with the same frequency
            during IPO "positive" periods.</para>
        
        <figure>
            <title>Annual Average IPO Time Series</title>
            
            <mediaobject>
                <imageobject>
                    <imagedata contentwidth="616" fileref="figures/figure1_1_5.jpg"/>
                </imageobject>
            </mediaobject>
        </figure>
        
        <figure>
            <title>NSW Regional Flood Index Frequency Curves for Positive and
                Negative IPO Epochs (after Kiem et al., 2003)</title>
            
            <mediaobject>
                <imageobject>
                    <imagedata contentwidth="544" fileref="figures/figure1_1_6.jpg"/>
                </imageobject>
            </mediaobject>
        </figure>
        
        <para>The finding that flood risk in parts of Australia is modulated by
            low frequency climate variability is recent. Users are reminded this is
            an area of active research and to keep abreast of future developments.
            Nonetheless, the practical implication of these findings is
            considerable. A standard flood frequency analysis can produce
            significantly biased estimates of flood risk if this phenomenon is
            ignored. Guidance on how to conduct a flood frequency analysis in such
            circumstances is provided in Section <emphasis role="bold"> "WPGeneratedID_Xref_Non-HomogDataSect._1"</emphasis> of this Book in
            Australian Rainfall and Runoff.</para>
    </section>
    
    <section>
        <title>Regional Flood Information</title>
        
        <para>Whereas the primary focus of this chapter is flood frequency
            analysis using at-site information, the accuracy of the frequency
            analysis can be improved, substantially in some cases, by augmenting
            at-site information with regional information. Subsequent chapters in
            this Book describe methods for estimating flood frequency at ungauged
            sites. Provided such methods also provide estimates of uncertainty, the
            regional information can be pooled with the at-site information to yield
            more accurate results. Section 6.3.5 shows how regional information on
            flood probability model parameters can be pooled with at-site
            information. When pooling at-site and regional information it is
            important to establish that both sources of information are consistent -
            that is, they yield statistically consistent results.</para>
    </section>
    
    <section>
        <title>Missing Records</title>
        
        <para>Streamflow data frequently contain gaps for a variety of reasons
            including the malfunction of recording equipment. Rainfall records on
            the catchment and streamflow data from nearby catchments may indicate
            the likelihood of a large flood having occurred during the gap. A
            regression may be able to be derived to enable a missing flood to be
            estimated, but as discussed in Section of this Chapter in Book of
            Australian Rainfall and Runoff, the degree of correlation is often
            insufficient for a quantitative estimate.</para>
        
        <para>For annual series the missing record period is of no consequence
            and can be included in the period of record, if it can be determined
            that the largest flow for the year occurred outside the gap, or that no
            large rains occurred during the gap. However the rainfall records and
            streamflow on nearby catchments might indicate that a large flood could
            have occurred during the period of missing record. If a regression with
            good correlation can be derived from concurrent records, the missing
            flood can be estimated and used as the annual flood for the year. If the
            flood cannot be estimated with reasonable certainty, the whole year
            should be excluded from the analysis.</para>
        
        <para>For POT series data, treatment of missing records is less clear.
            McDermott and Pilgrim (1982) tested seven methods, leading to the
            following recommendations based on the assumption that the periods of
            missing data are random occurrences and are independent of the
            occurrence of flood peaks.</para>
        
        <orderedlist>
            <listitem>
                <para>Where a nearby station record exists covering the missing
                    record period, and a good relation between the flood peaks on the
                    two catchments can be obtained, then use this relation and the
                    nearby station record to fill in the missing events of
                    interest.</para>
            </listitem>
            
            <listitem>
                <para>Where a nearby station record exists covering the missing
                    record period, and the relation between the flood peaks on the two
                    catchments is such that only the occurrence of an event can be
                    predicted but not its magnitude, then:</para>
                
                <itemizedlist>
                    <listitem>
                        <para>for record lengths less than 20 years, ignore the missing
                            data and include the missing period in the overall period of
                            record;</para>
                    </listitem>
                </itemizedlist>
                
                <itemizedlist>
                    <listitem>
                        <para>for record lengths greater than 20 years, subtract an
                            amount from each year with missing data proportional to the
                            ratio of the number of peaks missed to the total number of
                            ranked peaks in the year.</para>
                    </listitem>
                </itemizedlist>
            </listitem>
            
            <listitem>
                <para>Where no nearby station record exists covering the missing
                    record period, or where no relation between flood peaks on the
                    catchment exists, then ignore the missing data and include the
                    missing record period in the overall period of record.</para>
            </listitem>
        </orderedlist>
    </section>
</section>

