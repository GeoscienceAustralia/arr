<?xml version="1.0" encoding="UTF-8"?>
<section status="In Preparation" version="5.0" xml:id="b3_ch2_s9"
         xmlns="http://docbook.org/ns/docbook"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:svg="http://www.w3.org/2000/svg"
         xmlns:m="http://www.w3.org/1998/Math/MathML"
         xmlns:html="http://www.w3.org/1999/xhtml"
         xmlns:db="http://docbook.org/ns/docbook">
  <title>Supplementary Information</title>

  <section>
    <title>Box 1: Theory of Peak Over Threshold and Annual Maximum
    Series</title>

    <section xml:id="b3_ch2_s_k55h9">
      <title>Annual Exceedance Probability AEP</title>

      <para>The objective is to derive the distribution of the maximum flood peak within a specified
        interval of time. Referring to the continuous streamflow times series <xref
          linkend="b3_ch2_f_e1wwl"/>, let the random variable q be a local peak discharge defined as
        a discharge
        <?oxy_delete author="RadhikaChhotai" timestamp="20151022T173807+1100" content="which"?><?oxy_insert_start author="RadhikaChhotai" timestamp="20151022T173807+1100"?>that<?oxy_insert_end?>
        has lower discharge on either side of the peak. This presents an immediate problem as any
        bump on the hydrograph would produce a local peak. To circumvent this
        problem<?oxy_insert_start author="RadhikaChhotai" timestamp="20151022T173853+1100"?>,<?oxy_insert_end?>
        we focus on peaks greater than some threshold defined as q<subscript>o</subscript>. The
        threshold is selected so that the peaks above the threshold are sufficiently separated in
        time to be statistically independent of each other.</para>

      <figure xml:id="b3_ch2_f_e1wwl">
        <title>Peak Over Threshold series</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="../../figures/3001.jpg"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>It is assumed that all peaks above the threshold
      q<subscript>o</subscript> are sampled from the same distribution denoted
      by the pdf p(q|q&gt;q<subscript>o</subscript>).</para>

      <para>Suppose<?oxy_insert_start author="RadhikaChhotai" timestamp="20151022T173936+1100"?>,<?oxy_insert_end?>
        over a time interval of length t years, there are n peaks over the threshold
          q<subscript>o</subscript>. This defines the POT time series
          {q<subscript>1</subscript>,…,q<subscript>n</subscript>}<?oxy_insert_start author="RadhikaChhotai" timestamp="20151022T174105+1100"?>,<?oxy_insert_end?>
        which consists of n independent realisations sampled from the pdf
          p(q|q&gt;q<subscript>o</subscript>).</para>

      <para>Let w be the maximum value in the POT time series; that is,</para>

      <para>w = max
      {q<subscript>1</subscript>,…,q<subscript>n</subscript>}</para>

      <para>For w to be the maximum value, each peak within the POT series
      must be less than or equal to w. In probability theory this condition is
      expressed by the compound event consisting of the intersection of the
      following n events:</para>

      <equation xml:id="b3_ch2_e_0h1bg">
        <m:math display="block">
          <m:mrow>
            <m:mrow>
              <m:mo>{</m:mo>

              <m:mrow>
                <m:mrow>
                  <m:mo>(</m:mo>

                  <m:mrow>
                    <m:msub>
                      <m:mi>q</m:mi>

                      <m:mi>1</m:mi>
                    </m:msub>

                    <m:mo>≤ w</m:mo>
                  </m:mrow>

                  <m:mo>)</m:mo>
                </m:mrow>

                <m:mo>⋂</m:mo>

                <m:mrow>
                  <m:mo>(</m:mo>

                  <m:mrow>
                    <m:msub>
                      <m:mi>q</m:mi>

                      <m:mi>2</m:mi>
                    </m:msub>

                    <m:mo>≤ w</m:mo>
                  </m:mrow>

                  <m:mo>)</m:mo>
                </m:mrow>

                <m:mo>⋂</m:mo>

                <m:mi>....</m:mi>

                <m:mo>⋂</m:mo>

                <m:mrow>
                  <m:mo>(</m:mo>

                  <m:mrow>
                    <m:msub>
                      <m:mi>q</m:mi>

                      <m:mi>n</m:mi>
                    </m:msub>

                    <m:mo>≤ w</m:mo>
                  </m:mrow>

                  <m:mo>)</m:mo>
                </m:mrow>
              </m:mrow>

              <m:mo>}</m:mo>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>Because the peaks are assumed to be statistically independent, the
      probability of the compound event is the product of the probabilities of
      the individual events. Therefore the probability that the random
      variable W<inlineequation>
          <m:math display="inline">
            <m:mi>≤</m:mi>
          </m:math>
        </inlineequation> w in a POT series with n events occurring over the
      interval t simplifies to:</para>

      <equation xml:id="b3_ch2_e_2uebb">
        <m:math display="block">
          <m:mrow>
            <m:mrow>
              <m:mi>P(W≤w∣n,t)</m:mi>
            </m:mrow>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mi>P[(</m:mi>

              <m:msub>
                <m:mi>x</m:mi>

                <m:mi>i</m:mi>
              </m:msub>

              <m:mo>≤</m:mo>

              <m:mo>w)</m:mo>

              <m:mrow>
                <m:mo>⋂</m:mo>

                <m:mo>.... ⋂</m:mo>

                <m:mo>(</m:mo>

                <m:msub>
                  <m:mi>q</m:mi>

                  <m:mi>n</m:mi>
                </m:msub>
              </m:mrow>

              <m:mo>≤</m:mo>

              <m:mi>w)]</m:mi>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <equation xml:id="b3_ch2_e_abslg">
        <m:math display="block">
          <m:mrow>
            <m:mo>=</m:mo>

            <m:mrow>
              <m:mi>P(</m:mi>

              <m:msub>
                <m:mi>q</m:mi>

                <m:mi>1</m:mi>
              </m:msub>

              <m:mi>≤w)P(</m:mi>

              <m:msub>
                <m:mi>q</m:mi>

                <m:mi>2</m:mi>
              </m:msub>

              <m:mi>≤</m:mi>

              <m:mo>w)....P(</m:mo>

              <m:mrow>
                <m:msub>
                  <m:mi>q</m:mi>

                  <m:mi>n</m:mi>
                </m:msub>

                <m:mo>≤ w )</m:mo>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <equation xml:id="b3_ch2_e_uxlp2">
        <m:math display="block">
          <m:mrow>
            <m:mi>=</m:mi>

            <m:mo>P</m:mo>

            <m:mrow>
              <m:mo>(</m:mo>

              <m:mi>q≤w</m:mi>

              <m:mo>)</m:mo>
            </m:mrow>

            <m:mo>ⁿ</m:mo>
          </m:mrow>
        </m:math>
      </equation>

      <para>The number of POT events n occurring over an interval t is random.
      Suppose that the random variable n follows a Poisson distribution with ν
      being the average number of POT events per year; that is:</para>

      <equation xml:id="b3_ch2_e_0lceb">
        <m:math display="block">
          <m:mrow>
            <m:mi>P(n|ν,t)</m:mi>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mfrac>
                <m:mrow>
                  <m:msup>
                    <m:mi>(νt)</m:mi>

                    <m:mi>n</m:mi>
                  </m:msup>

                  <m:mrow>
                    <m:mi>exp</m:mi>

                    <m:mo>(-νt)</m:mo>
                  </m:mrow>
                </m:mrow>

                <m:mi>n!</m:mi>
              </m:mfrac>

              <m:mo>, n =</m:mo>

              <m:mi>0,1,2....</m:mi>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>Application of the total probability theorem yields the
      distribution of the largest peak magnitude over the time interval with
      length t:</para>

      <equation xml:id="b3_ch2_e_zdrjq">
        <m:math display="block">
          <m:mrow>
            <m:mi>P(W≤w|t)</m:mi>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mrow>
                <m:mrow>
                  <m:munderover>
                    <m:mo>∑</m:mo>

                    <m:mi>n=0</m:mi>

                    <m:mi>∞</m:mi>
                  </m:munderover>

                  <m:mi>P(W≤w|n,t)P(n|ν,t)</m:mi>
                </m:mrow>
              </m:mrow>

              <m:mo>=</m:mo>

              <m:mi>exp[-(νt)P(q&gt;w)</m:mi>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>where P(W<inlineequation>
          <m:math display="inline">
            <m:mi>≤</m:mi>
          </m:math>
        </inlineequation>w|t) is the probability that the largest peak over
      time interval t is less than or equal to w. When the time interval t is
      set to one year, <xref linkend="b3_ch2_e_zdrjq"/> defines the
      distribution of the AM series.</para>

      <para>ARR defines Annual Exceedance Probability as:</para>

      <equation xml:id="b3_ch2_e_w9t35">
        <m:math display="block">
          <m:mrow>
            <m:mi>AEP(w)</m:mi>

            <m:mo>=</m:mo>

            <m:mi>1-P(W≤w| t=1)</m:mi>
          </m:mrow>
        </m:math>
      </equation>

      <para>where AEP(w) is the probability of the largest peak in a year
      exceeding magnitude w.</para>
    </section>

    <section xml:id="b3_ch2_s_fzc71">
      <title>Exceedances per Year (EY)</title>

      <para>We now derive the probability distribution of the time to the next
      flood peak which has a magnitude in excess of w. With regard to <xref
      linkend="b3_ch2_e_zdrjq"/>, if the largest peak during the interval t is
      less than or equal to w, then the time to the next peak with magnitude
      in excess of w must be greater than t. It therefore follows that the
      distribution of the time to the next peak with magnitude exceeding w
      is</para>

      <equation xml:id="b3_ch2_e_30300">
        <m:math display="block">
          <m:mrow>
            <m:mtext>P(Time to next peak exceeding w≤t)</m:mtext>

            <m:mo>=</m:mo>

            <m:mi>1- exp[-νP(q&gt;w)t]</m:mi>
          </m:mrow>
        </m:math>
      </equation>

      <equation xml:id="b3_ch2_e_28swr">
        <m:math display="block">
          <m:mrow>
            <m:mo>=</m:mo>

            <m:mi>1-exp[-EY(w)t]</m:mi>
          </m:mrow>
        </m:math>
      </equation>

      <para>This is
        <?oxy_delete author="RadhikaChhotai" timestamp="20151022T174112+1100" content="recognized"?><?oxy_insert_start author="RadhikaChhotai" timestamp="20151022T174112+1100"?>recognised<?oxy_insert_end?>
        as an exponential distribution with parameter vP(q&gt;w) which is the expected number of
        peaks exceeding w per year.</para>

      <para>ARR defines this parameter as EY(w) which stands for Exceedances
      per Year, but more strictly, is the expected number of peaks that exceed
      w in a year.</para>
    </section>

    <section xml:id="b3_ch2_s_syine">
      <title>Linking AEP and EY</title>

      <para>If we select a particular peak magnitude w, combining <xref
      linkend="b3_ch2_e_zdrjq"/>, <xref linkend="b3_ch2_e_w9t35"/> and <xref
      linkend="b3_ch2_e_30300"/> yields the following relationship between
      EY(w) and AEP(w):</para>

      <equation xml:id="b3_ch2_e_yf64d">
        <m:math display="block">
          <m:mrow>
            <m:mi>AEP(w)</m:mi>

            <m:mo>=</m:mo>

            <m:mi>1 - P (W≤w | t=1 )</m:mi>
          </m:mrow>
        </m:math>
      </equation>

      <equation xml:id="b3_ch2_e_gbvhs">
        <m:math display="block">
          <m:mrow>
            <m:mo>=</m:mo>

            <m:mi>1- exp[-νP(q&gt;w)]</m:mi>
          </m:mrow>
        </m:math>
      </equation>

      <equation xml:id="b3_ch2_e_vjpol">
        <m:math display="block">
          <m:mi>= 1 - exp[-EY(w)]</m:mi>
        </m:math>
      </equation>

      <para>If we express AEP(w) as 1/Y(w) then <xref
      linkend="b3_ch2_e_yf64d"/> can be rewritten as:</para>

      <equation xml:id="b3_ch2_e_v4tbm">
        <m:math display="block">
          <m:mrow>
            <m:mi>EY(w)</m:mi>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:msub>
                <m:mi>-log</m:mi>

                <m:mi>e</m:mi>
              </m:msub>

              <m:mo>[1-AEP(w)]</m:mo>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <equation xml:id="b3_ch2_e_tftt7">
        <m:math display="block">
          <m:mrow>
            <m:mo>=</m:mo>

            <m:mrow>
              <m:msub>
                <m:mi>-log</m:mi>

                <m:mi>e</m:mi>
              </m:msub>

              <m:mrow>
                <m:mo>[</m:mo>

                <m:mrow>
                  <m:mi>1</m:mi>

                  <m:mo>-</m:mo>

                  <m:mfrac>
                    <m:mi>1</m:mi>

                    <m:mi>Y(w)</m:mi>
                  </m:mfrac>
                </m:mrow>

                <m:mo>]</m:mo>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>This relationship assumes peaks in the POT series are
      statistically independent and that there is no seasonality in the sense
      that the probability density of the POT peak above a threshold
      p(q|q&gt;q<subscript>o</subscript>) does not change over the year. While
      the no-seasonality assumption appears questionable on first inspection,
      in practice the threshold q<subscript>0</subscript> is selected so that
      the expected number of peaks exceeding the threshold
      q<subscript>0</subscript> in any year is of the order of 1. This is done
      to ensure the POT peaks are genuine floods and statistically
      independent. As a consequence of the high threshold selected in
      practice, the impact of seasonality is diminished.</para>
    </section>
  </section>

  <section xml:id="b3_ch2_s_ktbsy">
    <title>Box 2: Formal Definition of Zero-Threshold Mixture
    Distribution</title>

    <para>The zero-threshold mixture model has a distribution function:</para>

    <equation xml:id="b3_ch2_e_6bhbp">
      <m:math display="block">
        <m:mrow>
          <m:mi>P(Q≤q|θ)</m:mi>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mo>{</m:mo>

            <m:mtable>
              <m:mtr>
                <m:mtd>
                  <m:mrow>
                    <m:msub>
                      <m:mi>P</m:mi>

                      <m:mi>0</m:mi>
                    </m:msub>

                    <m:mo>if q =</m:mo>

                    <m:msub>
                      <m:mi>q</m:mi>

                      <m:mi>0</m:mi>
                    </m:msub>
                  </m:mrow>
                </m:mtd>
              </m:mtr>

              <m:mtr>
                <m:mtd>
                  <m:mrow>
                    <m:msub>
                      <m:mi>P</m:mi>

                      <m:mi>0</m:mi>
                    </m:msub>

                    <m:mrow>
                      <m:mi>+(1-</m:mi>

                      <m:msub>
                        <m:mi>P</m:mi>

                        <m:mi>0</m:mi>
                      </m:msub>

                      <m:mi>)</m:mi>

                      <m:mfrac>
                        <m:mrow>
                          <m:mi>P(Q≤q∣</m:mi>

                          <m:mo>θ) -</m:mo>

                          <m:mi>P(Q≤</m:mi>

                          <m:msub>
                            <m:mi>q</m:mi>

                            <m:mi>0</m:mi>
                          </m:msub>

                          <m:mi>∣θ)</m:mi>
                        </m:mrow>

                        <m:mrow>
                          <m:mi>P(Q&gt;</m:mi>

                          <m:msub>
                            <m:mi>q</m:mi>

                            <m:mi>0</m:mi>
                          </m:msub>

                          <m:mo>|</m:mo>

                          <m:mi>θ)</m:mi>
                        </m:mrow>
                      </m:mfrac>

                      <m:mrow>
                        <m:mi>if q&gt;</m:mi>

                        <m:msub>
                          <m:mi>q</m:mi>

                          <m:mi>0</m:mi>
                        </m:msub>
                      </m:mrow>
                    </m:mrow>
                  </m:mrow>
                </m:mtd>
              </m:mtr>
            </m:mtable>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>where q<subscript>0</subscript> is the zero-threshold flow,
    P<subscript>0</subscript> is the probability of the AM peak equaling
    q<subscript>0</subscript> and P(Q<inlineequation>
        <m:math display="inline">
          <m:mi>≤</m:mi>
        </m:math>
      </inlineequation>q|θ) is a probability model such as described in <xref
    linkend="b3_ch2_t_s5j9j"/>.</para>

    <para>The pdf of the mixture model can be expressed using the generalized
    probability density which allows the random variable to take discrete
    values as well as continuous values:</para>

    <equation xml:id="b3_ch2_e_3izqm">
      <m:math display="block">
        <m:mi>P(q|θ)</m:mi>

        <m:mo>=</m:mo>

        <m:mrow>
          <m:mo>{</m:mo>

          <m:mtable>
            <m:mtr>
              <m:mtd>
                <m:mrow>
                  <m:msub>
                    <m:mi>P</m:mi>

                    <m:mi>0</m:mi>
                  </m:msub>

                  <m:mo>if q =</m:mo>

                  <m:msub>
                    <m:mi>q</m:mi>

                    <m:mi>0</m:mi>
                  </m:msub>
                </m:mrow>
              </m:mtd>
            </m:mtr>

            <m:mtr>
              <m:mtd>
                <m:mrow>
                  <m:mrow>
                    <m:mfrac>
                      <m:mrow>
                        <m:mi>1</m:mi>

                        <m:mo>-</m:mo>

                        <m:msub>
                          <m:mi>P</m:mi>

                          <m:mi>0</m:mi>
                        </m:msub>
                      </m:mrow>

                      <m:mrow>
                        <m:mi>P(q&gt;</m:mi>

                        <m:msub>
                          <m:mi>q</m:mi>

                          <m:mi>0</m:mi>
                        </m:msub>

                        <m:mo>|</m:mo>

                        <m:mi>θ)</m:mi>
                      </m:mrow>
                    </m:mfrac>

                    <m:mrow>
                      <m:mrow>
                        <m:mrow>
                          <m:mi>p(q|θ)/(q,</m:mi>

                          <m:msub>
                            <m:mi>q</m:mi>

                            <m:mi>0</m:mi>
                          </m:msub>
                        </m:mrow>

                        <m:mo>) if q&gt;</m:mo>
                      </m:mrow>

                      <m:msub>
                        <m:mi>q</m:mi>

                        <m:mi>0</m:mi>
                      </m:msub>
                    </m:mrow>
                  </m:mrow>
                </m:mrow>
              </m:mtd>
            </m:mtr>
          </m:mtable>
        </m:mrow>
      </m:math>
    </equation>

    <para>where I() is an indicator function defined as:</para>

    <equation xml:id="b3_ch2_e_kwfzv">
      <m:math display="block">
        <m:mrow>
          <m:mrow>
            <m:mi>I(q,</m:mi>

            <m:mrow>
              <m:msub>
                <m:mi>q</m:mi>

                <m:mi>0</m:mi>
              </m:msub>
            </m:mrow>
          </m:mrow>

          <m:mo>) =</m:mo>

          <m:mrow>
            <m:mo>{</m:mo>

            <m:mtable>
              <m:mtr>
                <m:mtd>
                  <m:mrow>
                    <m:mi>1</m:mi>

                    <m:mo>if q&gt;</m:mo>

                    <m:msub>
                      <m:mi>q</m:mi>

                      <m:mi>0</m:mi>
                    </m:msub>
                  </m:mrow>
                </m:mtd>
              </m:mtr>

              <m:mtr>
                <m:mtd>
                  <m:mrow>
                    <m:mi>0</m:mi>

                    <m:mo>if</m:mo>

                    <m:msub>
                      <m:mi>q≤q</m:mi>

                      <m:mi>0</m:mi>
                    </m:msub>
                  </m:mrow>
                </m:mtd>
              </m:mtr>
            </m:mtable>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>
  </section>

  <section xml:id="b3_ch2_s_aa2de">
    <title>Box 3: Likelihood function: No-error-discharge case</title>

    <para>The likelihood function is, by definition, the joint pdf of D given
    the parameter vector <inlineequation>
        <m:math display="inline">
          <m:mi>θ</m:mi>
        </m:math>
      </inlineequation>.</para>

    <para>The likelihood function for the gauged data is the joint pdf of the
    n gauged floods. Given the AM flood peaks are statistically independent,
    the likelihood can be simplified to (Stedinger and Cohn, 1986):</para>

    <equation xml:id="b3_ch2_e_x1evi">
      <m:math display="block">
        <m:mrow>
          <m:mrow>
            <m:mi>p(</m:mi>

            <m:msub>
              <m:mi>q</m:mi>

              <m:mi>1</m:mi>
            </m:msub>

            <m:mi>,...,</m:mi>

            <m:msub>
              <m:mi>q</m:mi>

              <m:mi>n</m:mi>
            </m:msub>

            <m:mi>|θ)</m:mi>
          </m:mrow>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mrow>
              <m:munderover>
                <m:mo>∏</m:mo>

                <m:mi>i=1</m:mi>

                <m:mi>n</m:mi>
              </m:munderover>

              <m:mi>p</m:mi>
            </m:mrow>

            <m:msub>
              <m:mi>(q</m:mi>

              <m:mi>i</m:mi>
            </m:msub>

            <m:mi>|</m:mi>

            <m:mo>θ)</m:mo>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>The likelihood of the binomial censored data relies on the fact that
    the probability of observing exactly x exceedances in n years is given by
    the binomial distribution</para>

    <equation xml:id="b3_ch2_e_bo9zf">
      <m:math display="block">
        <m:mrow>
          <m:mi>P(X|n,∏)=</m:mi>

          <m:msubsup>
            <m:mi>C</m:mi>

            <m:mi>x</m:mi>

            <m:mi>n</m:mi>
          </m:msubsup>

          <m:mi>(1-</m:mi>

          <m:msup>
            <m:mi>∏)</m:mi>

            <m:mi>n-x</m:mi>
          </m:msup>

          <m:msup>
            <m:mi>∏</m:mi>

            <m:mi>x</m:mi>
          </m:msup>
        </m:mrow>
      </m:math>
    </equation>

    <para>where <inlineequation>
        <m:math display="inline">
          <m:mi>Π</m:mi>
        </m:math>
      </inlineequation> is the probability of an exceedance.</para>

    <para>Provided each censoring threshold does not overlap over time with
    any other censoring threshold, the likelihood of the censored data
    becomes:</para>

    <equation xml:id="b3_ch2_e_l0ukb">
      <m:math display="block">
        <m:mrow>
          <m:mi>p(censored data∣</m:mi>

          <m:mrow>
            <m:mi>θ)</m:mi>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:munderover>
                <m:mo>∏</m:mo>

                <m:mi>i=1</m:mi>

                <m:mi>m</m:mi>
              </m:munderover>

              <m:mi>[1-P(Q≤</m:mi>
            </m:mrow>
          </m:mrow>

          <m:msub>
            <m:mi>s</m:mi>

            <m:mi>i</m:mi>
          </m:msub>

          <m:mo>∣θ</m:mo>

          <m:msup>
            <m:mi>)]</m:mi>

            <m:msub>
              <m:mi>a</m:mi>

              <m:mi>0</m:mi>
            </m:msub>
          </m:msup>

          <m:mrow>
            <m:mi>P(Q≤</m:mi>

            <m:msub>
              <m:mi>s</m:mi>

              <m:mi>i</m:mi>
            </m:msub>

            <m:msup>
              <m:mi>∣θ)</m:mi>

              <m:msub>
                <m:mi>b</m:mi>

                <m:mi>0</m:mi>
              </m:msub>
            </m:msup>

            <m:mrow>
              <m:mo>=</m:mo>

              <m:mrow>
                <m:munderover>
                  <m:mo>∏</m:mo>

                  <m:mi>i=1</m:mi>

                  <m:mi>m</m:mi>
                </m:munderover>

                <m:mi>P(</m:mi>
              </m:mrow>
            </m:mrow>

            <m:mrow>
              <m:msub>
                <m:mi>a</m:mi>

                <m:mi>i</m:mi>
              </m:msub>

              <m:msub>
                <m:mi>,b</m:mi>

                <m:mi>i</m:mi>
              </m:msub>

              <m:mi>|</m:mi>

              <m:msub>
                <m:mi>s</m:mi>

                <m:mi>i</m:mi>
              </m:msub>

              <m:mi>,</m:mi>
            </m:mrow>
          </m:mrow>

          <m:mi>θ)</m:mi>
        </m:mrow>
      </m:math>
    </equation>

    <para>where
    P(a<subscript>i</subscript>,b<subscript>i</subscript>|s<subscript>i</subscript>,<inlineequation>
        <m:math display="inline">
          <m:mi>θ</m:mi>
        </m:math>
      </inlineequation>) is the binomial probability of observing exactly
    a<subscript>i</subscript> exceedances above the threshold discharge
    s<subscript>i</subscript> in
    (a<subscript>i</subscript>+b<subscript>i</subscript>).</para>
  </section>

  <section xml:id="b3_ch2_s_vyzbz">
    <title>Box 4: Likelihood function: Error-in-discharge case</title>

    <para><xref linkend="b3_ch2_f_6qnp5"/> presents a rating error space
    diagram. In zone 1 (<xref linkend="b3_ch2_f_6qnp5"/>), the interpolation
    zone it is assumed the rating error multiplier e<subscript>1</subscript>
    equals 1 – that is, errors within the rated part of the rating curve are
    deemed negligible. As a result the estimated discharge w equals the true
    discharge q. However, in zone 2, the extension zone, the rating error
    multiplier e<subscript>2</subscript> is assumed to be a random variable
    with mean of 1. The anchor point
    (q<subscript>1</subscript>,w<subscript>1</subscript>) separates the
    interpolation and extension zones. The rating error model can represented
    mathematically as:</para>

    <equation xml:id="b3_ch2_e_bvmht">
      <m:math display="block">
        <m:mrow>
          <m:mi>w</m:mi>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mo>{</m:mo>

            <m:mtable>
              <m:mtr>
                <m:mtd>
                  <m:mrow>
                    <m:mi>q</m:mi>

                    <m:mrow>
                      <m:msub>
                        <m:mi>if q ≤x</m:mi>

                        <m:mi>i</m:mi>
                      </m:msub>
                    </m:mrow>
                  </m:mrow>
                </m:mtd>
              </m:mtr>

              <m:mtr>
                <m:mtd>
                  <m:mrow>
                    <m:mrow>
                      <m:msub>
                        <m:mi>w</m:mi>

                        <m:mi>1</m:mi>
                      </m:msub>

                      <m:mo>+</m:mo>

                      <m:msub>
                        <m:mi>e</m:mi>

                        <m:mi>2</m:mi>
                      </m:msub>

                      <m:mo>(q-</m:mo>

                      <m:msub>
                        <m:mi>q</m:mi>

                        <m:mi>1</m:mi>
                      </m:msub>
                    </m:mrow>

                    <m:mrow>
                      <m:mi>)</m:mi>

                      <m:mo>if q&gt;</m:mo>

                      <m:msub>
                        <m:mi>q</m:mi>

                        <m:mi>1</m:mi>
                      </m:msub>
                    </m:mrow>
                  </m:mrow>
                </m:mtd>
              </m:mtr>
            </m:mtable>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>The rating error multiplier e<subscript>2</subscript> is sampled
    only once at the time of extending the rating curve. Therefore, all flood
    discharge estimates exceeding the anchor value of
    q<subscript>1</subscript> (which equals w<subscript>1</subscript>) are
    corrupted by the same rating error multiplier. It must be stressed that
    the error e<subscript>2</subscript> is not known – at best, only its
    probability distribution can be estimated. For practical applications one
    can assume e<subscript>2</subscript> is distributed as either a log-normal
    or normal distribution with mean 1 and standard deviation <inlineequation>
        <m:math display="inline">
          <m:msub>
            <m:mi>σ</m:mi>

            <m:mi>2</m:mi>
          </m:msub>
        </m:math>
      </inlineequation>.</para>

    <figure xml:id="b3_ch2_f_6qnp5">
      <title>Rating error multiplier space diagram for rating curve</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3009.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>Data are assigned to each of the two zones, i=1,2, in the rating
    error space diagram. The rating error multiplier standard deviation for
    the extension zone <inlineequation>
        <m:math display="inline">
          <m:msub>
            <m:mi>σ</m:mi>

            <m:mi>2</m:mi>
          </m:msub>
        </m:math>
      </inlineequation> is assigned a value with <inlineequation>
        <m:math display="inline">
          <m:mrow>
            <m:msub>
              <m:mi>σ</m:mi>

              <m:mi>1</m:mi>
            </m:msub>

            <m:mo>= 0</m:mo>
          </m:mrow>
        </m:math>
      </inlineequation>. There are n<subscript>i</subscript> annual flood peak
    estimates w<subscript>ji</subscript> satisfying the zone constraint
    w<subscript>i-1</subscript> ≤ w<subscript>ji</subscript> &lt;
    w<subscript>i</subscript>, j=1,..,n<subscript>i</subscript> where
    w<subscript>0</subscript>=0 and w<subscript>2</subscript>= <inlineequation>
        <m:math display="inline">
          <m:mi>∞</m:mi>
        </m:math>
      </inlineequation>. In addition, there are m<subscript>i</subscript>
    threshold discharge estimates w<subscript>ji</subscript> for which there
    are a<subscript>ji</subscript> exceedances in
    (a<subscript>ji</subscript>+b<subscript>ji</subscript>) years,
    j=1,..,m<subscript>i</subscript>. Collectively this data is represented
    as:</para>

    <equation xml:id="b3_ch2_e_68r89">
      <m:math display="block">
        <m:mrow>
          <m:mi>D</m:mi>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:msub>
              <m:mi>{D</m:mi>

              <m:mi>i</m:mi>
            </m:msub>

            <m:mo>, i=1,2}</m:mo>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <equation xml:id="b3_ch2_e_eyubb">
      <m:math display="block">
        <m:mrow>
          <m:mo>=</m:mo>

          <m:mrow>
            <m:msub>
              <m:mi>{[w</m:mi>

              <m:mi>ji</m:mi>
            </m:msub>

            <m:mo>,j=1,...</m:mo>

            <m:msub>
              <m:mi>n</m:mi>

              <m:mi>i</m:mi>
            </m:msub>

            <m:msub>
              <m:mi>;w</m:mi>

              <m:mi>ji</m:mi>
            </m:msub>

            <m:msub>
              <m:mi>,a</m:mi>

              <m:mi>ji</m:mi>
            </m:msub>

            <m:msub>
              <m:mi>,b</m:mi>

              <m:mi>ji</m:mi>
            </m:msub>

            <m:mrow>
              <m:mi>,j=1,...,</m:mi>

              <m:msub>
                <m:mi>m</m:mi>

                <m:mi>i</m:mi>
              </m:msub>

              <m:mi>],i=1,2}</m:mi>
            </m:mrow>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>Following Kuczera (1999) it can be shown for the two-zone rating
    error model of <xref linkend="b3_ch2_f_6qnp5"/> the likelihood reduces
    to:</para>

    <equation xml:id="b3_ch2_e_y1vv5">
      <m:math display="block">
        <m:mrow>
          <m:mrow>
            <m:mi>p(</m:mi>

            <m:msub>
              <m:mi>D</m:mi>

              <m:mi>1</m:mi>
            </m:msub>

            <m:msub>
              <m:mi>,D</m:mi>

              <m:mi>2</m:mi>
            </m:msub>

            <m:mrow>
              <m:mi>∣</m:mi>

              <m:msub>
                <m:mi>θ</m:mi>

                <m:mi>1</m:mi>
              </m:msub>
            </m:mrow>

            <m:mrow>
              <m:msub>
                <m:mi>,σ</m:mi>

                <m:mi>2</m:mi>
              </m:msub>

              <m:mo>)</m:mo>
            </m:mrow>
          </m:mrow>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mrow>
              <m:mi>p(</m:mi>

              <m:msub>
                <m:mi>D</m:mi>

                <m:mi>1</m:mi>
              </m:msub>

              <m:msub>
                <m:mi>,e</m:mi>

                <m:mi>1</m:mi>
              </m:msub>

              <m:mo>=1|θ</m:mo>

              <m:mi>)</m:mi>
            </m:mrow>

            <m:mrow>
              <m:mrow>
                <m:mo>[</m:mo>

                <m:mrow>
                  <m:mrow>
                    <m:munderover>
                      <m:mo>∫p(</m:mo>

                      <m:mi>0</m:mi>

                      <m:mi mathvariant="normal">∞</m:mi>
                    </m:munderover>
                  </m:mrow>

                  <m:msub>
                    <m:mi>D</m:mi>

                    <m:mi>2</m:mi>
                  </m:msub>

                  <m:msub>
                    <m:mi>,e</m:mi>

                    <m:mi>2</m:mi>
                  </m:msub>

                  <m:mo>| θ)g(</m:mo>

                  <m:mrow>
                    <m:msub>
                      <m:mi>e</m:mi>

                      <m:mi>2</m:mi>
                    </m:msub>

                    <m:msub>
                      <m:mi>|σ</m:mi>

                      <m:mi>2</m:mi>
                    </m:msub>
                  </m:mrow>

                  <m:msub>
                    <m:mi>)de</m:mi>

                    <m:mi>2</m:mi>
                  </m:msub>
                </m:mrow>

                <m:mo>]</m:mo>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>where</para>

    <equation xml:id="b3_ch2_e_pdt6x">
      <m:math display="block">
        <m:mrow>
          <m:mrow>
            <m:mi>p(</m:mi>

            <m:msub>
              <m:mi>D</m:mi>

              <m:mi>i</m:mi>
            </m:msub>

            <m:msub>
              <m:mi>,e</m:mi>

              <m:mi>i</m:mi>
            </m:msub>

            <m:mo>|</m:mo>

            <m:mi>θ)</m:mi>
          </m:mrow>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mrow>
              <m:munderover>
                <m:mo>∏</m:mo>

                <m:mi>j=1</m:mi>

                <m:msub>
                  <m:mi>n</m:mi>

                  <m:mi>i</m:mi>
                </m:msub>
              </m:munderover>

              <m:mfrac>
                <m:mi>1</m:mi>

                <m:msub>
                  <m:mi>e</m:mi>

                  <m:mi>i</m:mi>
                </m:msub>
              </m:mfrac>
            </m:mrow>

            <m:mo>p(</m:mo>

            <m:msub>
              <m:mi>q</m:mi>

              <m:mi>i-1</m:mi>
            </m:msub>

            <m:mo>+</m:mo>

            <m:mrow>
              <m:mfrac>
                <m:mrow>
                  <m:msub>
                    <m:mi>w</m:mi>

                    <m:mi>ji</m:mi>
                  </m:msub>

                  <m:mo>-</m:mo>

                  <m:msub>
                    <m:mi>w</m:mi>

                    <m:mi>i-1</m:mi>
                  </m:msub>
                </m:mrow>

                <m:msub>
                  <m:mi>e</m:mi>

                  <m:mi>i</m:mi>
                </m:msub>
              </m:mfrac>

              <m:mo>| θ)</m:mo>

              <m:mrow>
                <m:munderover>
                  <m:mo>∏</m:mo>

                  <m:mi>j=1</m:mi>

                  <m:msub>
                    <m:mi>m</m:mi>

                    <m:mi>i</m:mi>
                  </m:msub>
                </m:munderover>

                <m:mi>P[</m:mi>
              </m:mrow>

              <m:msub>
                <m:mi>a</m:mi>

                <m:mi>ji</m:mi>
              </m:msub>

              <m:msub>
                <m:mi>,b</m:mi>

                <m:mi>ji</m:mi>
              </m:msub>

              <m:msub>
                <m:mi>|q</m:mi>

                <m:mi>i-1</m:mi>
              </m:msub>

              <m:mi>+</m:mi>
            </m:mrow>

            <m:mfrac>
              <m:mrow>
                <m:msub>
                  <m:mi>w</m:mi>

                  <m:mi>ji</m:mi>
                </m:msub>

                <m:mo>-</m:mo>

                <m:msub>
                  <m:mi>w</m:mi>

                  <m:mi>i-1</m:mi>
                </m:msub>
              </m:mrow>

              <m:msub>
                <m:mi>e</m:mi>

                <m:mi>i</m:mi>
              </m:msub>
            </m:mfrac>

            <m:mi>,θ]</m:mi>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>g(e<subscript>i</subscript>|<inlineequation>
        <m:math display="inline">
          <m:msub>
            <m:mi>σ</m:mi>

            <m:mi>i</m:mi>
          </m:msub>
        </m:math>
      </inlineequation>) is the rating error multiplier pdf with mean 1 and
    standard deviation <inlineequation>
        <m:math display="inline">
          <m:msub>
            <m:mi>σ</m:mi>

            <m:mi>i</m:mi>
          </m:msub>
        </m:math>
      </inlineequation> and P(a,b|s,<inlineequation>
        <m:math display="inline">
          <m:mi>θ</m:mi>
        </m:math>
      </inlineequation>) is the binomial probability of observing exactly a
    exceedances above the threshold discharge s in (a+b). This is a complex
    expression which can only be evaluated numerically. However, it makes the
    fullest use of information on annual flood peaks and binomial-censored
    data in the presence of rating curve error. <xref
    linkend="b3_ch2_s_zlx6z"/> offers limited guidance on the choice of
    <inlineequation>
        <m:math display="inline">
          <m:msub>
            <m:mi>σ</m:mi>

            <m:mi>2</m:mi>
          </m:msub>
        </m:math>
      </inlineequation>.</para>
  </section>

  <section xml:id="b3_ch2_s_j8hj6">
    <title>Box 5: Importance sampling from the posterior distribution</title>

    <para>Importance sampling is a widely used method (Gelman <emphasis>et
    al</emphasis>., 1995) for sampling parameters from a target probability
    model for which there is no algorithm to draw random samples. The basic
    idea is to sample from a probability model for which a sampling algorithm
    exists – the probability model is called the importance distribution and
    the samples are called particles. The particles are then weighted so that
    they represent samples from the target distribution. The closer the
    importance distribution approximates the target, the more efficient the
    sampling.</para>

    <para>Three steps are involved:</para>

    <para><emphasis>Step 1:</emphasis> Find most probable parameters of the
    target distribution</para>

    <para>Any robust search method can be used to locate the value of <inlineequation>
        <m:math display="inline">
          <m:mi>θ</m:mi>
        </m:math>
      </inlineequation><?oxy_insert_start author="RadhikaChhotai" timestamp="20151022T174306+1100"?>,<?oxy_insert_end?>
      which
      <?oxy_delete author="RadhikaChhotai" timestamp="20151022T174259+1100" content="maximizes"?><?oxy_insert_start author="RadhikaChhotai" timestamp="20151022T174259+1100"?>maximises<?oxy_insert_end?>
      the logarithm of the posterior probability density; that is,</para>

    <equation xml:id="b3_ch2_e_bqy9q">
      <m:math display="block">
        <m:mrow>
          <m:mi>θ</m:mi>

          <m:mo>←</m:mo>

          <m:mi>max</m:mi>

          <m:mo>log</m:mo>

          <m:mi>p</m:mi>

          <m:mo>(θ|D)</m:mo>
        </m:mrow>
      </m:math>
    </equation>

    <para>where <inlineequation>
        <m:math display="inline">
          <m:mi>θ</m:mi>
        </m:math>
      </inlineequation> is the most probable value of <inlineequation>
        <m:math display="inline">
          <m:mi>θ</m:mi>
        </m:math>
      </inlineequation>. The shuffled complex evolution algorithm of Duan
    <emphasis>et al</emphasis>. (1992) is a recommended search method.</para>

    <para><emphasis>Step 2: </emphasis>Obtain the importance distribution using a
      multi<?oxy_insert_start author="RadhikaChhotai" timestamp="20151022T174317+1100"?>-<?oxy_insert_end?>normal
      approximation to the target distribution</para>

    <para>Almost always, the log of posterior pdf <inlineequation>
        <m:math display="inline">
          <m:mi>p(θ|D)</m:mi>
        </m:math>
      </inlineequation> can be approximated by a second-order Taylor series
    expansion about the most probable parameter to yield the multivariate
    normal approximation</para>

    <equation xml:id="b3_ch2_e_ee78h">
      <m:math display="block">
        <m:mrow>
          <m:mi>θ|</m:mi>

          <m:mo>D~N(θ</m:mo>

          <m:mi>,</m:mi>

          <m:mo>Σ</m:mo>

          <m:mi>)</m:mi>
        </m:mrow>
      </m:math>
    </equation>

    <para>where θ is interpreted as the mean and the posterior covariance
    <inlineequation>
        <m:math display="inline">
          <m:mi>Σ</m:mi>
        </m:math>
      </inlineequation> is defined as the inverse of the Hessian</para>

    <equation xml:id="b3_ch2_e_u721b">
      <m:math display="block">
        <m:mrow>
          <m:mi>Σ</m:mi>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:msup>
              <m:mrow>
                <m:mo>(</m:mo>

                <m:mrow>
                  <m:mi>-</m:mi>

                  <m:mfrac>
                    <m:mrow>
                      <m:msup>
                        <m:mi>δ</m:mi>

                        <m:mi>2</m:mi>
                      </m:msup>

                      <m:msub>
                        <m:mi>log</m:mi>

                        <m:mi>e</m:mi>
                      </m:msub>

                      <m:mi>p(θ</m:mi>

                      <m:mo>| D)</m:mo>
                    </m:mrow>

                    <m:mrow>
                      <m:msup>
                        <m:mi>δ</m:mi>

                        <m:mi>2</m:mi>
                      </m:msup>

                      <m:mi>θ</m:mi>
                    </m:mrow>
                  </m:mfrac>
                </m:mrow>

                <m:mo>)</m:mo>
              </m:mrow>

              <m:mi>-1</m:mi>
            </m:msup>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>An adaptive difference scheme should be used to evaluate the
    Hessian. Particular care needs to be exercised when selecting finite
    difference perturbations for the GEV and LPIII distributions when upper or
    lower bounds are close to the observed data.</para>

    <para><emphasis>Step 3:</emphasis> Importance sampling of target
    distribution</para>

    <para>The importance sampling algorithm proceeds as follows:</para>

    <orderedlist>
      <listitem>
        <para>Sample N particles according to <inlineequation>
            <m:math display="inline">
              <m:msub>
                <m:mi>θ</m:mi>
                <m:mi>i</m:mi>
              </m:msub>
              <m:mo>←</m:mo>
              <m:msub>
                <m:mi>p</m:mi>
                <m:mi>N</m:mi>
              </m:msub>
              <m:mo>(θ)</m:mo>
              <m:mi>,i=1,...,N</m:mi>
              <m:mi/>
            </m:math>
          </inlineequation>where pN(<inlineequation>
            <m:math display="inline">
              <m:mi>θ</m:mi>
            </m:math>
          </inlineequation>) is the pdf of the
          multi<?oxy_insert_start author="RadhikaChhotai" timestamp="20151022T174335+1100"?>-<?oxy_insert_end?>normal
          approximation obtained in Step 2.</para>
      </listitem>

      <listitem>
        <para>Calculate particle probability weights according to
        <inlineequation>
            <m:math display="inline">
              <m:mrow>
                <m:mi>P(</m:mi>

                <m:msub>
                  <m:mi>θ)</m:mi>

                  <m:mi>i</m:mi>
                </m:msub>
              </m:mrow>

              <m:mo>=</m:mo>

              <m:mfrac>
                <m:mrow>
                  <m:msub>
                    <m:mi>p(θ</m:mi>

                    <m:mi>i</m:mi>
                  </m:msub>

                  <m:mrow>
                    <m:mi>|</m:mi>

                    <m:mo>D)</m:mo>
                  </m:mrow>
                </m:mrow>

                <m:mrow>
                  <m:msub>
                    <m:mi>p</m:mi>

                    <m:mi>N</m:mi>
                  </m:msub>

                  <m:mrow>
                    <m:msub>
                      <m:mi>(θ</m:mi>

                      <m:mi>i</m:mi>
                    </m:msub>

                    <m:mo>)</m:mo>
                  </m:mrow>
                </m:mrow>
              </m:mfrac>
            </m:math>
          </inlineequation>,i=1,...,N</para>
      </listitem>

      <listitem>
        <para>Scale the particle weights so they sum to 1.</para>
      </listitem>
    </orderedlist>
  </section>

  <section xml:id="b3_ch2_s_l6g7s">
    <title>Box 6: LH moments for fitting the GEV distribution</title>

    <para>LH moments are based on linear combinations of higher
    order-statistics. A shift parameter <inlineequation>
        <m:math display="inline">
          <m:mi>η = 0,1,2,3...</m:mi>
        </m:math>
      </inlineequation> is introduced to give more emphasis on higher ranked
    flows. LH moments are defined as:</para>

    <equation xml:id="b3_ch2_e_9ipt3">
      <m:math display="block">
        <m:mrow>
          <m:msubsup>
            <m:mi>λ</m:mi>

            <m:mi>1</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mi>E[</m:mi>

            <m:mrow>
              <m:msub>
                <m:mi>X</m:mi>

                <m:mi>(η+1):(η+1)</m:mi>
              </m:msub>

              <m:mo>]</m:mo>
            </m:mrow>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <equation xml:id="b3_ch2_e_cpzjs">
      <m:math display="block">
        <m:mrow>
          <m:msubsup>
            <m:mi>λ</m:mi>

            <m:mi>2</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>

          <m:mo>=</m:mo>

          <m:mfrac>
            <m:mi>1</m:mi>

            <m:mi>2</m:mi>
          </m:mfrac>

          <m:mo>E</m:mo>

          <m:mrow>
            <m:mo>[</m:mo>

            <m:mrow>
              <m:msub>
                <m:mi>X</m:mi>

                <m:mi>(η+2):(η+2)</m:mi>
              </m:msub>

              <m:mo>-</m:mo>

              <m:msub>
                <m:mi>X</m:mi>

                <m:mi>(η+1):(η+3)</m:mi>
              </m:msub>
            </m:mrow>

            <m:mo>]</m:mo>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <equation xml:id="b3_ch2_e_vei75">
      <m:math display="block">
        <m:mrow>
          <m:msubsup>
            <m:mi>λ</m:mi>

            <m:mi>3</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mfrac>
              <m:mi>1</m:mi>

              <m:mi>3</m:mi>
            </m:mfrac>

            <m:mo>E</m:mo>

            <m:mrow>
              <m:mo>[</m:mo>

              <m:mrow>
                <m:msub>
                  <m:mi>X</m:mi>

                  <m:mi>(η+3):(η+3)</m:mi>
                </m:msub>

                <m:mo>-</m:mo>

                <m:mrow>
                  <m:msub>
                    <m:mi>2X</m:mi>

                    <m:mi>(η+2):(η+3)</m:mi>
                  </m:msub>

                  <m:mo>+</m:mo>

                  <m:msub>
                    <m:mi>X</m:mi>

                    <m:mi>(η+1):(η+3)</m:mi>
                  </m:msub>
                </m:mrow>
              </m:mrow>

              <m:mo>]</m:mo>
            </m:mrow>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <equation xml:id="b3_ch2_e_of6gn">
      <m:math display="block">
        <m:mrow>
          <m:msubsup>
            <m:mi>λ</m:mi>

            <m:mi>4</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mfrac>
              <m:mi>1</m:mi>

              <m:mi>4</m:mi>
            </m:mfrac>

            <m:mo>E</m:mo>

            <m:mrow>
              <m:mo>[</m:mo>

              <m:mrow>
                <m:msub>
                  <m:mi>X</m:mi>

                  <m:mi>(η+4):(η+4)</m:mi>
                </m:msub>

                <m:mo>-</m:mo>

                <m:mrow>
                  <m:msub>
                    <m:mi>3X</m:mi>

                    <m:mi>(η+3):(η+4)</m:mi>
                  </m:msub>

                  <m:mo>+</m:mo>

                  <m:mrow>
                    <m:msub>
                      <m:mi>3X</m:mi>

                      <m:mi>(η+2):(η+4)</m:mi>
                    </m:msub>

                    <m:mo>-</m:mo>

                    <m:msub>
                      <m:mi>X</m:mi>

                      <m:mi>(η+1):(η+4)</m:mi>
                    </m:msub>
                  </m:mrow>
                </m:mrow>
              </m:mrow>

              <m:mo>]</m:mo>
            </m:mrow>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para><xref linkend="b3_ch2_t_g48se"/> presents the relationship between
    the first four LH moments and the parameters of the GEV and Gumbel
    distributions.</para>

    <table xml:id="b3_ch2_t_g48se">
      <title>LH moments for GEV and Gumbel distributions (from Wang,
      1997)</title>

      <tgroup cols="2">
        <colspec align="center" colwidth="5*"/>

        <colspec colwidth="95*"/>

        <thead>
          <row>
            <entry align="center">Family</entry>

            <entry align="center">LH Moments</entry>
          </row>
        </thead>

        <tbody>
          <row>
            <entry>Generalized Extreme Value (GEV)</entry>

            <entry><inlineequation>
                <m:math display="inline">
                  <m:mtable>
                    <m:mtr>
                      <m:mtd>
                        <m:mrow>
                          <m:msubsup>
                            <m:mi>λ</m:mi>

                            <m:mi>1</m:mi>

                            <m:mi>η</m:mi>
                          </m:msubsup>

                          <m:mo>=</m:mo>

                          <m:mrow>
                            <m:mi>τ +</m:mi>

                            <m:mfrac>
                              <m:mi>α</m:mi>

                              <m:mi>κ</m:mi>
                            </m:mfrac>

                            <m:mi>[1-Γ(1+κ)(η+1</m:mi>

                            <m:msup>
                              <m:mi>)</m:mi>

                              <m:mi>-κ</m:mi>
                            </m:msup>

                            <m:mi>]</m:mi>

                            <m:mrow>
                              <m:mrow>
                                <m:msubsup>
                                  <m:mi>λ</m:mi>

                                  <m:mi>2</m:mi>

                                  <m:mi>η</m:mi>
                                </m:msubsup>

                                <m:mo>=</m:mo>

                                <m:mfrac>
                                  <m:mi>(η+2)αΓ(1+κ)</m:mi>

                                  <m:mi>2!κ</m:mi>
                                </m:mfrac>
                              </m:mrow>

                              <m:mo>[- (η+2</m:mo>

                              <m:msup>
                                <m:mi>)</m:mi>

                                <m:mi>-κ</m:mi>
                              </m:msup>

                              <m:mo>+(η +</m:mo>

                              <m:msup>
                                <m:mi>1 )</m:mi>

                                <m:mi>-κ</m:mi>
                              </m:msup>
                            </m:mrow>
                          </m:mrow>
                        </m:mrow>
                      </m:mtd>
                    </m:mtr>

                    <m:mtr>
                      <m:mtd>
                        <m:mrow>
                          <m:msubsup>
                            <m:mi>λ</m:mi>

                            <m:mi>3</m:mi>

                            <m:mi>η</m:mi>
                          </m:msubsup>

                          <m:mo>=</m:mo>

                          <m:mrow>
                            <m:mfrac>
                              <m:mi>(η+3)αΓ(1+κ)</m:mi>

                              <m:mi>3!κ</m:mi>
                            </m:mfrac>

                            <m:mo>[ - (η+4)(η+</m:mo>

                            <m:msup>
                              <m:mi>3)</m:mi>

                              <m:mi>-κ</m:mi>
                            </m:msup>

                            <m:mo>+2(η+3)(η+2</m:mo>

                            <m:msup>
                              <m:mi>)</m:mi>

                              <m:mi>-κ</m:mi>
                            </m:msup>

                            <m:mo>- (</m:mo>

                            <m:mrow>
                              <m:mi>η+2)(η+1</m:mi>

                              <m:msup>
                                <m:mi>)</m:mi>

                                <m:mi>-κ</m:mi>
                              </m:msup>

                              <m:mi>]</m:mi>
                            </m:mrow>
                          </m:mrow>
                        </m:mrow>
                      </m:mtd>
                    </m:mtr>

                    <m:mtr>
                      <m:mtd>
                        <m:mrow>
                          <m:mtable>
                            <m:mtr>
                              <m:mtd>
                                <m:mrow>
                                  <m:msubsup>
                                    <m:mi>λ</m:mi>

                                    <m:mi>4</m:mi>

                                    <m:mi>η</m:mi>
                                  </m:msubsup>

                                  <m:mo>=</m:mo>

                                  <m:mrow>
                                    <m:mfrac>
                                      <m:mi>(η+4)αΓ(1+κ)</m:mi>

                                      <m:mi>4!κ</m:mi>
                                    </m:mfrac>

                                    <m:mo>[ -(η+6)(η+5)(η+4</m:mo>

                                    <m:msup>
                                      <m:mi>)</m:mi>

                                      <m:mi>-κ</m:mi>
                                    </m:msup>

                                    <m:mo>+3(η+5)(η+4)(η+3</m:mo>

                                    <m:msup>
                                      <m:mi>)</m:mi>

                                      <m:mi>-κ</m:mi>
                                    </m:msup>

                                    <m:mo>]</m:mo>
                                  </m:mrow>
                                </m:mrow>
                              </m:mtd>
                            </m:mtr>

                            <m:mtr>
                              <m:mtd>
                                <m:mrow>
                                  <m:mtable>
                                    <m:mtr>
                                      <m:mtd>
                                        <m:mrow>
                                          <m:mi>-3(η+4)(η+3)(η+2</m:mi>

                                          <m:mrow>
                                            <m:msup>
                                              <m:mi>)</m:mi>

                                              <m:mi>-κ</m:mi>
                                            </m:msup>

                                            <m:mo>+ (η+3)(η+2)(η+1</m:mo>

                                            <m:msup>
                                              <m:mi>)</m:mi>

                                              <m:mi>-κ</m:mi>
                                            </m:msup>
                                          </m:mrow>
                                        </m:mrow>
                                      </m:mtd>
                                    </m:mtr>

                                    <m:mtr>
                                      <m:mtd>
                                        <m:mrow>
                                          <m:mi>where κ≠</m:mi>

                                          <m:mo>0</m:mo>
                                        </m:mrow>
                                      </m:mtd>
                                    </m:mtr>
                                  </m:mtable>
                                </m:mrow>
                              </m:mtd>
                            </m:mtr>
                          </m:mtable>
                        </m:mrow>
                      </m:mtd>
                    </m:mtr>
                  </m:mtable>
                </m:math>
              </inlineequation></entry>
          </row>

          <row>
            <entry>Gumbel</entry>

            <entry><inlineequation>
                <m:math display="inline">
                  <m:mtable>
                    <m:mtr>
                      <m:mtd>
                        <m:mrow>
                          <m:msubsup>
                            <m:mi>λ</m:mi>

                            <m:mi>1</m:mi>

                            <m:mi>η</m:mi>
                          </m:msubsup>

                          <m:mo>=</m:mo>

                          <m:mrow>
                            <m:mi>τ+α[0.5772+ln(η+1]</m:mi>

                            <m:msubsup>
                              <m:mi>λ</m:mi>

                              <m:mi>2</m:mi>

                              <m:mi>η</m:mi>
                            </m:msubsup>

                            <m:mi>=</m:mi>

                            <m:mfrac>
                              <m:mi>(η+2)α</m:mi>

                              <m:mi>2!</m:mi>
                            </m:mfrac>

                            <m:mi>[ln(η+2) - ln (η+1)</m:mi>
                          </m:mrow>
                        </m:mrow>
                      </m:mtd>
                    </m:mtr>

                    <m:mtr>
                      <m:mtd>
                        <m:mrow>
                          <m:msubsup>
                            <m:mi>λ</m:mi>

                            <m:mi>3</m:mi>

                            <m:mi>η</m:mi>
                          </m:msubsup>

                          <m:mo>=</m:mo>

                          <m:mrow>
                            <m:mfrac>
                              <m:mi>(η+3)α</m:mi>

                              <m:mi>3!</m:mi>
                            </m:mfrac>

                            <m:mo>[
                            (η+4)ln(η+3)-2(η+3)ln(η+2)+(η+2)ln(η+1)]</m:mo>
                          </m:mrow>
                        </m:mrow>
                      </m:mtd>
                    </m:mtr>

                    <m:mtr>
                      <m:mtd>
                        <m:mrow>
                          <m:mtable>
                            <m:mtr>
                              <m:mtd>
                                <m:mrow>
                                  <m:msubsup>
                                    <m:mi>λ</m:mi>

                                    <m:mi>4</m:mi>

                                    <m:mi>η</m:mi>
                                  </m:msubsup>

                                  <m:mo>=</m:mo>

                                  <m:mrow>
                                    <m:mfrac>
                                      <m:mi>(η+4)α</m:mi>

                                      <m:mi>4!</m:mi>
                                    </m:mfrac>

                                    <m:mo>[(η+6)(η+5)ln(η+4)-3(η+5)(η+4)ln(η+3)</m:mo>
                                  </m:mrow>
                                </m:mrow>
                              </m:mtd>
                            </m:mtr>

                            <m:mtr>
                              <m:mtd>
                                <m:mrow>
                                  <m:mi>+3(η+4)(η+3)ln(η+2)-(η+3)(η+2)ln(η+1)]</m:mi>
                                </m:mrow>
                              </m:mtd>
                            </m:mtr>
                          </m:mtable>
                        </m:mrow>
                      </m:mtd>
                    </m:mtr>
                  </m:mtable>
                </m:math>
              </inlineequation></entry>
          </row>
        </tbody>
      </tgroup>
    </table>

    <para>For ease of computation Wang (1997) derived the following
    approximation for the shape parameter <inlineequation>
        <m:math display="inline">
          <m:mi>κ</m:mi>
        </m:math>
      </inlineequation>:</para>

    <para><equation xml:id="b3_ch2_e_ieds7">
        <m:math display="inline">
          <m:mi>κ</m:mi>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:msub>
              <m:mi>a</m:mi>

              <m:mi>0</m:mi>
            </m:msub>

            <m:mo>+</m:mo>

            <m:mrow>
              <m:mrow>
                <m:msub>
                  <m:mi>a</m:mi>

                  <m:mi>1</m:mi>
                </m:msub>

                <m:msubsup>
                  <m:mi>[τ</m:mi>

                  <m:mi>3</m:mi>

                  <m:mi>η</m:mi>
                </m:msubsup>
              </m:mrow>

              <m:mo>]+</m:mo>

              <m:mrow>
                <m:mrow>
                  <m:msub>
                    <m:mi>a</m:mi>

                    <m:mi>2</m:mi>
                  </m:msub>

                  <m:msubsup>
                    <m:mi>[τ</m:mi>

                    <m:mi>3</m:mi>

                    <m:mi>η-2</m:mi>
                  </m:msubsup>
                </m:mrow>

                <m:mo>]+</m:mo>

                <m:mrow>
                  <m:msub>
                    <m:mi>a</m:mi>

                    <m:mi>3</m:mi>
                  </m:msub>

                  <m:mrow>
                    <m:msubsup>
                      <m:mi>[τ</m:mi>

                      <m:mi>3</m:mi>

                      <m:mi>η-3</m:mi>
                    </m:msubsup>

                    <m:msup>
                      <m:mi>]</m:mi>

                      <m:mi/>
                    </m:msup>
                  </m:mrow>
                </m:mrow>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation></para>

    <para>where the polynomial coefficients vary with η according to <xref
    linkend="b3_ch2_t_idxtt"/>.</para>

    <table xml:id="b3_ch2_t_idxtt">
      <title>Polynomial coefficients for use with <xref
      linkend="b3_ch2_e_ieds7"/></title>

      <tgroup cols="5">
        <colspec align="center"/>

        <thead>
          <row>
            <entry align="center">η</entry>

            <entry align="center">a<subscript>0</subscript></entry>

            <entry align="center">a<subscript>1</subscript></entry>

            <entry align="center">a<subscript>2</subscript></entry>

            <entry align="center">a<subscript>3</subscript></entry>
          </row>
        </thead>

        <tbody>
          <row>
            <entry>0</entry>

            <entry>0.2849</entry>

            <entry>-1.8213</entry>

            <entry>0.8140</entry>

            <entry>-0.2835</entry>
          </row>

          <row>
            <entry>1</entry>

            <entry>0.4823</entry>

            <entry>-2.1494</entry>

            <entry>0.7269</entry>

            <entry>-0.2103</entry>
          </row>

          <row>
            <entry>2</entry>

            <entry>0.5914</entry>

            <entry>-2.3351</entry>

            <entry>0.6442</entry>

            <entry>-0.1616</entry>
          </row>

          <row>
            <entry>3</entry>

            <entry>0.6618</entry>

            <entry>-2.4548</entry>

            <entry>0.5733</entry>

            <entry>-0.1273</entry>
          </row>

          <row>
            <entry>4</entry>

            <entry>0.7113</entry>

            <entry>-2.5383</entry>

            <entry>0.5142</entry>

            <entry>-0.1027</entry>
          </row>
        </tbody>
      </tgroup>
    </table>

    <para>Wang (1997) derived the following estimators for LH moments with
    shift parameter <inlineequation>
        <m:math display="inline">
          <m:mi>η</m:mi>
        </m:math>
      </inlineequation>:</para>

    <equation xml:id="b3_ch2_e_q4032">
      <m:math display="block">
        <m:mrow>
          <m:msubsup>
            <m:mi>λ</m:mi>

            <m:mi>1</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mfrac>
              <m:mi>1</m:mi>

              <m:msubsup>
                <m:mi>C</m:mi>

                <m:mi>η+1</m:mi>

                <m:mi>n</m:mi>
              </m:msubsup>
            </m:mfrac>

            <m:mrow>
              <m:munderover>
                <m:mo>∑</m:mo>

                <m:mi>i=1</m:mi>

                <m:mi>n</m:mi>
              </m:munderover>

              <m:msubsup>
                <m:mi>C</m:mi>

                <m:mi>η</m:mi>

                <m:mi>j-1</m:mi>
              </m:msubsup>
            </m:mrow>

            <m:msub>
              <m:mi>x</m:mi>

              <m:mi>(i)</m:mi>
            </m:msub>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <equation xml:id="b3_ch2_e_uowzw">
      <m:math display="block">
        <m:mrow>
          <m:msubsup>
            <m:mi>λ</m:mi>

            <m:mi>2</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mfrac>
              <m:mi>1</m:mi>

              <m:mi>2</m:mi>
            </m:mfrac>

            <m:mfrac>
              <m:mi>1</m:mi>

              <m:msubsup>
                <m:mi>C</m:mi>

                <m:mi>η+2</m:mi>

                <m:mi>n</m:mi>
              </m:msubsup>
            </m:mfrac>

            <m:mrow>
              <m:munderover>
                <m:mo>∑</m:mo>

                <m:mi>i=1</m:mi>

                <m:mi>n</m:mi>
              </m:munderover>

              <m:mrow>
                <m:mo>(</m:mo>

                <m:mrow>
                  <m:msubsup>
                    <m:mi>C</m:mi>

                    <m:mi>η+1</m:mi>

                    <m:mi>i-1</m:mi>
                  </m:msubsup>

                  <m:mo>-</m:mo>

                  <m:mrow>
                    <m:msubsup>
                      <m:mi>C</m:mi>

                      <m:mi>η</m:mi>

                      <m:mi>i-1</m:mi>
                    </m:msubsup>

                    <m:msubsup>
                      <m:mi>C</m:mi>

                      <m:mi>1</m:mi>

                      <m:mi>n-i</m:mi>
                    </m:msubsup>
                  </m:mrow>
                </m:mrow>

                <m:mo>)</m:mo>
              </m:mrow>
            </m:mrow>

            <m:msub>
              <m:mi>q</m:mi>

              <m:mi>(i)</m:mi>
            </m:msub>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <equation xml:id="b3_ch2_e_3pbp1">
      <m:math display="block">
        <m:mrow>
          <m:msubsup>
            <m:mi>λ</m:mi>

            <m:mi>3</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mfrac>
              <m:mi>1</m:mi>

              <m:mi>3</m:mi>
            </m:mfrac>

            <m:mfrac>
              <m:mi>1</m:mi>

              <m:msubsup>
                <m:mi>C</m:mi>

                <m:mi>η+3</m:mi>

                <m:mi>n</m:mi>
              </m:msubsup>
            </m:mfrac>

            <m:mrow>
              <m:munderover>
                <m:mo>∑</m:mo>

                <m:mi>i=1</m:mi>

                <m:mi>n</m:mi>
              </m:munderover>

              <m:mrow>
                <m:mo>(</m:mo>

                <m:mrow>
                  <m:msubsup>
                    <m:mi>C</m:mi>

                    <m:mi>η+2</m:mi>

                    <m:mi>i-1</m:mi>
                  </m:msubsup>

                  <m:mo>-2</m:mo>

                  <m:mrow>
                    <m:mrow>
                      <m:msubsup>
                        <m:mi>C</m:mi>

                        <m:mi>η+1</m:mi>

                        <m:mi>i-1</m:mi>
                      </m:msubsup>

                      <m:msubsup>
                        <m:mi>C</m:mi>

                        <m:mi>1</m:mi>

                        <m:mi>n-i</m:mi>
                      </m:msubsup>
                    </m:mrow>

                    <m:mo>+</m:mo>

                    <m:mrow>
                      <m:msubsup>
                        <m:mi>C</m:mi>

                        <m:mi>η</m:mi>

                        <m:mi>i-1</m:mi>
                      </m:msubsup>

                      <m:msubsup>
                        <m:mi>C</m:mi>

                        <m:mi>2</m:mi>

                        <m:mi>n-i</m:mi>
                      </m:msubsup>
                    </m:mrow>
                  </m:mrow>
                </m:mrow>

                <m:mo>)</m:mo>
              </m:mrow>
            </m:mrow>

            <m:msub>
              <m:mi>q</m:mi>

              <m:mi>(i)</m:mi>
            </m:msub>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <equation xml:id="b3_ch2_e_cu4cg">
      <m:math display="block">
        <m:mrow>
          <m:msubsup>
            <m:mi>λ</m:mi>

            <m:mi>4</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mfrac>
              <m:mi>1</m:mi>

              <m:mi>4</m:mi>
            </m:mfrac>

            <m:mfrac>
              <m:mi>1</m:mi>

              <m:msubsup>
                <m:mi>C</m:mi>

                <m:mi>η+4</m:mi>

                <m:mi>n</m:mi>
              </m:msubsup>
            </m:mfrac>

            <m:mrow>
              <m:munderover>
                <m:mo>∑</m:mo>

                <m:mi>i=1</m:mi>

                <m:mi>n</m:mi>
              </m:munderover>

              <m:mrow>
                <m:mo>(</m:mo>

                <m:mrow>
                  <m:msubsup>
                    <m:mi>C</m:mi>

                    <m:mi>η+3</m:mi>

                    <m:mi>i-1</m:mi>
                  </m:msubsup>

                  <m:mo>-</m:mo>

                  <m:mrow>
                    <m:mrow>
                      <m:msubsup>
                        <m:mi>3C</m:mi>

                        <m:mi>η+2</m:mi>

                        <m:mi>i-1</m:mi>
                      </m:msubsup>

                      <m:msubsup>
                        <m:mi>C</m:mi>

                        <m:mi>1</m:mi>

                        <m:mi>n-i</m:mi>
                      </m:msubsup>
                    </m:mrow>

                    <m:mo>+</m:mo>

                    <m:mrow>
                      <m:mrow>
                        <m:msubsup>
                          <m:mi>3C</m:mi>

                          <m:mi>η+1</m:mi>

                          <m:mi>i-1</m:mi>
                        </m:msubsup>

                        <m:msubsup>
                          <m:mi>C</m:mi>

                          <m:mi>2</m:mi>

                          <m:mi>n-i</m:mi>
                        </m:msubsup>
                      </m:mrow>

                      <m:mo>-</m:mo>

                      <m:mrow>
                        <m:msubsup>
                          <m:mi>C</m:mi>

                          <m:mi>η</m:mi>

                          <m:mi>i-1</m:mi>
                        </m:msubsup>

                        <m:msubsup>
                          <m:mi>C</m:mi>

                          <m:mi>3</m:mi>

                          <m:mi>n-i</m:mi>
                        </m:msubsup>
                      </m:mrow>
                    </m:mrow>
                  </m:mrow>
                </m:mrow>

                <m:mo>)</m:mo>
              </m:mrow>
            </m:mrow>

            <m:msub>
              <m:mi>q</m:mi>

              <m:mi>(i)</m:mi>
            </m:msub>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>The selection of the best shift parameter requires some form of
    goodness-of-fit test. Wang (1998) argued that the first three LH moments
    are used to fit the GEV model leaving the fourth LH moment available for
    testing the adequacy of the fit. Wang proposed the following approximate
    test statistic:</para>

    <equation xml:id="b3_ch2_e_otv9s">
      <m:math display="block">
        <m:mrow>
          <m:mi>z</m:mi>

          <m:mo>=</m:mo>

          <m:mfrac>
            <m:mrow>
              <m:msubsup>
                <m:mi>τ</m:mi>

                <m:mi>4</m:mi>

                <m:mi>η</m:mi>
              </m:msubsup>

              <m:mo>-</m:mo>

              <m:msubsup>
                <m:mi>τ</m:mi>

                <m:mi>4</m:mi>

                <m:mi>η</m:mi>
              </m:msubsup>
            </m:mrow>

            <m:mrow>
              <m:mi>σ</m:mi>

              <m:mrow>
                <m:mo>(</m:mo>

                <m:mrow>
                  <m:mrow>
                    <m:msubsup>
                      <m:mi>τ</m:mi>

                      <m:mi>4</m:mi>

                      <m:mi>η</m:mi>
                    </m:msubsup>

                    <m:msubsup>
                      <m:mi>|τ</m:mi>

                      <m:mi>3</m:mi>

                      <m:mi>η</m:mi>
                    </m:msubsup>
                  </m:mrow>

                  <m:mo>=</m:mo>

                  <m:msubsup>
                    <m:mi>τ</m:mi>

                    <m:mi>3</m:mi>

                    <m:mi>η</m:mi>
                  </m:msubsup>
                </m:mrow>

                <m:mo>)</m:mo>
              </m:mrow>
            </m:mrow>
          </m:mfrac>
        </m:mrow>
      </m:math>
    </equation>

    <para>where <inlineequation>
        <m:math display="inline">
          <m:msubsup>
            <m:mi>τ</m:mi>

            <m:mi>4</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>
        </m:math>
      </inlineequation> is the sample estimate of the LH-kurtosis,
    <inlineequation>
        <m:math display="inline">
          <m:msubsup>
            <m:mi>τ</m:mi>

            <m:mi>4</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>
        </m:math>
      </inlineequation> is the LH-kurtosis derived from the GEV parameters
    fitted to the first three LH moments, and <inlineequation>
        <m:math display="inline">
          <m:mrow>
            <m:mi>σ</m:mi>

            <m:mo>(</m:mo>

            <m:msubsup>
              <m:mi>τ</m:mi>

              <m:mi>4</m:mi>

              <m:mi>η</m:mi>
            </m:msubsup>

            <m:msubsup>
              <m:mi>|τ</m:mi>

              <m:mi>3</m:mi>

              <m:mi>η</m:mi>
            </m:msubsup>

            <m:mi>=</m:mi>

            <m:msubsup>
              <m:mi>τ</m:mi>

              <m:mi>3</m:mi>

              <m:mi>η</m:mi>
            </m:msubsup>

            <m:mi>)</m:mi>
          </m:mrow>
        </m:math>
      </inlineequation> is the standard deviation of <inlineequation>
        <m:math display="inline">
          <m:msubsup>
            <m:mi>τ</m:mi>

            <m:mi>4</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>
        </m:math>
      </inlineequation> assuming the sample LH-skewness equals the LH-skewness
    derived from the GEV parameters fitted to the first three LH moments.
    Under the hypothesis that the underlying distribution is GEV, the test
    statistic z is approximately normal distributed with mean 0 and variance
    1. Wang (1998) describes a simple relationship to estimate <inlineequation>
        <m:math display="inline">
          <m:mrow>
            <m:mi>σ</m:mi>

            <m:msubsup>
              <m:mi>(τ</m:mi>

              <m:mi>4</m:mi>

              <m:mi>η</m:mi>
            </m:msubsup>

            <m:mi>|</m:mi>

            <m:msubsup>
              <m:mi>τ</m:mi>

              <m:mi>3</m:mi>

              <m:mi>η</m:mi>
            </m:msubsup>

            <m:mi>=</m:mi>

            <m:msubsup>
              <m:mi>τ</m:mi>

              <m:mi>3</m:mi>

              <m:mi>η</m:mi>
            </m:msubsup>

            <m:mi>)</m:mi>
          </m:mrow>
        </m:math>
      </inlineequation> .</para>
  </section>

  <section xml:id="b3_ch2_s_wltta">
    <title>Box 7: Parametric bootstrap</title>

    <para>The sampling distribution of an estimator can be approximated using
    the Monte Carlo method known as the parametric bootstrap:</para>

    <orderedlist>
      <listitem>
        <para>Fit the probability model to n years of gauged discharges using
        L or LH moments to yield the parameter estimate <inlineequation>
            <m:math display="inline">
              <m:mi>θ</m:mi>
            </m:math>
          </inlineequation>.</para>
      </listitem>

      <listitem>
        <para>Set i=1</para>
      </listitem>

      <listitem>
        <para>Randomly sample n flows from the fitted distribution; that is,
        q<subscript>ji</subscript> ← p(q|<inlineequation>
            <m:math display="inline">
              <m:mi>θ</m:mi>
            </m:math>
          </inlineequation>),j=1,...,n</para>
      </listitem>

      <listitem>
        <para>Fit the model to the sampled flows
        {q<subscript>ji</subscript>,j=1,..,n}using L or LH moments to yield
        the parameter estimate θ<subscript>i</subscript></para>
      </listitem>

      <listitem>
        <para>Increment i. Go to step 3 if i does not exceed N.</para>
      </listitem>
    </orderedlist>

    <para>This procedure yields N equi-weighted samples that approximate the
    sampling distribution p(<inlineequation>
        <m:math display="inline">
          <m:mi>θ</m:mi>
        </m:math>
      </inlineequation>|D). As a result, they can be used to quantify
    parameter uncertainty and estimate quantile confidence limits. However,
    because the parametric bootstrap assumes <inlineequation>
        <m:math display="inline">
          <m:mi>θ</m:mi>
        </m:math>
      </inlineequation> is the true parameter, it underestimates the
    uncertainty and therefore should not be used to estimate expected
    probabilities.</para>
  </section>

  <section xml:id="b3_ch2_s_lg0c6">
    <title>Example 1: Extrapolation and Process Understanding</title>

    <para>The importance of process understanding when extrapolating beyond
    the observed record is illustrated by a simple Monte Carlo experiment. A
    Poisson rectangular pulse rainfall model is used to generate a long record
    of high resolution rainfall. This is routed through a rainfall-runoff
    model to generate runoff into the stream system. The storage-discharge
    relationship for the stream is depicted by the bilinear relationship shown
    in <xref linkend="b3_ch2_f_hpsm2"/>. A feature of this relationship is the
    activation of significant flood terrace storage once a threshold discharge
    is exceeded.</para>

    <figure xml:id="b3_ch2_f_hpsm2">
      <title>Bilinear channel storage-discharge relationship</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3010.jpg"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>The routing model parameters were selected so that major flood
    terrace storage is activated by floods of less than 1% AEP. This situation
    was chosen to represent a river with multiple flood terraces with the
    lowest terraces accommodating the majority of floods and the highest
    terrace only inundated by extreme floods.</para>

    <para><xref linkend="b3_ch2_f_owuiv"/> presents the flood frequency curve
    based on 30000 simulated years – it shows a clear break in slope around
    the 1% AEP corresponding to the activation of major flood terrace storage.
    Indeed the flood frequency curve displays downward curvature despite that
    the fact the rainfall frequency curve displays upward curvature in the 1%
    to 0.1% (1 in 1000) AEP range. In contrast the flood frequency curve based
    on 100 years of “data” shows no evidence of downward curvature. This is
    because in a 100-year record there is little chance of the major flood
    terrace storage being activated. Indeed without knowledge of the
    underlying hydraulics one would be tempted to extrapolate the 100-year
    flood record using a straight line extrapolation. Such an extrapolation
    would rapidly diverge from the “true” frequency curve.</para>

    <figure xml:id="b3_ch2_f_owuiv">
      <title>Simulated rainfall and flood frequency curves with major
      floodplain storage activated at a threshold discharge of 3500
      m<superscript>3</superscript>/s</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3011.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>Although the example idealises the dominant rainfall-runoff dynamics
    it delivers a very strong message. Extrapolation of flood frequency curves
    fitted to gauged discharges records requires the exercise of hydrologic
    judgment backed up by appropriate modelling. The problem of extrapolation
    is much more general. For example, in this example, if a rainfall-runoff
    approach were used with the rainfall-runoff model calibrated to small
    events the simulated flood frequency curve is likely to be compromised in
    a similar way.</para>
  </section>

  <section xml:id="b3_ch2_s_cli4f">
    <title>Example 2: Accuracy of Daily Gauged Discharges</title>

    <para>The use of daily discharge readings in Flood Frequency Analysis is
    most problematic for smaller catchments, which can be “flashy” in the
    sense that the hydrograph can rise and subside within a twenty four hour
    period. This effect can be quite significant, even for reasonably large
    catchments.</para>

    <para><xref linkend="b3_ch2_f_097da"/> and <xref
    linkend="b3_ch2_f_mvr25"/>, taken from Micevski <emphasis>et
    al</emphasis>. (2003), compare instantaneous annual maximum discharge
    against the discharge recorded at 9am on the same day for two gauging
    stations in the Hunter Valley: Goulburn River at Coggan with area 3340
    km<superscript>2</superscript> and Hunter River at Singleton with area
    16400 km<superscript>2</superscript>. The dashed line represents equality.
    <xref linkend="b3_ch2_f_097da"/> demonstrates that the true peak flow can
    be up to 10 times the 9am flow. In contrast the estimation error is much
    smaller for the larger catchment shown in <xref
    linkend="b3_ch2_f_mvr25"/>.</para>

    <figure xml:id="b3_ch2_f_097da">
      <title>Comparison between true peak flow and 9 am flow for Goulburn
      River at Coggan</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3012.PNG"/>
        </imageobject>
      </mediaobject>
    </figure>

    <figure xml:id="b3_ch2_f_mvr25">
      <title>Comparison between true peak flow and 9 am flow for Hunter River
      at Singleton</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3013.PNG"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>The example demonstrates the need to check the representativeness of
    daily readings by comparing instantaneous peak flows against daily
    readings.</para>
  </section>

  <section xml:id="b3_ch2_s_fn122">
    <title>Example 3: Fitting a probability model to gauged data</title>

    <para>This example illustrates fitting a probability model to gauged
    Annual Maximum (AM) flood data. The following table lists 31 years of
    gauged Annual Maximum discharges (AM) (m<superscript>3</superscript>/s)
    for the Hunter River at Singleton:</para>

    <informaltable>
      <tgroup cols="4">
        <colspec/>

        <colspec/>

        <colspec align="center"/>

        <tbody>
          <row>
            <entry>Year</entry>

            <entry>AM discharge (m³/s)</entry>

            <entry>Year</entry>

            <entry>AM discharge (m³/s)</entry>
          </row>

          <row>
            <entry>1938</entry>

            <entry>76.26</entry>

            <entry>1954</entry>

            <entry>1391.43</entry>
          </row>

          <row>
            <entry>1939</entry>

            <entry>171.87</entry>

            <entry>1955</entry>

            <entry>12525.66</entry>
          </row>

          <row>
            <entry>1940</entry>

            <entry>218.21</entry>

            <entry>1956</entry>

            <entry>1099.54</entry>
          </row>

          <row>
            <entry>1941</entry>

            <entry>668.79</entry>

            <entry>1957</entry>

            <entry>447.75</entry>
          </row>

          <row>
            <entry>1942</entry>

            <entry>1374.42</entry>

            <entry>1958</entry>

            <entry>478.92</entry>
          </row>

          <row>
            <entry>1943</entry>

            <entry>124.12</entry>

            <entry>1959</entry>

            <entry>180.52</entry>
          </row>

          <row>
            <entry>1944</entry>

            <entry>276.3</entry>

            <entry>1960</entry>

            <entry>164.36</entry>
          </row>

          <row>
            <entry>1945</entry>

            <entry>895.5</entry>

            <entry>1961</entry>

            <entry>229.54</entry>
          </row>

          <row>
            <entry>1946</entry>

            <entry>1374.42</entry>

            <entry>1962</entry>

            <entry>2125.4</entry>
          </row>

          <row>
            <entry>1947</entry>

            <entry>280.18</entry>

            <entry>1963</entry>

            <entry>966.35</entry>
          </row>

          <row>
            <entry>1948</entry>

            <entry>202.62</entry>

            <entry>1964</entry>

            <entry>2751.68</entry>
          </row>

          <row>
            <entry>1949</entry>

            <entry>4052.42</entry>

            <entry>1965</entry>

            <entry>49.03</entry>
          </row>

          <row>
            <entry>1950</entry>

            <entry>2323.77</entry>

            <entry>1966</entry>

            <entry>79.51</entry>
          </row>

          <row>
            <entry>1951</entry>

            <entry>2536.31</entry>

            <entry>1967</entry>

            <entry>912.5</entry>
          </row>

          <row>
            <entry>1952</entry>

            <entry>3315.62</entry>

            <entry>1968</entry>

            <entry>926.67</entry>
          </row>

          <row>
            <entry>1953</entry>

            <entry>1232.73</entry>
          </row>
        </tbody>
      </tgroup>
    </informaltable>

    <para>The data was imported into FLIKE using the “import” control in the
    following dialog:</para>

    <figure xml:id="b3_ch2_f_0cep8">
      <title>Data Import using FLIKE - Hunter River at Singleton</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3014.PNG"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>The Log Pearson III distribution was selected to be fitted using the
    Bayesian inference method in the following dialog:</para>

    <figure xml:id="b3_ch2_f_s2mjy">
      <title>Selection of Analysis Option in FLIKE</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3015.PNG"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>The following table presents the posterior mean, standard deviation
    and correlation for the LPIII parameters: m, s and g which are
    respectively the mean, standard deviation and skewness of
    log<subscript>e</subscript> q:</para>

    <informaltable>
      <tgroup cols="6">
        <colspec align="center"/>

        <colspec colname="_4" colnum="4"/>

        <colspec colname="_5"/>

        <colspec colname="_6"/>

        <tbody>
          <row>
            <entry>LPIII parameter</entry>

            <entry>Mean</entry>

            <entry>Std Deviation</entry>

            <entry nameend="_6" namest="_4">Correlation</entry>
          </row>

          <row>
            <entry>m</entry>

            <entry>6.433</entry>

            <entry>0.262</entry>

            <entry>1.000</entry>

            <entry/>

            <entry/>
          </row>

          <row>
            <entry>log<subscript>e</subscript> s</entry>

            <entry>0.353</entry>

            <entry>0.144</entry>

            <entry>0.111</entry>

            <entry>1.000</entry>

            <entry/>
          </row>

          <row>
            <entry>g</entry>

            <entry>0.131</entry>

            <entry>0.479</entry>

            <entry>0.033</entry>

            <entry>0.123</entry>

            <entry>1.000</entry>
          </row>
        </tbody>
      </tgroup>
    </informaltable>

    <para><xref linkend="b3_ch2_f_0us6g"/> displays the log normal probability
    plot of the gauged flows, the X% AEP quantile curve (derived using the
    posterior mean parameters), the 90% quantile confidence limits and the
    expected probability curve.</para>

    <figure xml:id="b3_ch2_f_0us6g">
      <title>Bayesian LPIII fit to 31 years of gauged Annual Maximum floods
      with prior information on skewness</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3016.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>The good fit to the gauged data and the tight confidence limits
    needs to be tempered by the fact that the figure plots the logarithm of
    the flood peaks. The following table of selected X% AEP quantiles
    q<subscript>Y</subscript> and their 90% confidence limits presents a more
    sobering perspective. For example, for the 1% AEP flood, the 5% and 95%
    confidence limits are respectively 37% and 546% of the quantile
    q<subscript>Y</subscript>! The 0.2% AEP confidence limits are so wide as
    to render estimation meaningless. Note the expected AEP for the quantile
    q<subscript>Y</subscript> consistently exceeds the nominal X% AEP. For
    example, the 1% (1 in 100) AEP quantile of 19572
    m<superscript>3</superscript>/s has an expected AEP of 1.35% (1 in
    74).</para>

    <informaltable>
      <tgroup cols="5">
        <colspec/>

        <colspec/>

        <colspec/>

        <colspec align="center"/>

        <tbody>
          <row>
            <entry>AEP (%)</entry>

            <entry>Quantile estimate q<subscript>Y</subscript></entry>

            <entry>Quantile confidence limits 5% limit</entry>

            <entry>Quantile confidence limits 95% limit</entry>

            <entry>Expected 1 in Y AEP for q<subscript>Y</subscript></entry>
          </row>

          <row>
            <entry>10</entry>

            <entry>3928</entry>

            <entry>2228</entry>

            <entry>8408</entry>

            <entry>10.1</entry>
          </row>

          <row>
            <entry>2</entry>

            <entry>12786</entry>

            <entry>5502</entry>

            <entry>51009</entry>

            <entry>2.33</entry>
          </row>

          <row>
            <entry>1</entry>

            <entry>19572</entry>

            <entry>7188</entry>

            <entry>106933</entry>

            <entry>1.35</entry>
          </row>

          <row>
            <entry>0.2</entry>

            <entry>47033</entry>

            <entry>11507</entry>

            <entry>570619</entry>

            <entry>0.48</entry>
          </row>
        </tbody>
      </tgroup>
    </informaltable>
  </section>

  <section xml:id="b3_ch2_s_n6bet">
    <title>Example 4: Use of binomial censored historical data</title>

    <para>This example is a continuation of Example 3. It illustrates the
    benefit of using historical flood information. The gauged record spanned
    1938 to 1969. The biggest flood in that record occurred in 1955. An
    examination of historic records indicates that during the ungauged period
    1820 to 1937 there was only one flood that exceeded the 1955 flood – this
    flood occurred in 1820. This represents valuable information even though
    the magnitude of the 1820 flood is not reliably known. This is an example
    of censored data. Over the ungauged period 1820 to 1937 there was one
    flood above and 117 floods below the threshold discharge corresponding to
    the 1955 flood. This information is entered into FLIKE as follows (<xref
    linkend="b3_ch2_f_ibgcw"/>):</para>

    <figure xml:id="b3_ch2_f_ibgcw">
      <title>FLIKE - Censored data input</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3017.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>The Log Pearson III distribution was fitted to gauged and censored
    data using the Bayesian approach.</para>

    <para>The following table presents the posterior mean, standard deviation
    and correlation for the LPIII parameters: m, s and g which are
    respectively the mean, standard deviation and skewness of
    log<subscript>e</subscript> q. Comparison with Example 3 reveals the
    censored data have reduced by almost 17% the uncertainty in the skewness
    g, the parameter that controls the shape of the distribution, particularly
    in the tail region.</para>

    <informaltable>
      <tgroup cols="6">
        <colspec/>

        <colspec/>

        <colspec/>

        <colspec colname="_4"/>

        <colspec align="center" colname="_5"/>

        <colspec colname="_6"/>

        <tbody>
          <row>
            <entry>LPIII parameter</entry>

            <entry>Mean</entry>

            <entry>Std Deviation</entry>

            <entry nameend="_6" namest="_4">Correlation</entry>
          </row>

          <row>
            <entry>m</entry>

            <entry>6.365</entry>

            <entry>0.237</entry>

            <entry>1.000</entry>

            <entry/>

            <entry/>
          </row>

          <row>
            <entry>log<subscript>e</subscript> s</entry>

            <entry>0.303</entry>

            <entry>0.120</entry>

            <entry>-0.236</entry>

            <entry>1.000</entry>

            <entry/>
          </row>

          <row>
            <entry>g</entry>

            <entry>-0.004</entry>

            <entry>0.405</entry>

            <entry>-0.227</entry>

            <entry>-0.409</entry>

            <entry>1.000</entry>
          </row>
        </tbody>
      </tgroup>
    </informaltable>

    <para>The following figure displays on a log normal probability plot the
    gauged flows, the X% AEP quantile curve (derived using the posterior mean
    parameters), the 90% quantile confidence limits and the expected
    probability curve. Compared with Example 3 the tightening of the
    confidence limits is most noticeable.</para>

    <figure xml:id="b3_ch2_f_1smuh">
      <title>Bayesian LPIII fit to 31 years gauged AM floods plus 117 years of
      censored data</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3018.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>The following table of selected 1 in Y AEP quantiles
    q<subscript>Y</subscript> and their 90% confidence limits illustrates the
    benefit of the information contained in the historic data. For example,
    for the 1% AEP flood the 5% and 95% confidence limits are respectively 58%
    and 205% of the quantile qY! This represents a major reduction in quantile
    uncertainty compared with Example 3 which yielded limits of 38% and
    553%.</para>

    <para/>

    <informaltable>
      <tgroup cols="5">
        <colspec/>

        <colspec/>

        <colspec/>

        <colspec align="center"/>

        <tbody>
          <row>
            <entry>% AEP</entry>

            <entry>Quantile estimate q<subscript>Y</subscript></entry>

            <entry>Quantile confidence limits 5% limit</entry>

            <entry>Quantile confidence limits 95% limit</entry>

            <entry>Expected 1 in Y AEP for q<subscript>Y</subscript></entry>
          </row>

          <row>
            <entry>10</entry>

            <entry>3293</entry>

            <entry>2181</entry>

            <entry>4946</entry>

            <entry>10.4</entry>
          </row>

          <row>
            <entry>2</entry>

            <entry>9350</entry>

            <entry>5777</entry>

            <entry>16511</entry>

            <entry>2.08</entry>
          </row>

          <row>
            <entry>1</entry>

            <entry>13510</entry>

            <entry>7784</entry>

            <entry>27685</entry>

            <entry>1.09</entry>
          </row>

          <row>
            <entry>0.2</entry>

            <entry>28451</entry>

            <entry>12966</entry>

            <entry>85586</entry>

            <entry>0.28</entry>
          </row>
        </tbody>
      </tgroup>
    </informaltable>

    <para>This example highlights the significant reductions in uncertainty
    that historical data can offer. However, care must be exercised ensuring
    the integrity of the historic information – see Section 3.8 for more
    details.</para>
  </section>

  <section xml:id="b3_ch2_s_9cmvk">
    <title>Example 5: Use of regional information</title>

    <para>This is a continuation of Example 3. In Example 3 the posterior mean of the skewness was
      estimated to be 0.131 with a posterior standard of 0.479. The uncertainty in the 1% AEP
      quantile was large. Suppose hypothetically that a regional analysis of skewness was conducted.
      Furthermore<?oxy_insert_start author="RadhikaChhotai" timestamp="20151022T175036+1100"?>,<?oxy_insert_end?>
      suppose the expected regional skew is 0.00 with a standard deviation of 0.30. This information
      is entered into FLIKE by selecting the Gaussian prior distributions button and clicking on
      “edit” control <xref linkend="b3_ch2_f_zlnc1"/>:</para>

    <figure xml:id="b3_ch2_f_zlnc1">
      <title>FLIKE - Gaussian Prior Distributions Input</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3019.PNG"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>The prior information was directly entered into the following
      <?oxy_delete author="RadhikaChhotai" timestamp="20151022T175058+1100" content="dialog"?><?oxy_insert_start author="RadhikaChhotai" timestamp="20151022T175058+1100"?>dialogue<?oxy_insert_end?>.
      Note that very large prior standard deviations are assigned to the mean and standard deviation
      parameters to ensure there is no prior information about theses parameters. If the Log Pearson
      III distribution has been selected, the option to import the prior information from the ARR
      Regional Flood Frequency Estimation method is available (refer to Book 3 Chapter 2).</para>

    <figure xml:id="b3_ch2_f_pkw4b">
      <title>FLIKE - Prior Information</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3020.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para><xref linkend="b3_ch2_f_gc6ok"/> presents the probability plot for
    the LPIII model fitted to the gauged data with prior information on the
    skewness. Comparison with <xref linkend="b3_ch2_f_0us6g"/> reveals
    substantially improved accuracy in the right hand tail.</para>

    <figure xml:id="b3_ch2_f_gc6ok">
      <title>Bayesian LPIII fit to 31 years of gauged Annual Maximum floods
      with prior information on skewness</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3021.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>The table compares the LPIII fitted with and without prior
    information on skewness. The posterior uncertainty on the skewness is
    about 87% of the prior standard deviation indicating the gauged data are
    not very informative about the shape parameter of the flood
    distribution.</para>

    <informaltable>
      <tgroup cols="5">
        <colspec/>

        <colspec colname="_2"/>

        <colspec colname="_3"/>

        <colspec align="center" colname="_4"/>

        <colspec colname="_5"/>

        <tbody>
          <row>
            <entry morerows="1">LPIII parameter</entry>

            <entry nameend="_3" namest="_2">No prior information</entry>

            <entry nameend="_5" namest="_4">With prior information</entry>
          </row>

          <row>
            <entry>Mean</entry>

            <entry>Std deviation</entry>

            <entry>Mean</entry>

            <entry>Std deviation</entry>
          </row>

          <row>
            <entry>m</entry>

            <entry>6.433</entry>

            <entry>0.262</entry>

            <entry>6.421</entry>

            <entry>0.251</entry>
          </row>

          <row>
            <entry>log<subscript>e</subscript> s</entry>

            <entry>0.353</entry>

            <entry>0.144</entry>

            <entry>0.320</entry>

            <entry>0.131</entry>
          </row>

          <row>
            <entry>g</entry>

            <entry>0.131</entry>

            <entry>0.479</entry>

            <entry>0.019</entry>

            <entry>0.260</entry>
          </row>
        </tbody>
      </tgroup>
    </informaltable>

    <para>The table of selected AEP quantiles q<subscript>Y</subscript> and their 90% confidence
      limits further illustrates the benefit of incorporating regional information. For example, for
      the 1% AEP flood the 5% and 95% confidence limits are respectively 37% and 546% of the
      quantile
      q<subscript>1%</subscript><?oxy_insert_start author="RadhikaChhotai" timestamp="20151022T175114+1100"?>,<?oxy_insert_end?>
      when no prior information is used. These limits are reduced to 46% and 292% using prior
      regional information.</para>

    <informaltable>
      <tgroup cols="7">
        <colspec/>

        <colspec colname="_2"/>

        <colspec colname="_3"/>

        <colspec colname="_4"/>

        <colspec colname="_5"/>

        <colspec align="center" colname="_6"/>

        <colspec colname="_7"/>

        <tbody>
          <row>
            <entry morerows="1">% AEP</entry>

            <entry nameend="_4" namest="_2">No prior information</entry>

            <entry nameend="_7" namest="_5">With prior information</entry>
          </row>

          <row>
            <entry>Quantile q<subscript>Y</subscript></entry>

            <entry>Quantile confidence limits 5% limit</entry>

            <entry>Quantile confidence limits 95% limit</entry>

            <entry>Quantile q<subscript>Y</subscript></entry>

            <entry>Quantile confidence limits 5% limit</entry>

            <entry>Quantile confidence limits 95% limit</entry>
          </row>

          <row>
            <entry>10</entry>

            <entry>3928</entry>

            <entry>2228</entry>

            <entry>8408</entry>

            <entry>3597</entry>

            <entry>2171</entry>

            <entry>6702</entry>
          </row>

          <row>
            <entry>2</entry>

            <entry>12786</entry>

            <entry>5502</entry>

            <entry>51009</entry>

            <entry>10534</entry>

            <entry>5310</entry>

            <entry>26633</entry>
          </row>

          <row>
            <entry>1</entry>

            <entry>19572</entry>

            <entry>7188</entry>

            <entry>106933</entry>

            <entry>15412</entry>

            <entry>7092</entry>

            <entry>45086</entry>
          </row>
        </tbody>
      </tgroup>
    </informaltable>
  </section>

  <section xml:id="b3_ch2_s_v6fo7">
    <title>Example 6: Censoring PILFs using multiple Grubbs-Beck test</title>

    <para>The multiple Grubbs-Beck test is recommended in all flood frequency
    analyses to identify Potentially Influential Low Flows (PILFs). This
    example is taken from Pedruco <emphasis>et al</emphasis>. (2013). The
    following table lists 56 years of Annual Maximum discharges for the
    Wimmera river:</para>

    <informaltable>
      <tgroup cols="7">
        <tbody>
          <row>
            <entry>464.35</entry>

            <entry>167.72</entry>

            <entry>119.63</entry>

            <entry>71.4</entry>

            <entry>32.18</entry>

            <entry>14.16</entry>

            <entry>8.52</entry>
          </row>

          <row>
            <entry>395.65</entry>

            <entry>155.22</entry>

            <entry>110.56</entry>

            <entry>69.67</entry>

            <entry>25.91</entry>

            <entry>12.64</entry>

            <entry>3.22</entry>
          </row>

          <row>
            <entry>285.92</entry>

            <entry>147</entry>

            <entry>102.62</entry>

            <entry>67.49</entry>

            <entry>24.83</entry>

            <entry>11.9</entry>

            <entry>2.28</entry>
          </row>

          <row>
            <entry>278.01</entry>

            <entry>143.99</entry>

            <entry>97.32</entry>

            <entry>61.64</entry>

            <entry>23.95</entry>

            <entry>11.79</entry>

            <entry>2.13</entry>
          </row>

          <row>
            <entry>235.22</entry>

            <entry>143.62</entry>

            <entry>96.78</entry>

            <entry>54.4</entry>

            <entry>22.76</entry>

            <entry>11.41</entry>

            <entry>1.9</entry>
          </row>

          <row>
            <entry>211.91</entry>

            <entry>142.66</entry>

            <entry>87.98</entry>

            <entry>38.62</entry>

            <entry>19.04</entry>

            <entry>10.8</entry>

            <entry>1.43</entry>
          </row>

          <row>
            <entry>173.79</entry>

            <entry>134.36</entry>

            <entry>79.15</entry>

            <entry>36.62</entry>

            <entry>17.37</entry>

            <entry>10.31</entry>

            <entry>1.16</entry>
          </row>

          <row>
            <entry>170.13</entry>

            <entry>123.8</entry>

            <entry>77.03</entry>

            <entry>34.07</entry>

            <entry>14.87</entry>

            <entry>10.08</entry>

            <entry>0.01</entry>
          </row>
        </tbody>
      </tgroup>
    </informaltable>

    <para>The following figure presents the probability plot for GEV
    distribution. The fit to the right-hand tail is problematic.</para>

    <figure xml:id="b3_ch2_f_unzxz">
      <title>GEV fit - 56 years of AM discharges - Wimmera River</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3022.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>In FLIKE the multiple Grubbs-Beck test is implemented by clicking on
    the “censor” control as shown below. The dialog advises the multiple
    Grubbs-Beck test has identified 27 PILFs.</para>

    <figure xml:id="b3_ch2_f_rmgeb">
      <title>FLIKE - Using Multiple Grubbs-Beck test</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3023.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>On agreeing to censor these flows, FLIKE automatically performs two
    changes to the inference setup:</para>

    <orderedlist>
      <listitem>
        <para>The 27 lowest discharges are excluded from the
        calibration.</para>
      </listitem>

      <listitem>
        <para>The “censored data” dialog is populated with the information
        that there are 27 Annual Maximum discharges that lie below the
        threshold of 54.399 which corresponds the rank-28 discharge.</para>
      </listitem>
    </orderedlist>

    <para>The following two dialogs illustrate these changes:</para>

    <figure xml:id="b3_ch2_f_x5jni">
      <title>FLIKE - PILFs censored data</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3024.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>The following probability plot demonstrates the substantially
    improved fit to the right-hand tail along with significantly tighter
    confidence limits:</para>

    <figure xml:id="b3_ch2_f_atra8">
      <title>GEV fit - 56 years AM of gauged discharge - Using multiple
      Grubbs-Beck test</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3025.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>
  </section>

  <section xml:id="b3_ch2_s_4mn8v">
    <title>Example 7: Improving poor fits using censoring of low discharge
    data</title>

    <para>The standard probability models such as GEV and LPIII may not
    adequately fit flood data for a variety of reasons. Often the poor fit is
    associated with a sigmoidal probability plot as illustrated in <xref
    linkend="b3_ch2_f_unzxz"/>. In such cases one can employ four or
    five-parameter distributions which have sufficient degrees of freedom to
    track the data in both upper and lower tails of the sigmoidal curve.
    Alternatively one can adopt a calibration approach that gives less weight
    to smaller floods. The latter approach is illustrated in this example
    which considers 50 Annual Maximum floods (m<superscript>3</superscript>/s)
    for the Albert River at Broomfleet presented in the following
    table:</para>

    <informaltable>
      <tgroup cols="10">
        <tbody>
          <row>
            <entry>13.02</entry>

            <entry>15.57</entry>

            <entry>15.85</entry>

            <entry>16.70</entry>

            <entry>22.36</entry>

            <entry>36.51</entry>

            <entry>72.73</entry>

            <entry>78.11</entry>

            <entry>87.73</entry>

            <entry>88.30</entry>
          </row>

          <row>
            <entry>95.65</entry>

            <entry>99.90</entry>

            <entry>113.77</entry>

            <entry>116.88</entry>

            <entry>124.52</entry>

            <entry>131.03</entry>

            <entry>156.22</entry>

            <entry>156.50</entry>

            <entry>190.74</entry>

            <entry>210.55</entry>
          </row>

          <row>
            <entry>220.74</entry>

            <entry>249.61</entry>

            <entry>249.61</entry>

            <entry>271.68</entry>

            <entry>285.83</entry>

            <entry>302.81</entry>

            <entry>305.64</entry>

            <entry>362.24</entry>

            <entry>384.88</entry>

            <entry>461.29</entry>
          </row>

          <row>
            <entry>466.95</entry>

            <entry>676.37</entry>

            <entry>752.78</entry>

            <entry>761.27</entry>

            <entry>761.27</entry>

            <entry>860.32</entry>

            <entry>863.15</entry>

            <entry>865.98</entry>

            <entry>1086.72</entry>

            <entry>1177.28</entry>
          </row>

          <row>
            <entry>1185.77</entry>

            <entry>1214.07</entry>

            <entry>1273.50</entry>

            <entry>1327.27</entry>

            <entry>1341.42</entry>

            <entry>1364.06</entry>

            <entry>1468.77</entry>

            <entry>1652.72</entry>

            <entry>1689.51</entry>

            <entry>1765.92</entry>
          </row>
        </tbody>
      </tgroup>
    </informaltable>

    <para><xref linkend="b3_ch2_f_q9xq4"/> displays the GEV Bayesian fit on a
    Gumbel probability plot. Although the observed floods are largely
    contained within the 90% confidence limits, the fit, nonetheless, is poor
    – the data exhibit a sigmoidal trend with reverse curvature developing for
    floods with a less than 50%. It appears that the confidence limits have
    been inflated because the GEV fit represents a poor compromise. <xref
    linkend="b3_ch2_f_4llzf"/> displays the fit after censoring the 5 low
    outliers identified by the multiple Grubbs-Beck test. The improvement in
    fit is marginal at best.</para>

    <figure xml:id="b3_ch2_f_q9xq4">
      <title>Bayesian fit to all gauged data Gumbel probability plot</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3026.PNG"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para/>

    <figure xml:id="b3_ch2_f_4llzf">
      <title>Bayesian fit with 5 low outliers censored after application of
      multiple Grubbs-Beck test</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3027.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>To deal with this poor fit, a trial-and-error approach based on
    censoring low flows can be used to obtain a fit that favours the right
    hand tail of the distribution. <xref linkend="b3_ch2_f_382cm"/>
    illustrates one such fit. To de-emphasize the left hand tail the floods
    below the threshold of 250 m<superscript>3</superscript>/s were censored.
    This means the GEV distribution was fitted to:</para>

    <itemizedlist>
      <listitem>
        <para>A gauged record consisting of the 27 floods above 250
        m<superscript>3</superscript>/s; and</para>
      </listitem>

      <listitem>
        <para>A censored record consisting of 23 floods below the threshold of
        250 m<superscript>3</superscript>/s and 0 floods above this
        threshold.</para>
      </listitem>
    </itemizedlist>

    <para>The censored record provides an anchor point for the GEV
    distribution – it ensures that the chance of an Annual Maximum flood being
    less than 250 m<superscript>3</superscript>/s is about 23/50 without
    forcing the GEV to fit the peaks below the 250
    m<superscript>3</superscript>/s threshold. The fit effectively disregards
    floods with a greater than 50% AEP and provides a good fit to the upper
    tail. Another benefit is the substantially reduced 90% confidence
    range</para>

    <figure xml:id="b3_ch2_f_382cm">
      <title>Bayesian fit with floods below 250
      m<superscript>3</superscript>/s threshold treated as censored
      observations</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3028.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>An alternative to this manual method for censoring is illustrated in
    Example 10 which presents the LH moments procedure for de-emphasising low
    discharges.</para>
  </section>

  <section xml:id="b3_ch2_s_lzisv">
    <title>Example 8: A Non-Homogeneous Flood Probability Model</title>

    <para>The work of Micevski <emphasis>et al</emphasis>. (2003) illustrates
    an example of a non-homogeneous model. An indicator time series based on
    the IPO time series (<xref linkend="b3_ch2_f_6x7dy"/>) was used to create
    the exogeneous vector x:</para>

    <equation xml:id="b3_ch2_e_rdpiz">
      <m:math display="block">
        <m:mrow>
          <m:mi>x</m:mi>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:msub>
              <m:mi>{I</m:mi>

              <m:mi>t</m:mi>
            </m:msub>

            <m:mo>, t = 1,...,n}</m:mo>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>where the indicator</para>

    <equation xml:id="b3_ch2_e_ps320">
      <m:math display="block">
        <m:mrow>
          <m:msub>
            <m:mi>I</m:mi>

            <m:mi>t</m:mi>
          </m:msub>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mo>{</m:mo>

            <m:mtable>
              <m:mtr>
                <m:mtd>
                  <m:mrow>
                    <m:mi>1 if</m:mi>

                    <m:msub>
                      <m:mi>IPO</m:mi>

                      <m:mi>t</m:mi>
                    </m:msub>

                    <m:mrow>
                      <m:mi>≥</m:mi>

                      <m:msub>
                        <m:mi>IPO</m:mi>

                        <m:mi>thresh</m:mi>
                      </m:msub>
                    </m:mrow>
                  </m:mrow>
                </m:mtd>
              </m:mtr>

              <m:mtr>
                <m:mtd>
                  <m:mrow>
                    <m:mi>0 if</m:mi>

                    <m:msub>
                      <m:mi>IPO</m:mi>

                      <m:mi>t</m:mi>
                    </m:msub>

                    <m:msub>
                      <m:mi>&lt; IPO</m:mi>

                      <m:mi>thresh</m:mi>
                    </m:msub>
                  </m:mrow>
                </m:mtd>
              </m:mtr>
            </m:mtable>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>IPO<subscript>t</subscript> is the IPO index for year t and
    IPO<subscript>thresh</subscript> is a threshold value equal to
    -0.125.</para>

    <para>At each of the 33 NSW sites considered by Micevski <emphasis>et
    al</emphasis>. (2003) the AM peak discharges were stratified according to
    the indicator I<subscript>t</subscript>. A 2-parameter log-normal
    distribution was fitted to the gauged discharges with indicator equal to 1
    – this is the IPO+ distribution. Likewise, a 2-parameter log-normal
    distribution was fitted to the gauged discharges with indicator equal to 0
    – this is the IPO- distribution. <xref linkend="b3_ch2_f_qzdoi"/> presents
    the histogram for the ratio of the IPO- and IPO+ floods for selected X%
    AEPs. If the the IPO+ and IPO- distributions were homogeneous then about
    half of the sites should have a flood ratio &lt; 1 – <xref
    linkend="b3_ch2_f_qzdoi"/> shows otherwise.</para>

    <para><xref linkend="b3_ch2_f_el7ls"/> and <xref
    linkend="b3_ch2_f_0wj1a"/> present log normal fits to the IPO+ and IPO-
    annual maximum flood data for the Clarence River at Lilydale respectively.
    Though the adequacy of the log normal model to fit high floods may be
    questioned, in the range 50% to 10% AEP, the IPO- floods are about 2.6
    times the IPO+ floods with the same AEP.</para>

    <figure xml:id="b3_ch2_f_qzdoi">
      <title>Histogram of IPO- and IPO+ flood ratios</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3029.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para/>

    <figure xml:id="b3_ch2_f_el7ls">
      <title>Log-normal fit to 43 years of IPO+ data for the Clarence River at
      Lilydale (units ML/day)</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3030.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para/>

    <figure xml:id="b3_ch2_f_0wj1a">
      <title>Log-normal fit to 33 years of IPO- data for the Clarence River at
      Lilydale (units ML/day)</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3031.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <figure xml:id="b3_ch2_f_orrph">
      <title>Log-normal fit to 76 years of data for the Clarence River at
      Lilydale (units ML/day)</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3032.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>To avoid bias in estimating long-term flood risk it is essential
    that the gauged record adequately span both IPO+ and IPO- years. In this
    example, the IPO+ record is 43 years and the IPO- record is 33 years in
    length. With reference to <xref linkend="b3_ch2_f_6x7dy"/> this length of
    record appears to adequately sample both IPO epochs. This suggests that
    fitting to all the data will yield a largely unbiased estimate of the
    long-term flood risk. <xref linkend="b3_ch2_f_orrph"/> illustrates a log
    normal fit to all the data.</para>

    <para>A better appreciation of the differences in flood risk can be
    gleaned by considering <xref linkend="b3_ch2_f_73gq1"/> which presents the
    fitted log normal distributions to the IPO+, IPO- and total data. During
    an IPO+ period a flood peak of 100 m<superscript>3</superscript>/s has a
    5% AEP while during an IPO- period it has a 25% AEP. Likewise a flood peak
    of 200 m<superscript>3</superscript> /s has 1% and 10% AEPs for IPO+ and
    IPO- periods respectively. The differences in flood risk are considerable.
    If a short gauged record falling largely in the IPO+ period was used, a
    standard Flood Frequency Analysis could seriously underestimate the
    long-term or marginal flood risk.</para>

    <para>The marginal flood risk can be derived by combining the IPO+ and
    IPO- distribution using <xref linkend="b3_ch2_e_p72ly"/> to give:</para>

    <equation xml:id="b3_ch2_e_sy22b">
      <m:math display="block">
        <m:mrow>
          <m:mrow>
            <m:mi>P(Q≤</m:mi>

            <m:mo>q)</m:mo>

            <m:mi>=</m:mi>

            <m:mo>P(x</m:mo>
          </m:mrow>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mi>0)</m:mi>

            <m:mrow>
              <m:munderover>
                <m:mo>∫</m:mo>

                <m:mi>0</m:mi>

                <m:mi>q</m:mi>
              </m:munderover>

              <m:mi>p(z|</m:mi>
            </m:mrow>

            <m:mi>θ(x=0))dz + P (x=1)</m:mi>

            <m:mrow>
              <m:munderover>
                <m:mo>∫</m:mo>

                <m:mi>0</m:mi>

                <m:mi>q</m:mi>
              </m:munderover>

              <m:mi>p(z|</m:mi>
            </m:mrow>

            <m:mi>θ(x=1))dz</m:mi>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>The exogenous variable x can take two values, 0 or 1, depending on
    the IPO epoch. P(x=0), the probability of being in an IPO- epoch, is
    assigned the value 33/76 based on the observation that 33 of the 76 years
    of record were in the IPO- epoch. Likewise P(x=1), the probability of
    being in an IPO+ epoch, is assigned the value 43/76. It follows that
    p(z|<inlineequation>
        <m:math display="inline">
          <m:mi>θ</m:mi>
        </m:math>
      </inlineequation>,x=0) and p(z|<inlineequation>
        <m:math display="inline">
          <m:mi>θ</m:mi>
        </m:math>
      </inlineequation>,x=1) are the log normal pdfs fitted to IOP- and IPO+
    data respectively.</para>

    <para>The derived marginal distribution is plotted in <xref
    linkend="b3_ch2_f_73gq1"/>. It almost exactly matches the log normal
    distribution fitted to all the data.</para>

    <figure xml:id="b3_ch2_f_73gq1">
      <title>Marginal, IPO+ and IPO+ log-normal distributions for the Clarence
      River at Lilydale</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3033.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>
  </section>

  <section xml:id="b3_ch2_s_38w71">
    <title>Example 9: L moments fit to gauged data</title>

    <para>This example illustrates fitting a GEV distribution to gauged data
    using L moments. The following table lists 47 ranked Annual Maximum flood
    for the Styx River at Jeogla:</para>

    <informaltable>
      <tgroup cols="8">
        <tbody>
          <row>
            <entry>878</entry>

            <entry>541</entry>

            <entry>521</entry>

            <entry>513</entry>

            <entry>436</entry>

            <entry>411</entry>

            <entry>405</entry>

            <entry>315</entry>
          </row>

          <row>
            <entry>309</entry>

            <entry>300</entry>

            <entry>294</entry>

            <entry>258</entry>

            <entry>255</entry>

            <entry>235</entry>

            <entry>221</entry>

            <entry>220</entry>
          </row>

          <row>
            <entry>206</entry>

            <entry>196</entry>

            <entry>194</entry>

            <entry>190</entry>

            <entry>186</entry>

            <entry>177</entry>

            <entry>164</entry>

            <entry>126</entry>
          </row>

          <row>
            <entry>117</entry>

            <entry>111</entry>

            <entry>108</entry>

            <entry>105</entry>

            <entry>92.2</entry>

            <entry>88.6</entry>

            <entry>79.9</entry>

            <entry>74</entry>
          </row>

          <row>
            <entry>71.9</entry>

            <entry>62.6</entry>

            <entry>61.2</entry>

            <entry>60.3</entry>

            <entry>58</entry>

            <entry>53.5</entry>

            <entry>39.1</entry>

            <entry>26.7</entry>
          </row>

          <row>
            <entry>26.1</entry>

            <entry>23.8</entry>

            <entry>22.4</entry>

            <entry>22.1</entry>

            <entry>18.6</entry>

            <entry>13</entry>

            <entry>8.18</entry>

            <entry/>
          </row>
        </tbody>
      </tgroup>
    </informaltable>

    <para>The following table reports the results of estimating GEV parameters
    by substituting the L moment estimates in <xref linkend="b3_ch2_e_gf6r2"/>
    to obtain <inlineequation>
        <m:math display="inline">
          <m:mi>κ</m:mi>
        </m:math>
      </inlineequation> and then using the equations in <xref
    linkend="b3_ch2_t_achre"/> to estimate <inlineequation>
        <m:math display="inline">
          <m:mi>τ</m:mi>
        </m:math>
      </inlineequation> and <inlineequation>
        <m:math display="inline">
          <m:mi>α</m:mi>
        </m:math>
      </inlineequation>. The standard deviation and correlation were derived
    from 5000 bootstrapped samples following the procedure described in <xref
    linkend="b3_ch2_s_3sslo"/>.</para>

    <informaltable>
      <tgroup cols="8">
        <colspec colname="_6" colnum="6"/>

        <colspec colname="_7"/>

        <colspec colname="_8"/>

        <tbody>
          <row>
            <entry>L moment estimates</entry>

            <entry>L moment estimates</entry>

            <entry>GEV parameter</entry>

            <entry>Parameter estimate</entry>

            <entry>Standard deviation</entry>

            <entry nameend="_8" namest="_6">Correlation</entry>
          </row>

          <row>
            <entry>λ<subscript>1</subscript></entry>

            <entry>189.238</entry>

            <entry>τ</entry>

            <entry>100.660</entry>

            <entry>17.657</entry>

            <entry>1.000</entry>

            <entry/>

            <entry/>
          </row>

          <row>
            <entry>λ<subscript>2</subscript></entry>

            <entry>92.476</entry>

            <entry>α</entry>

            <entry>104.157</entry>

            <entry>15.554</entry>

            <entry>0.597</entry>

            <entry>1.000</entry>

            <entry/>
          </row>

          <row>
            <entry>λ<subscript>3</subscript></entry>

            <entry>29.264</entry>

            <entry>κ</entry>

            <entry>-0.219</entry>

            <entry>0.130</entry>

            <entry>0.358</entry>

            <entry>0.268</entry>

            <entry>1.000</entry>
          </row>
        </tbody>
      </tgroup>
    </informaltable>

    <para>The following figure presents a probability plot of the gauged data
    along with GEV X% AEP quantiles and their 90% confidence limits. The
    confidence limits widen appreciably for the bigger floods – this is
    largely due to there being insufficient information to accurately infer
    the shape parameter <inlineequation>
        <m:math display="inline">
          <m:mi>κ</m:mi>
        </m:math>
      </inlineequation>.</para>

    <figure xml:id="b3_ch2_f_keijm">
      <title>Styx River at Jeogla</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3034.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>
  </section>

  <section xml:id="b3_ch2_s_4o6lc">
    <title>Example 10: Improving poor fits using LH moments</title>

    <para>This example is a continuation of Example 7. The GEV distribution
    was fitted to the gauged data for the Albert River at Broomfleet using LH
    moments.</para>

    <para><xref linkend="b3_ch2_f_nuhvd"/> displays the GEV L moment fit on a
    Gumbel probability plot. Although the observed floods are largely
    contained within the 90% confidence limits, the fit, nonetheless, is poor
    with systematic departures from the data which exhibit reverse
    curvature.</para>

    <para>To deal with this poor fit, a LH moment search was conducted to find
    the optimal shift parameter <inlineequation>
        <m:math display="inline">
          <m:mi>η</m:mi>
        </m:math>
      </inlineequation> using the procedure described in <xref
    linkend="b3_ch2_s_xodr0"/>. The optimal shift was found to be 4. <xref
    linkend="b3_ch2_f_yx491"/> presents the LH moment fit with shift
    <inlineequation>
        <m:math display="inline">
          <m:mi>η</m:mi>
        </m:math>
      </inlineequation> equal to 4. The fit effectively disregards floods in
    excess of a 50% AEP and provides a very good fit to upper tail.</para>

    <figure xml:id="b3_ch2_f_nuhvd">
      <title>L moment fit - Albert River at Broomfleet</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3035.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <figure xml:id="b3_ch2_f_yx491">
      <title>LH moment fit with shift η=4</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3036.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>The very significant reduction in the width of the quantile
    confidence intervals is largely due to the shape parameter <inlineequation>
        <m:math display="inline">
          <m:mi>κ</m:mi>
        </m:math>
      </inlineequation> changing from –0.17 to 0.50. The L moment fit in <xref
    linkend="b3_ch2_f_nuhvd"/> was a compromise with the bulk of the small and
    medium-sized floods suggesting an upward curvature in the probability plot
    – as a result the GEV shape parameter <inlineequation>
        <m:math display="inline">
          <m:mi>κ</m:mi>
        </m:math>
      </inlineequation> had to be negative to enable upward curvature. In
    contrast, the LH moment fit favoured the large-sized floods which exhibit
    a downward curvature resulting in a positive shape parameter. For positive
    <inlineequation>
        <m:math display="inline">
          <m:mi>κ</m:mi>
        </m:math>
      </inlineequation> the GEV has an upper bound. In this case the upper
    bound is about 2070 m<superscript>3</superscript>/s which is only 17%
    greater than the largest observed flood.</para>
  </section>

  <section xml:id="b3_ch2_s_4boa6">
    <title>Example 11: Fitting a probability model to POT data</title>

    <para>This example is a continuation of Example 9 which considers the Styx
    River at Jeogla. It illustrates fitting an exponential distribution to POT
    data. The table lists all the independent peak flows recorded over a 47
    year period that exceeded a threshold of 74
    m<superscript>3</superscript>/s – the total number of peaks was 47.
    Comparison with the Annual Maximum flood peaks in Example 9 reveals that
    in 15 of the 47 years of record the Annual Maximum peak were below the
    threshold of 74 m<superscript>3</superscript>/s.</para>

    <informaltable>
      <tgroup cols="8">
        <tbody>
          <row>
            <entry>878</entry>

            <entry>541</entry>

            <entry>521</entry>

            <entry>513</entry>

            <entry>436</entry>

            <entry>411</entry>

            <entry>405</entry>

            <entry>315</entry>
          </row>

          <row>
            <entry>309</entry>

            <entry>301</entry>

            <entry>300</entry>

            <entry>294</entry>

            <entry>283</entry>

            <entry>258</entry>

            <entry>255</entry>

            <entry>255</entry>
          </row>

          <row>
            <entry>238</entry>

            <entry>235</entry>

            <entry>221</entry>

            <entry>220</entry>

            <entry>206</entry>

            <entry>196</entry>

            <entry>194</entry>

            <entry>190</entry>
          </row>

          <row>
            <entry>186</entry>

            <entry>164</entry>

            <entry>150</entry>

            <entry>149</entry>

            <entry>134</entry>

            <entry>129</entry>

            <entry>129</entry>

            <entry>126</entry>
          </row>

          <row>
            <entry>119</entry>

            <entry>118</entry>

            <entry>117</entry>

            <entry>117</entry>

            <entry>111</entry>

            <entry>108</entry>

            <entry>105</entry>

            <entry>98</entry>
          </row>

          <row>
            <entry>92.2</entry>

            <entry>92.2</entry>

            <entry>91.7</entry>

            <entry>88.6</entry>

            <entry>85.2</entry>

            <entry>79.9</entry>

            <entry>74</entry>

            <entry/>
          </row>
        </tbody>
      </tgroup>
    </informaltable>

    <para>The first two L moments were estimated as 226.36 and 79.2. Noting
    that the exponential distribution is a special case of the generalised
    Pareto when <inlineequation>
        <m:math display="inline">
          <m:mi>κ</m:mi>
        </m:math>
      </inlineequation> = 0, it follows from <xref linkend="b3_ch2_t_achre"/>
    that the exponential parameters are related to the L moments by:</para>

    <equation xml:id="b3_ch2_e_iokdx">
      <m:math display="block">
        <m:mrow>
          <m:msub>
            <m:mi>λ</m:mi>

            <m:mi>1</m:mi>
          </m:msub>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:msub>
              <m:mi>q</m:mi>

              <m:mi>*</m:mi>
            </m:msub>

            <m:mo>+</m:mo>

            <m:mrow>
              <m:mi>β</m:mi>

              <m:mrow>
                <m:msub>
                  <m:mi>λ</m:mi>

                  <m:mi>2</m:mi>
                </m:msub>

                <m:mo>=</m:mo>

                <m:mfrac>
                  <m:mi>β</m:mi>

                  <m:mi>2</m:mi>
                </m:mfrac>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>which yields values for q* and β of 68.11 and 158.24 respectively.
    Using <xref linkend="b3_ch2_e_w9t35"/>, the expected number of peaks that
    exceed w in a year is:</para>

    <equation xml:id="b3_ch2_e_jtnyh">
      <m:math display="block">
        <m:mrow>
          <m:mi>EY (w)</m:mi>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mi>νP(q&gt;w)</m:mi>

            <m:mrow>
              <m:mo>=</m:mo>

              <m:mrow>
                <m:mi>ν exp</m:mi>

                <m:mrow>
                  <m:mo>(</m:mo>

                  <m:mrow>
                    <m:mi>-</m:mi>

                    <m:mfrac>
                      <m:mi>w-q</m:mi>

                      <m:mi>β</m:mi>
                    </m:mfrac>
                  </m:mrow>

                  <m:mo>)</m:mo>
                </m:mrow>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <equation xml:id="b3_ch2_e_7uagh">
      <m:math display="block">
        <m:mrow>
          <m:mrow>
            <m:msub>
              <m:mi>log</m:mi>

              <m:mi>e</m:mi>
            </m:msub>

            <m:mo>EY(w)</m:mo>
          </m:mrow>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mrow>
              <m:msub>
                <m:mi>log</m:mi>

                <m:mi>e</m:mi>
              </m:msub>

              <m:mo>ν</m:mo>
            </m:mrow>

            <m:mo>+</m:mo>

            <m:mrow>
              <m:mfrac>
                <m:mi>q</m:mi>

                <m:mi>β</m:mi>
              </m:mfrac>

              <m:mo>-</m:mo>

              <m:mfrac>
                <m:mi>w</m:mi>

                <m:mi>β</m:mi>
              </m:mfrac>
            </m:mrow>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>where ν is the average number of flood peaks above the threshold q*
    per year.</para>

    <para>Given that 47 peaks above the threshold occurred in 47 years, ν
    equals 1.0. The following figure presents a plot of the fitted POT
    exponential model against the observed POT series.</para>

    <figure xml:id="b3_ch2_f_s588s">
      <title>Styx River at Jeogla, POT series</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3037.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para/>
  </section>
</section>
<?oxy_options track_changes="on"?>