<?xml version="1.0" encoding="UTF-8"?>
<section status="In Preparation" version="5.0" xml:id="b3_ch2_s9"
         xmlns="http://docbook.org/ns/docbook"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:svg="http://www.w3.org/2000/svg"
         xmlns:m="http://www.w3.org/1998/Math/MathML"
         xmlns:html="http://www.w3.org/1999/xhtml"
         xmlns:db="http://docbook.org/ns/docbook">
  <title>Supplementary Information</title>

  <section>
    <title>Box 1: Theory of Peak Over Threshold and Annual Maximum
    Series</title>

    <section xml:id="b3_ch2_s_k55h9">
      <title>Annual Exceedance Probability AEP</title>

      <para>The objective is to derive the distribution of the maximum flood peak within a specified
        interval of time. Referring to the continuous streamflow times series <xref
          linkend="b3_ch2_f_e1wwl"/>, let the random variable q be a local peak discharge defined as
        a discharge
        <?oxy_delete author="RadhikaChhotai" timestamp="20151022T173807+1100" content="which"?><?oxy_insert_start author="RadhikaChhotai" timestamp="20151022T173807+1100"?>that<?oxy_insert_end?>
        has lower discharge on either side of the peak. This presents an immediate problem as any
        bump on the hydrograph would produce a local peak. To circumvent this
        problem<?oxy_insert_start author="RadhikaChhotai" timestamp="20151022T173853+1100"?>,<?oxy_insert_end?>
        we focus on peaks greater than some threshold defined as q<subscript>o</subscript>. The
        threshold is selected so that the peaks above the threshold are sufficiently separated in
        time to be statistically independent of each other.</para>

      <figure xml:id="b3_ch2_f_e1wwl">
        <title>Peak Over Threshold series</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="../../figures/3001.jpg"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>It is assumed that all peaks above the threshold
      q<subscript>o</subscript> are sampled from the same distribution denoted
      by the pdf p(q|q&gt;q<subscript>o</subscript>).</para>

      <para>Suppose<?oxy_insert_start author="RadhikaChhotai" timestamp="20151022T173936+1100"?>,<?oxy_insert_end?>
        over a time interval of length t years, there are n peaks over the threshold
          q<subscript>o</subscript>. This defines the POT time series
          {q<subscript>1</subscript>,…,q<subscript>n</subscript>}<?oxy_insert_start author="RadhikaChhotai" timestamp="20151022T174105+1100"?>,<?oxy_insert_end?>
        which consists of n independent realisations sampled from the pdf
          p(q|q&gt;q<subscript>o</subscript>).</para>

      <para>Let w be the maximum value in the POT time series; that is,</para>

      <para>w = max
      {q<subscript>1</subscript>,…,q<subscript>n</subscript>}</para>

      <para>For w to be the maximum value, each peak within the POT series
      must be less than or equal to w. In probability theory this condition is
      expressed by the compound event consisting of the intersection of the
      following n events:</para>

      <equation xml:id="b3_ch2_e_0h1bg">
        <m:math display="block">
          <m:mrow>
            <m:mrow>
              <m:mo>{</m:mo>

              <m:mrow>
                <m:mrow>
                  <m:mo>(</m:mo>

                  <m:mrow>
                    <m:msub>
                      <m:mi>q</m:mi>

                      <m:mi>1</m:mi>
                    </m:msub>

                    <m:mo>≤ w</m:mo>
                  </m:mrow>

                  <m:mo>)</m:mo>
                </m:mrow>

                <m:mo>⋂</m:mo>

                <m:mrow>
                  <m:mo>(</m:mo>

                  <m:mrow>
                    <m:msub>
                      <m:mi>q</m:mi>

                      <m:mi>2</m:mi>
                    </m:msub>

                    <m:mo>≤ w</m:mo>
                  </m:mrow>

                  <m:mo>)</m:mo>
                </m:mrow>

                <m:mo>⋂</m:mo>

                <m:mi>....</m:mi>

                <m:mo>⋂</m:mo>

                <m:mrow>
                  <m:mo>(</m:mo>

                  <m:mrow>
                    <m:msub>
                      <m:mi>q</m:mi>

                      <m:mi>n</m:mi>
                    </m:msub>

                    <m:mo>≤ w</m:mo>
                  </m:mrow>

                  <m:mo>)</m:mo>
                </m:mrow>
              </m:mrow>

              <m:mo>}</m:mo>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>Because the peaks are assumed to be statistically independent, the
      probability of the compound event is the product of the probabilities of
      the individual events. Therefore the probability that the random
      variable W<inlineequation>
          <m:math display="inline">
            <m:mi>≤</m:mi>
          </m:math>
        </inlineequation> w in a POT series with n events occurring over the
      interval t simplifies to:</para>

      <equation xml:id="b3_ch2_e_2uebb">
        <m:math display="block">
          <m:mrow>
            <m:mrow>
              <m:mi>P(W≤w∣n,t)</m:mi>
            </m:mrow>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mi>P[(</m:mi>

              <m:msub>
                <m:mi>x</m:mi>

                <m:mi>i</m:mi>
              </m:msub>

              <m:mo>≤</m:mo>

              <m:mo>w)</m:mo>

              <m:mrow>
                <m:mo>⋂</m:mo>

                <m:mo>.... ⋂</m:mo>

                <m:mo>(</m:mo>

                <m:msub>
                  <m:mi>q</m:mi>

                  <m:mi>n</m:mi>
                </m:msub>
              </m:mrow>

              <m:mo>≤</m:mo>

              <m:mi>w)]</m:mi>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <equation xml:id="b3_ch2_e_abslg">
        <m:math display="block">
          <m:mrow>
            <m:mo>=</m:mo>

            <m:mrow>
              <m:mi>P(</m:mi>

              <m:msub>
                <m:mi>q</m:mi>

                <m:mi>1</m:mi>
              </m:msub>

              <m:mi>≤w)P(</m:mi>

              <m:msub>
                <m:mi>q</m:mi>

                <m:mi>2</m:mi>
              </m:msub>

              <m:mi>≤</m:mi>

              <m:mo>w)....P(</m:mo>

              <m:mrow>
                <m:msub>
                  <m:mi>q</m:mi>

                  <m:mi>n</m:mi>
                </m:msub>

                <m:mo>≤ w )</m:mo>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <equation xml:id="b3_ch2_e_uxlp2">
        <m:math display="block">
          <m:mrow>
            <m:mi>=</m:mi>

            <m:mo>P</m:mo>

            <m:mrow>
              <m:mo>(</m:mo>

              <m:mi>q≤w</m:mi>

              <m:mo>)</m:mo>
            </m:mrow>

            <m:mo>ⁿ</m:mo>
          </m:mrow>
        </m:math>
      </equation>

      <para>The number of POT events n occurring over an interval t is random.
      Suppose that the random variable n follows a Poisson distribution with ν
      being the average number of POT events per year; that is:</para>

      <equation xml:id="b3_ch2_e_0lceb">
        <m:math display="block">
          <m:mrow>
            <m:mi>P(n|ν,t)</m:mi>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mfrac>
                <m:mrow>
                  <m:msup>
                    <m:mi>(νt)</m:mi>

                    <m:mi>n</m:mi>
                  </m:msup>

                  <m:mrow>
                    <m:mi>exp</m:mi>

                    <m:mo>(-νt)</m:mo>
                  </m:mrow>
                </m:mrow>

                <m:mi>n!</m:mi>
              </m:mfrac>

              <m:mo>, n =</m:mo>

              <m:mi>0,1,2....</m:mi>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>Application of the total probability theorem yields the
      distribution of the largest peak magnitude over the time interval with
      length t:</para>

      <equation xml:id="b3_ch2_e_zdrjq">
        <m:math display="block">
          <m:mrow>
            <m:mi>P(W≤w|t)</m:mi>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:mrow>
                <m:mrow>
                  <m:munderover>
                    <m:mo>∑</m:mo>

                    <m:mi>n=0</m:mi>

                    <m:mi>∞</m:mi>
                  </m:munderover>

                  <m:mi>P(W≤w|n,t)P(n|ν,t)</m:mi>
                </m:mrow>
              </m:mrow>

              <m:mo>=</m:mo>

              <m:mi>exp[-(νt)P(q&gt;w)</m:mi>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>where P(W<inlineequation>
          <m:math display="inline">
            <m:mi>≤</m:mi>
          </m:math>
        </inlineequation>w|t) is the probability that the largest peak over
      time interval t is less than or equal to w. When the time interval t is
      set to one year, <xref linkend="b3_ch2_e_zdrjq"/> defines the
      distribution of the AM series.</para>

      <para>ARR defines Annual Exceedance Probability as:</para>

      <equation xml:id="b3_ch2_e_w9t35">
        <m:math display="block">
          <m:mrow>
            <m:mi>AEP(w)</m:mi>

            <m:mo>=</m:mo>

            <m:mi>1-P(W≤w| t=1)</m:mi>
          </m:mrow>
        </m:math>
      </equation>

      <para>where AEP(w) is the probability of the largest peak in a year
      exceeding magnitude w.</para>
    </section>

    <section xml:id="b3_ch2_s_fzc71">
      <title>Exceedances per Year (EY)</title>

      <para>We now derive the probability distribution of the time to the next
      flood peak which has a magnitude in excess of w. With regard to <xref
      linkend="b3_ch2_e_zdrjq"/>, if the largest peak during the interval t is
      less than or equal to w, then the time to the next peak with magnitude
      in excess of w must be greater than t. It therefore follows that the
      distribution of the time to the next peak with magnitude exceeding w
      is</para>

      <equation xml:id="b3_ch2_e_30300">
        <m:math display="block">
          <m:mrow>
            <m:mtext>P(Time to next peak exceeding w≤t)</m:mtext>

            <m:mo>=</m:mo>

            <m:mi>1- exp[-νP(q&gt;w)t]</m:mi>
          </m:mrow>
        </m:math>
      </equation>

      <equation xml:id="b3_ch2_e_28swr">
        <m:math display="block">
          <m:mrow>
            <m:mo>=</m:mo>

            <m:mi>1-exp[-EY(w)t]</m:mi>
          </m:mrow>
        </m:math>
      </equation>

      <para>This is
        <?oxy_delete author="RadhikaChhotai" timestamp="20151022T174112+1100" content="recognized"?><?oxy_insert_start author="RadhikaChhotai" timestamp="20151022T174112+1100"?>recognised<?oxy_insert_end?>
        as an exponential distribution with parameter vP(q&gt;w) which is the expected number of
        peaks exceeding w per year.</para>

      <para>ARR defines this parameter as EY(w) which stands for Exceedances
      per Year, but more strictly, is the expected number of peaks that exceed
      w in a year.</para>
    </section>

    <section xml:id="b3_ch2_s_syine">
      <title>Linking AEP and EY</title>

      <para>If we select a particular peak magnitude w, combining <xref
      linkend="b3_ch2_e_zdrjq"/>, <xref linkend="b3_ch2_e_w9t35"/> and <xref
      linkend="b3_ch2_e_30300"/> yields the following relationship between
      EY(w) and AEP(w):</para>

      <equation xml:id="b3_ch2_e_yf64d">
        <m:math display="block">
          <m:mrow>
            <m:mi>AEP(w)</m:mi>

            <m:mo>=</m:mo>

            <m:mi>1 - P (W≤w | t=1 )</m:mi>
          </m:mrow>
        </m:math>
      </equation>

      <equation xml:id="b3_ch2_e_gbvhs">
        <m:math display="block">
          <m:mrow>
            <m:mo>=</m:mo>

            <m:mi>1- exp[-νP(q&gt;w)]</m:mi>
          </m:mrow>
        </m:math>
      </equation>

      <equation xml:id="b3_ch2_e_vjpol">
        <m:math display="block">
          <m:mi>= 1 - exp[-EY(w)]</m:mi>
        </m:math>
      </equation>

      <para>If we express AEP(w) as 1/Y(w) then <xref
      linkend="b3_ch2_e_yf64d"/> can be rewritten as:</para>

      <equation xml:id="b3_ch2_e_v4tbm">
        <m:math display="block">
          <m:mrow>
            <m:mi>EY(w)</m:mi>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:msub>
                <m:mi>-log</m:mi>

                <m:mi>e</m:mi>
              </m:msub>

              <m:mo>[1-AEP(w)]</m:mo>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <equation xml:id="b3_ch2_e_tftt7">
        <m:math display="block">
          <m:mrow>
            <m:mo>=</m:mo>

            <m:mrow>
              <m:msub>
                <m:mi>-log</m:mi>

                <m:mi>e</m:mi>
              </m:msub>

              <m:mrow>
                <m:mo>[</m:mo>

                <m:mrow>
                  <m:mi>1</m:mi>

                  <m:mo>-</m:mo>

                  <m:mfrac>
                    <m:mi>1</m:mi>

                    <m:mi>Y(w)</m:mi>
                  </m:mfrac>
                </m:mrow>

                <m:mo>]</m:mo>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation>

      <para>This relationship assumes peaks in the POT series are
      statistically independent and that there is no seasonality in the sense
      that the probability density of the POT peak above a threshold
      p(q|q&gt;q<subscript>o</subscript>) does not change over the year. While
      the no-seasonality assumption appears questionable on first inspection,
      in practice the threshold q<subscript>0</subscript> is selected so that
      the expected number of peaks exceeding the threshold
      q<subscript>0</subscript> in any year is of the order of 1. This is done
      to ensure the POT peaks are genuine floods and statistically
      independent. As a consequence of the high threshold selected in
      practice, the impact of seasonality is diminished.</para>
    </section>
  </section>

  <section xml:id="b3_ch2_s_ktbsy">
    <title>Box 2: Formal Definition of Zero-Threshold Mixture
    Distribution</title>

    <para>The zero-threshold mixture model has a distribution function:</para>

    <equation xml:id="b3_ch2_e_6bhbp">
      <m:math display="block">
        <m:mrow>
          <m:mi>P(Q≤q|θ)</m:mi>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mo>{</m:mo>

            <m:mtable>
              <m:mtr>
                <m:mtd>
                  <m:mrow>
                    <m:msub>
                      <m:mi>P</m:mi>

                      <m:mi>0</m:mi>
                    </m:msub>

                    <m:mo>if q =</m:mo>

                    <m:msub>
                      <m:mi>q</m:mi>

                      <m:mi>0</m:mi>
                    </m:msub>
                  </m:mrow>
                </m:mtd>
              </m:mtr>

              <m:mtr>
                <m:mtd>
                  <m:mrow>
                    <m:msub>
                      <m:mi>P</m:mi>

                      <m:mi>0</m:mi>
                    </m:msub>

                    <m:mrow>
                      <m:mi>+(1-</m:mi>

                      <m:msub>
                        <m:mi>P</m:mi>

                        <m:mi>0</m:mi>
                      </m:msub>

                      <m:mi>)</m:mi>

                      <m:mfrac>
                        <m:mrow>
                          <m:mi>P(Q≤q∣</m:mi>

                          <m:mo>θ) -</m:mo>

                          <m:mi>P(Q≤</m:mi>

                          <m:msub>
                            <m:mi>q</m:mi>

                            <m:mi>0</m:mi>
                          </m:msub>

                          <m:mi>∣θ)</m:mi>
                        </m:mrow>

                        <m:mrow>
                          <m:mi>P(Q&gt;</m:mi>

                          <m:msub>
                            <m:mi>q</m:mi>

                            <m:mi>0</m:mi>
                          </m:msub>

                          <m:mo>|</m:mo>

                          <m:mi>θ)</m:mi>
                        </m:mrow>
                      </m:mfrac>

                      <m:mrow>
                        <m:mi>if q&gt;</m:mi>

                        <m:msub>
                          <m:mi>q</m:mi>

                          <m:mi>0</m:mi>
                        </m:msub>
                      </m:mrow>
                    </m:mrow>
                  </m:mrow>
                </m:mtd>
              </m:mtr>
            </m:mtable>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>where q<subscript>0</subscript> is the zero-threshold flow,
    P<subscript>0</subscript> is the probability of the AM peak equaling
    q<subscript>0</subscript> and P(Q<inlineequation>
        <m:math display="inline">
          <m:mi>≤</m:mi>
        </m:math>
      </inlineequation>q|θ) is a probability model such as described in <xref
    linkend="b3_ch2_t_s5j9j"/>.</para>

    <para>The pdf of the mixture model can be expressed using the generalized
    probability density which allows the random variable to take discrete
    values as well as continuous values:</para>

    <equation xml:id="b3_ch2_e_3izqm">
      <m:math display="block">
        <m:mi>P(q|θ)</m:mi>

        <m:mo>=</m:mo>

        <m:mrow>
          <m:mo>{</m:mo>

          <m:mtable>
            <m:mtr>
              <m:mtd>
                <m:mrow>
                  <m:msub>
                    <m:mi>P</m:mi>

                    <m:mi>0</m:mi>
                  </m:msub>

                  <m:mo>if q =</m:mo>

                  <m:msub>
                    <m:mi>q</m:mi>

                    <m:mi>0</m:mi>
                  </m:msub>
                </m:mrow>
              </m:mtd>
            </m:mtr>

            <m:mtr>
              <m:mtd>
                <m:mrow>
                  <m:mrow>
                    <m:mfrac>
                      <m:mrow>
                        <m:mi>1</m:mi>

                        <m:mo>-</m:mo>

                        <m:msub>
                          <m:mi>P</m:mi>

                          <m:mi>0</m:mi>
                        </m:msub>
                      </m:mrow>

                      <m:mrow>
                        <m:mi>P(q&gt;</m:mi>

                        <m:msub>
                          <m:mi>q</m:mi>

                          <m:mi>0</m:mi>
                        </m:msub>

                        <m:mo>|</m:mo>

                        <m:mi>θ)</m:mi>
                      </m:mrow>
                    </m:mfrac>

                    <m:mrow>
                      <m:mrow>
                        <m:mrow>
                          <m:mi>p(q|θ)/(q,</m:mi>

                          <m:msub>
                            <m:mi>q</m:mi>

                            <m:mi>0</m:mi>
                          </m:msub>
                        </m:mrow>

                        <m:mo>) if q&gt;</m:mo>
                      </m:mrow>

                      <m:msub>
                        <m:mi>q</m:mi>

                        <m:mi>0</m:mi>
                      </m:msub>
                    </m:mrow>
                  </m:mrow>
                </m:mrow>
              </m:mtd>
            </m:mtr>
          </m:mtable>
        </m:mrow>
      </m:math>
    </equation>

    <para>where I() is an indicator function defined as:</para>

    <equation xml:id="b3_ch2_e_kwfzv">
      <m:math display="block">
        <m:mrow>
          <m:mrow>
            <m:mi>I(q,</m:mi>

            <m:mrow>
              <m:msub>
                <m:mi>q</m:mi>

                <m:mi>0</m:mi>
              </m:msub>
            </m:mrow>
          </m:mrow>

          <m:mo>) =</m:mo>

          <m:mrow>
            <m:mo>{</m:mo>

            <m:mtable>
              <m:mtr>
                <m:mtd>
                  <m:mrow>
                    <m:mi>1</m:mi>

                    <m:mo>if q&gt;</m:mo>

                    <m:msub>
                      <m:mi>q</m:mi>

                      <m:mi>0</m:mi>
                    </m:msub>
                  </m:mrow>
                </m:mtd>
              </m:mtr>

              <m:mtr>
                <m:mtd>
                  <m:mrow>
                    <m:mi>0</m:mi>

                    <m:mo>if</m:mo>

                    <m:msub>
                      <m:mi>q≤q</m:mi>

                      <m:mi>0</m:mi>
                    </m:msub>
                  </m:mrow>
                </m:mtd>
              </m:mtr>
            </m:mtable>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>
  </section>

  <section xml:id="b3_ch2_s_aa2de">
    <title>Box 3: Likelihood function: No-error-discharge case</title>

    <para>The likelihood function is, by definition, the joint pdf of D given
    the parameter vector <inlineequation>
        <m:math display="inline">
          <m:mi>θ</m:mi>
        </m:math>
      </inlineequation>.</para>

    <para>The likelihood function for the gauged data is the joint pdf of the
    n gauged floods. Given the AM flood peaks are statistically independent,
    the likelihood can be simplified to (Stedinger and Cohn, 1986):</para>

    <equation xml:id="b3_ch2_e_x1evi">
      <m:math display="block">
        <m:mrow>
          <m:mrow>
            <m:mi>p(</m:mi>

            <m:msub>
              <m:mi>q</m:mi>

              <m:mi>1</m:mi>
            </m:msub>

            <m:mi>,...,</m:mi>

            <m:msub>
              <m:mi>q</m:mi>

              <m:mi>n</m:mi>
            </m:msub>

            <m:mi>|θ)</m:mi>
          </m:mrow>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mrow>
              <m:munderover>
                <m:mo>∏</m:mo>

                <m:mi>i=1</m:mi>

                <m:mi>n</m:mi>
              </m:munderover>

              <m:mi>p</m:mi>
            </m:mrow>

            <m:msub>
              <m:mi>(q</m:mi>

              <m:mi>i</m:mi>
            </m:msub>

            <m:mi>|</m:mi>

            <m:mo>θ)</m:mo>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>The likelihood of the binomial censored data relies on the fact that
    the probability of observing exactly x exceedances in n years is given by
    the binomial distribution</para>

    <equation xml:id="b3_ch2_e_bo9zf">
      <m:math display="block">
        <m:mrow>
          <m:mi>P(X|n,∏)=</m:mi>

          <m:msubsup>
            <m:mi>C</m:mi>

            <m:mi>x</m:mi>

            <m:mi>n</m:mi>
          </m:msubsup>

          <m:mi>(1-</m:mi>

          <m:msup>
            <m:mi>∏)</m:mi>

            <m:mi>n-x</m:mi>
          </m:msup>

          <m:msup>
            <m:mi>∏</m:mi>

            <m:mi>x</m:mi>
          </m:msup>
        </m:mrow>
      </m:math>
    </equation>

    <para>where <inlineequation>
        <m:math display="inline">
          <m:mi>Π</m:mi>
        </m:math>
      </inlineequation> is the probability of an exceedance.</para>

    <para>Provided each censoring threshold does not overlap over time with
    any other censoring threshold, the likelihood of the censored data
    becomes:</para>

    <equation xml:id="b3_ch2_e_l0ukb">
      <m:math display="block">
        <m:mrow>
          <m:mi>p(censored data∣</m:mi>

          <m:mrow>
            <m:mi>θ)</m:mi>

            <m:mo>=</m:mo>

            <m:mrow>
              <m:munderover>
                <m:mo>∏</m:mo>

                <m:mi>i=1</m:mi>

                <m:mi>m</m:mi>
              </m:munderover>

              <m:mi>[1-P(Q≤</m:mi>
            </m:mrow>
          </m:mrow>

          <m:msub>
            <m:mi>s</m:mi>

            <m:mi>i</m:mi>
          </m:msub>

          <m:mo>∣θ</m:mo>

          <m:msup>
            <m:mi>)]</m:mi>

            <m:msub>
              <m:mi>a</m:mi>

              <m:mi>0</m:mi>
            </m:msub>
          </m:msup>

          <m:mrow>
            <m:mi>P(Q≤</m:mi>

            <m:msub>
              <m:mi>s</m:mi>

              <m:mi>i</m:mi>
            </m:msub>

            <m:msup>
              <m:mi>∣θ)</m:mi>

              <m:msub>
                <m:mi>b</m:mi>

                <m:mi>0</m:mi>
              </m:msub>
            </m:msup>

            <m:mrow>
              <m:mo>=</m:mo>

              <m:mrow>
                <m:munderover>
                  <m:mo>∏</m:mo>

                  <m:mi>i=1</m:mi>

                  <m:mi>m</m:mi>
                </m:munderover>

                <m:mi>P(</m:mi>
              </m:mrow>
            </m:mrow>

            <m:mrow>
              <m:msub>
                <m:mi>a</m:mi>

                <m:mi>i</m:mi>
              </m:msub>

              <m:msub>
                <m:mi>,b</m:mi>

                <m:mi>i</m:mi>
              </m:msub>

              <m:mi>|</m:mi>

              <m:msub>
                <m:mi>s</m:mi>

                <m:mi>i</m:mi>
              </m:msub>

              <m:mi>,</m:mi>
            </m:mrow>
          </m:mrow>

          <m:mi>θ)</m:mi>
        </m:mrow>
      </m:math>
    </equation>

    <para>where
    P(a<subscript>i</subscript>,b<subscript>i</subscript>|s<subscript>i</subscript>,<inlineequation>
        <m:math display="inline">
          <m:mi>θ</m:mi>
        </m:math>
      </inlineequation>) is the binomial probability of observing exactly
    a<subscript>i</subscript> exceedances above the threshold discharge
    s<subscript>i</subscript> in
    (a<subscript>i</subscript>+b<subscript>i</subscript>).</para>
  </section>

  <section xml:id="b3_ch2_s_vyzbz">
    <title>Box 4: Likelihood function: Error-in-discharge case</title>

    <para><xref linkend="b3_ch2_f_6qnp5"/> presents a rating error space
    diagram. In zone 1 (<xref linkend="b3_ch2_f_6qnp5"/>), the interpolation
    zone it is assumed the rating error multiplier e<subscript>1</subscript>
    equals 1 – that is, errors within the rated part of the rating curve are
    deemed negligible. As a result the estimated discharge w equals the true
    discharge q. However, in zone 2, the extension zone, the rating error
    multiplier e<subscript>2</subscript> is assumed to be a random variable
    with mean of 1. The anchor point
    (q<subscript>1</subscript>,w<subscript>1</subscript>) separates the
    interpolation and extension zones. The rating error model can represented
    mathematically as:</para>

    <equation xml:id="b3_ch2_e_bvmht">
      <m:math display="block">
        <m:mrow>
          <m:mi>w</m:mi>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mo>{</m:mo>

            <m:mtable>
              <m:mtr>
                <m:mtd>
                  <m:mrow>
                    <m:mi>q</m:mi>

                    <m:mrow>
                      <m:msub>
                        <m:mi>if q ≤x</m:mi>

                        <m:mi>i</m:mi>
                      </m:msub>
                    </m:mrow>
                  </m:mrow>
                </m:mtd>
              </m:mtr>

              <m:mtr>
                <m:mtd>
                  <m:mrow>
                    <m:mrow>
                      <m:msub>
                        <m:mi>w</m:mi>

                        <m:mi>1</m:mi>
                      </m:msub>

                      <m:mo>+</m:mo>

                      <m:msub>
                        <m:mi>e</m:mi>

                        <m:mi>2</m:mi>
                      </m:msub>

                      <m:mo>(q-</m:mo>

                      <m:msub>
                        <m:mi>q</m:mi>

                        <m:mi>1</m:mi>
                      </m:msub>
                    </m:mrow>

                    <m:mrow>
                      <m:mi>)</m:mi>

                      <m:mo>if q&gt;</m:mo>

                      <m:msub>
                        <m:mi>q</m:mi>

                        <m:mi>1</m:mi>
                      </m:msub>
                    </m:mrow>
                  </m:mrow>
                </m:mtd>
              </m:mtr>
            </m:mtable>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>The rating error multiplier e<subscript>2</subscript> is sampled
    only once at the time of extending the rating curve. Therefore, all flood
    discharge estimates exceeding the anchor value of
    q<subscript>1</subscript> (which equals w<subscript>1</subscript>) are
    corrupted by the same rating error multiplier. It must be stressed that
    the error e<subscript>2</subscript> is not known – at best, only its
    probability distribution can be estimated. For practical applications one
    can assume e<subscript>2</subscript> is distributed as either a log-normal
    or normal distribution with mean 1 and standard deviation <inlineequation>
        <m:math display="inline">
          <m:msub>
            <m:mi>σ</m:mi>

            <m:mi>2</m:mi>
          </m:msub>
        </m:math>
      </inlineequation>.</para>

    <figure xml:id="b3_ch2_f_6qnp5">
      <title>Rating error multiplier space diagram for rating curve</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3009.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>Data are assigned to each of the two zones, i=1,2, in the rating
    error space diagram. The rating error multiplier standard deviation for
    the extension zone <inlineequation>
        <m:math display="inline">
          <m:msub>
            <m:mi>σ</m:mi>

            <m:mi>2</m:mi>
          </m:msub>
        </m:math>
      </inlineequation> is assigned a value with <inlineequation>
        <m:math display="inline">
          <m:mrow>
            <m:msub>
              <m:mi>σ</m:mi>

              <m:mi>1</m:mi>
            </m:msub>

            <m:mo>= 0</m:mo>
          </m:mrow>
        </m:math>
      </inlineequation>. There are n<subscript>i</subscript> annual flood peak
    estimates w<subscript>ji</subscript> satisfying the zone constraint
    w<subscript>i-1</subscript> ≤ w<subscript>ji</subscript> &lt;
    w<subscript>i</subscript>, j=1,..,n<subscript>i</subscript> where
    w<subscript>0</subscript>=0 and w<subscript>2</subscript>= <inlineequation>
        <m:math display="inline">
          <m:mi>∞</m:mi>
        </m:math>
      </inlineequation>. In addition, there are m<subscript>i</subscript>
    threshold discharge estimates w<subscript>ji</subscript> for which there
    are a<subscript>ji</subscript> exceedances in
    (a<subscript>ji</subscript>+b<subscript>ji</subscript>) years,
    j=1,..,m<subscript>i</subscript>. Collectively this data is represented
    as:</para>

    <equation xml:id="b3_ch2_e_68r89">
      <m:math display="block">
        <m:mrow>
          <m:mi>D</m:mi>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:msub>
              <m:mi>{D</m:mi>

              <m:mi>i</m:mi>
            </m:msub>

            <m:mo>, i=1,2}</m:mo>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <equation xml:id="b3_ch2_e_eyubb">
      <m:math display="block">
        <m:mrow>
          <m:mo>=</m:mo>

          <m:mrow>
            <m:msub>
              <m:mi>{[w</m:mi>

              <m:mi>ji</m:mi>
            </m:msub>

            <m:mo>,j=1,...</m:mo>

            <m:msub>
              <m:mi>n</m:mi>

              <m:mi>i</m:mi>
            </m:msub>

            <m:msub>
              <m:mi>;w</m:mi>

              <m:mi>ji</m:mi>
            </m:msub>

            <m:msub>
              <m:mi>,a</m:mi>

              <m:mi>ji</m:mi>
            </m:msub>

            <m:msub>
              <m:mi>,b</m:mi>

              <m:mi>ji</m:mi>
            </m:msub>

            <m:mrow>
              <m:mi>,j=1,...,</m:mi>

              <m:msub>
                <m:mi>m</m:mi>

                <m:mi>i</m:mi>
              </m:msub>

              <m:mi>],i=1,2}</m:mi>
            </m:mrow>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>Following Kuczera (1999) it can be shown for the two-zone rating
    error model of <xref linkend="b3_ch2_f_6qnp5"/> the likelihood reduces
    to:</para>

    <equation xml:id="b3_ch2_e_y1vv5">
      <m:math display="block">
        <m:mrow>
          <m:mrow>
            <m:mi>p(</m:mi>

            <m:msub>
              <m:mi>D</m:mi>

              <m:mi>1</m:mi>
            </m:msub>

            <m:msub>
              <m:mi>,D</m:mi>

              <m:mi>2</m:mi>
            </m:msub>

            <m:mrow>
              <m:mi>∣</m:mi>

              <m:msub>
                <m:mi>θ</m:mi>

                <m:mi>1</m:mi>
              </m:msub>
            </m:mrow>

            <m:mrow>
              <m:msub>
                <m:mi>,σ</m:mi>

                <m:mi>2</m:mi>
              </m:msub>

              <m:mo>)</m:mo>
            </m:mrow>
          </m:mrow>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mrow>
              <m:mi>p(</m:mi>

              <m:msub>
                <m:mi>D</m:mi>

                <m:mi>1</m:mi>
              </m:msub>

              <m:msub>
                <m:mi>,e</m:mi>

                <m:mi>1</m:mi>
              </m:msub>

              <m:mo>=1|θ</m:mo>

              <m:mi>)</m:mi>
            </m:mrow>

            <m:mrow>
              <m:mrow>
                <m:mo>[</m:mo>

                <m:mrow>
                  <m:mrow>
                    <m:munderover>
                      <m:mo>∫p(</m:mo>

                      <m:mi>0</m:mi>

                      <m:mi mathvariant="normal">∞</m:mi>
                    </m:munderover>
                  </m:mrow>

                  <m:msub>
                    <m:mi>D</m:mi>

                    <m:mi>2</m:mi>
                  </m:msub>

                  <m:msub>
                    <m:mi>,e</m:mi>

                    <m:mi>2</m:mi>
                  </m:msub>

                  <m:mo>| θ)g(</m:mo>

                  <m:mrow>
                    <m:msub>
                      <m:mi>e</m:mi>

                      <m:mi>2</m:mi>
                    </m:msub>

                    <m:msub>
                      <m:mi>|σ</m:mi>

                      <m:mi>2</m:mi>
                    </m:msub>
                  </m:mrow>

                  <m:msub>
                    <m:mi>)de</m:mi>

                    <m:mi>2</m:mi>
                  </m:msub>
                </m:mrow>

                <m:mo>]</m:mo>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>where</para>

    <equation xml:id="b3_ch2_e_pdt6x">
      <m:math display="block">
        <m:mrow>
          <m:mrow>
            <m:mi>p(</m:mi>

            <m:msub>
              <m:mi>D</m:mi>

              <m:mi>i</m:mi>
            </m:msub>

            <m:msub>
              <m:mi>,e</m:mi>

              <m:mi>i</m:mi>
            </m:msub>

            <m:mo>|</m:mo>

            <m:mi>θ)</m:mi>
          </m:mrow>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mrow>
              <m:munderover>
                <m:mo>∏</m:mo>

                <m:mi>j=1</m:mi>

                <m:msub>
                  <m:mi>n</m:mi>

                  <m:mi>i</m:mi>
                </m:msub>
              </m:munderover>

              <m:mfrac>
                <m:mi>1</m:mi>

                <m:msub>
                  <m:mi>e</m:mi>

                  <m:mi>i</m:mi>
                </m:msub>
              </m:mfrac>
            </m:mrow>

            <m:mo>p(</m:mo>

            <m:msub>
              <m:mi>q</m:mi>

              <m:mi>i-1</m:mi>
            </m:msub>

            <m:mo>+</m:mo>

            <m:mrow>
              <m:mfrac>
                <m:mrow>
                  <m:msub>
                    <m:mi>w</m:mi>

                    <m:mi>ji</m:mi>
                  </m:msub>

                  <m:mo>-</m:mo>

                  <m:msub>
                    <m:mi>w</m:mi>

                    <m:mi>i-1</m:mi>
                  </m:msub>
                </m:mrow>

                <m:msub>
                  <m:mi>e</m:mi>

                  <m:mi>i</m:mi>
                </m:msub>
              </m:mfrac>

              <m:mo>| θ)</m:mo>

              <m:mrow>
                <m:munderover>
                  <m:mo>∏</m:mo>

                  <m:mi>j=1</m:mi>

                  <m:msub>
                    <m:mi>m</m:mi>

                    <m:mi>i</m:mi>
                  </m:msub>
                </m:munderover>

                <m:mi>P[</m:mi>
              </m:mrow>

              <m:msub>
                <m:mi>a</m:mi>

                <m:mi>ji</m:mi>
              </m:msub>

              <m:msub>
                <m:mi>,b</m:mi>

                <m:mi>ji</m:mi>
              </m:msub>

              <m:msub>
                <m:mi>|q</m:mi>

                <m:mi>i-1</m:mi>
              </m:msub>

              <m:mi>+</m:mi>
            </m:mrow>

            <m:mfrac>
              <m:mrow>
                <m:msub>
                  <m:mi>w</m:mi>

                  <m:mi>ji</m:mi>
                </m:msub>

                <m:mo>-</m:mo>

                <m:msub>
                  <m:mi>w</m:mi>

                  <m:mi>i-1</m:mi>
                </m:msub>
              </m:mrow>

              <m:msub>
                <m:mi>e</m:mi>

                <m:mi>i</m:mi>
              </m:msub>
            </m:mfrac>

            <m:mi>,θ]</m:mi>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>g(e<subscript>i</subscript>|<inlineequation>
        <m:math display="inline">
          <m:msub>
            <m:mi>σ</m:mi>

            <m:mi>i</m:mi>
          </m:msub>
        </m:math>
      </inlineequation>) is the rating error multiplier pdf with mean 1 and
    standard deviation <inlineequation>
        <m:math display="inline">
          <m:msub>
            <m:mi>σ</m:mi>

            <m:mi>i</m:mi>
          </m:msub>
        </m:math>
      </inlineequation> and P(a,b|s,<inlineequation>
        <m:math display="inline">
          <m:mi>θ</m:mi>
        </m:math>
      </inlineequation>) is the binomial probability of observing exactly a
    exceedances above the threshold discharge s in (a+b). This is a complex
    expression which can only be evaluated numerically. However, it makes the
    fullest use of information on annual flood peaks and binomial-censored
    data in the presence of rating curve error. <xref
    linkend="b3_ch2_s_zlx6z"/> offers limited guidance on the choice of
    <inlineequation>
        <m:math display="inline">
          <m:msub>
            <m:mi>σ</m:mi>

            <m:mi>2</m:mi>
          </m:msub>
        </m:math>
      </inlineequation>.</para>
  </section>

  <section xml:id="b3_ch2_s_j8hj6">
    <title>Box 5: Importance sampling from the posterior distribution</title>

    <para>Importance sampling is a widely used method (Gelman <emphasis>et
    al</emphasis>., 1995) for sampling parameters from a target probability
    model for which there is no algorithm to draw random samples. The basic
    idea is to sample from a probability model for which a sampling algorithm
    exists – the probability model is called the importance distribution and
    the samples are called particles. The particles are then weighted so that
    they represent samples from the target distribution. The closer the
    importance distribution approximates the target, the more efficient the
    sampling.</para>

    <para>Three steps are involved:</para>

    <para><emphasis>Step 1:</emphasis> Find most probable parameters of the
    target distribution</para>

    <para>Any robust search method can be used to locate the value of <inlineequation>
        <m:math display="inline">
          <m:mi>θ</m:mi>
        </m:math>
      </inlineequation><?oxy_insert_start author="RadhikaChhotai" timestamp="20151022T174306+1100"?>,<?oxy_insert_end?>
      which
      <?oxy_delete author="RadhikaChhotai" timestamp="20151022T174259+1100" content="maximizes"?><?oxy_insert_start author="RadhikaChhotai" timestamp="20151022T174259+1100"?>maximises<?oxy_insert_end?>
      the logarithm of the posterior probability density; that is,</para>

    <equation xml:id="b3_ch2_e_bqy9q">
      <m:math display="block">
        <m:mrow>
          <m:mi>θ</m:mi>

          <m:mo>←</m:mo>

          <m:mi>max</m:mi>

          <m:mo>log</m:mo>

          <m:mi>p</m:mi>

          <m:mo>(θ|D)</m:mo>
        </m:mrow>
      </m:math>
    </equation>

    <para>where <inlineequation>
        <m:math display="inline">
          <m:mi>θ</m:mi>
        </m:math>
      </inlineequation> is the most probable value of <inlineequation>
        <m:math display="inline">
          <m:mi>θ</m:mi>
        </m:math>
      </inlineequation>. The shuffled complex evolution algorithm of Duan
    <emphasis>et al</emphasis>. (1992) is a recommended search method.</para>

    <para><emphasis>Step 2: </emphasis>Obtain the importance distribution using a
      multi<?oxy_insert_start author="RadhikaChhotai" timestamp="20151022T174317+1100"?>-<?oxy_insert_end?>normal
      approximation to the target distribution</para>

    <para>Almost always, the log of posterior pdf <inlineequation>
        <m:math display="inline">
          <m:mi>p(θ|D)</m:mi>
        </m:math>
      </inlineequation> can be approximated by a second-order Taylor series
    expansion about the most probable parameter to yield the multivariate
    normal approximation</para>

    <equation xml:id="b3_ch2_e_ee78h">
      <m:math display="block">
        <m:mrow>
          <m:mi>θ|</m:mi>

          <m:mo>D~N(θ</m:mo>

          <m:mi>,</m:mi>

          <m:mo>Σ</m:mo>

          <m:mi>)</m:mi>
        </m:mrow>
      </m:math>
    </equation>

    <para>where θ is interpreted as the mean and the posterior covariance
    <inlineequation>
        <m:math display="inline">
          <m:mi>Σ</m:mi>
        </m:math>
      </inlineequation> is defined as the inverse of the Hessian</para>

    <equation xml:id="b3_ch2_e_u721b">
      <m:math display="block">
        <m:mrow>
          <m:mi>Σ</m:mi>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:msup>
              <m:mrow>
                <m:mo>(</m:mo>

                <m:mrow>
                  <m:mi>-</m:mi>

                  <m:mfrac>
                    <m:mrow>
                      <m:msup>
                        <m:mi>δ</m:mi>

                        <m:mi>2</m:mi>
                      </m:msup>

                      <m:msub>
                        <m:mi>log</m:mi>

                        <m:mi>e</m:mi>
                      </m:msub>

                      <m:mi>p(θ</m:mi>

                      <m:mo>| D)</m:mo>
                    </m:mrow>

                    <m:mrow>
                      <m:msup>
                        <m:mi>δ</m:mi>

                        <m:mi>2</m:mi>
                      </m:msup>

                      <m:mi>θ</m:mi>
                    </m:mrow>
                  </m:mfrac>
                </m:mrow>

                <m:mo>)</m:mo>
              </m:mrow>

              <m:mi>-1</m:mi>
            </m:msup>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>An adaptive difference scheme should be used to evaluate the
    Hessian. Particular care needs to be exercised when selecting finite
    difference perturbations for the GEV and LPIII distributions when upper or
    lower bounds are close to the observed data.</para>

    <para><emphasis>Step 3:</emphasis> Importance sampling of target
    distribution</para>

    <para>The importance sampling algorithm proceeds as follows:</para>

    <orderedlist>
      <listitem>
        <para>Sample N particles according to <inlineequation>
            <m:math display="inline">
              <m:msub>
                <m:mi>θ</m:mi>
                <m:mi>i</m:mi>
              </m:msub>
              <m:mo>←</m:mo>
              <m:msub>
                <m:mi>p</m:mi>
                <m:mi>N</m:mi>
              </m:msub>
              <m:mo>(θ)</m:mo>
              <m:mi>,i=1,...,N</m:mi>
              <m:mi/>
            </m:math>
          </inlineequation>where pN(<inlineequation>
            <m:math display="inline">
              <m:mi>θ</m:mi>
            </m:math>
          </inlineequation>) is the pdf of the
          multi<?oxy_insert_start author="RadhikaChhotai" timestamp="20151022T174335+1100"?>-<?oxy_insert_end?>normal
          approximation obtained in Step 2.</para>
      </listitem>

      <listitem>
        <para>Calculate particle probability weights according to
        <inlineequation>
            <m:math display="inline">
              <m:mrow>
                <m:mi>P(</m:mi>

                <m:msub>
                  <m:mi>θ)</m:mi>

                  <m:mi>i</m:mi>
                </m:msub>
              </m:mrow>

              <m:mo>=</m:mo>

              <m:mfrac>
                <m:mrow>
                  <m:msub>
                    <m:mi>p(θ</m:mi>

                    <m:mi>i</m:mi>
                  </m:msub>

                  <m:mrow>
                    <m:mi>|</m:mi>

                    <m:mo>D)</m:mo>
                  </m:mrow>
                </m:mrow>

                <m:mrow>
                  <m:msub>
                    <m:mi>p</m:mi>

                    <m:mi>N</m:mi>
                  </m:msub>

                  <m:mrow>
                    <m:msub>
                      <m:mi>(θ</m:mi>

                      <m:mi>i</m:mi>
                    </m:msub>

                    <m:mo>)</m:mo>
                  </m:mrow>
                </m:mrow>
              </m:mfrac>
            </m:math>
          </inlineequation>,i=1,...,N</para>
      </listitem>

      <listitem>
        <para>Scale the particle weights so they sum to 1.</para>
      </listitem>
    </orderedlist>
  </section>

  <section xml:id="b3_ch2_s_l6g7s">
    <title>Box 6: LH moments for fitting the GEV distribution</title>

    <para>LH moments are based on linear combinations of higher
    order-statistics. A shift parameter <inlineequation>
        <m:math display="inline">
          <m:mi>η = 0,1,2,3...</m:mi>
        </m:math>
      </inlineequation> is introduced to give more emphasis on higher ranked
    flows. LH moments are defined as:</para>

    <equation xml:id="b3_ch2_e_9ipt3">
      <m:math display="block">
        <m:mrow>
          <m:msubsup>
            <m:mi>λ</m:mi>

            <m:mi>1</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mi>E[</m:mi>

            <m:mrow>
              <m:msub>
                <m:mi>X</m:mi>

                <m:mi>(η+1):(η+1)</m:mi>
              </m:msub>

              <m:mo>]</m:mo>
            </m:mrow>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <equation xml:id="b3_ch2_e_cpzjs">
      <m:math display="block">
        <m:mrow>
          <m:msubsup>
            <m:mi>λ</m:mi>

            <m:mi>2</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>

          <m:mo>=</m:mo>

          <m:mfrac>
            <m:mi>1</m:mi>

            <m:mi>2</m:mi>
          </m:mfrac>

          <m:mo>E</m:mo>

          <m:mrow>
            <m:mo>[</m:mo>

            <m:mrow>
              <m:msub>
                <m:mi>X</m:mi>

                <m:mi>(η+2):(η+2)</m:mi>
              </m:msub>

              <m:mo>-</m:mo>

              <m:msub>
                <m:mi>X</m:mi>

                <m:mi>(η+1):(η+3)</m:mi>
              </m:msub>
            </m:mrow>

            <m:mo>]</m:mo>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <equation xml:id="b3_ch2_e_vei75">
      <m:math display="block">
        <m:mrow>
          <m:msubsup>
            <m:mi>λ</m:mi>

            <m:mi>3</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mfrac>
              <m:mi>1</m:mi>

              <m:mi>3</m:mi>
            </m:mfrac>

            <m:mo>E</m:mo>

            <m:mrow>
              <m:mo>[</m:mo>

              <m:mrow>
                <m:msub>
                  <m:mi>X</m:mi>

                  <m:mi>(η+3):(η+3)</m:mi>
                </m:msub>

                <m:mo>-</m:mo>

                <m:mrow>
                  <m:msub>
                    <m:mi>2X</m:mi>

                    <m:mi>(η+2):(η+3)</m:mi>
                  </m:msub>

                  <m:mo>+</m:mo>

                  <m:msub>
                    <m:mi>X</m:mi>

                    <m:mi>(η+1):(η+3)</m:mi>
                  </m:msub>
                </m:mrow>
              </m:mrow>

              <m:mo>]</m:mo>
            </m:mrow>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <equation xml:id="b3_ch2_e_of6gn">
      <m:math display="block">
        <m:mrow>
          <m:msubsup>
            <m:mi>λ</m:mi>

            <m:mi>4</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mfrac>
              <m:mi>1</m:mi>

              <m:mi>4</m:mi>
            </m:mfrac>

            <m:mo>E</m:mo>

            <m:mrow>
              <m:mo>[</m:mo>

              <m:mrow>
                <m:msub>
                  <m:mi>X</m:mi>

                  <m:mi>(η+4):(η+4)</m:mi>
                </m:msub>

                <m:mo>-</m:mo>

                <m:mrow>
                  <m:msub>
                    <m:mi>3X</m:mi>

                    <m:mi>(η+3):(η+4)</m:mi>
                  </m:msub>

                  <m:mo>+</m:mo>

                  <m:mrow>
                    <m:msub>
                      <m:mi>3X</m:mi>

                      <m:mi>(η+2):(η+4)</m:mi>
                    </m:msub>

                    <m:mo>-</m:mo>

                    <m:msub>
                      <m:mi>X</m:mi>

                      <m:mi>(η+1):(η+4)</m:mi>
                    </m:msub>
                  </m:mrow>
                </m:mrow>
              </m:mrow>

              <m:mo>]</m:mo>
            </m:mrow>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para><xref linkend="b3_ch2_t_g48se"/> presents the relationship between
    the first four LH moments and the parameters of the GEV and Gumbel
    distributions.</para>

    <table xml:id="b3_ch2_t_g48se">
      <title>LH moments for GEV and Gumbel distributions (from Wang,
      1997)</title>

      <tgroup cols="2">
        <colspec align="center" colwidth="5*"/>

        <colspec colwidth="95*"/>

        <thead>
          <row>
            <entry align="center">Family</entry>

            <entry align="center">LH Moments</entry>
          </row>
        </thead>

        <tbody>
          <row>
            <entry>Generalized Extreme Value (GEV)</entry>

            <entry><inlineequation>
                <m:math display="inline">
                  <m:mtable>
                    <m:mtr>
                      <m:mtd>
                        <m:mrow>
                          <m:msubsup>
                            <m:mi>λ</m:mi>

                            <m:mi>1</m:mi>

                            <m:mi>η</m:mi>
                          </m:msubsup>

                          <m:mo>=</m:mo>

                          <m:mrow>
                            <m:mi>τ +</m:mi>

                            <m:mfrac>
                              <m:mi>α</m:mi>

                              <m:mi>κ</m:mi>
                            </m:mfrac>

                            <m:mi>[1-Γ(1+κ)(η+1</m:mi>

                            <m:msup>
                              <m:mi>)</m:mi>

                              <m:mi>-κ</m:mi>
                            </m:msup>

                            <m:mi>]</m:mi>

                            <m:mrow>
                              <m:mrow>
                                <m:msubsup>
                                  <m:mi>λ</m:mi>

                                  <m:mi>2</m:mi>

                                  <m:mi>η</m:mi>
                                </m:msubsup>

                                <m:mo>=</m:mo>

                                <m:mfrac>
                                  <m:mi>(η+2)αΓ(1+κ)</m:mi>

                                  <m:mi>2!κ</m:mi>
                                </m:mfrac>
                              </m:mrow>

                              <m:mo>[- (η+2</m:mo>

                              <m:msup>
                                <m:mi>)</m:mi>

                                <m:mi>-κ</m:mi>
                              </m:msup>

                              <m:mo>+(η +</m:mo>

                              <m:msup>
                                <m:mi>1 )</m:mi>

                                <m:mi>-κ</m:mi>
                              </m:msup>
                            </m:mrow>
                          </m:mrow>
                        </m:mrow>
                      </m:mtd>
                    </m:mtr>

                    <m:mtr>
                      <m:mtd>
                        <m:mrow>
                          <m:msubsup>
                            <m:mi>λ</m:mi>

                            <m:mi>3</m:mi>

                            <m:mi>η</m:mi>
                          </m:msubsup>

                          <m:mo>=</m:mo>

                          <m:mrow>
                            <m:mfrac>
                              <m:mi>(η+3)αΓ(1+κ)</m:mi>

                              <m:mi>3!κ</m:mi>
                            </m:mfrac>

                            <m:mo>[ - (η+4)(η+</m:mo>

                            <m:msup>
                              <m:mi>3)</m:mi>

                              <m:mi>-κ</m:mi>
                            </m:msup>

                            <m:mo>+2(η+3)(η+2</m:mo>

                            <m:msup>
                              <m:mi>)</m:mi>

                              <m:mi>-κ</m:mi>
                            </m:msup>

                            <m:mo>- (</m:mo>

                            <m:mrow>
                              <m:mi>η+2)(η+1</m:mi>

                              <m:msup>
                                <m:mi>)</m:mi>

                                <m:mi>-κ</m:mi>
                              </m:msup>

                              <m:mi>]</m:mi>
                            </m:mrow>
                          </m:mrow>
                        </m:mrow>
                      </m:mtd>
                    </m:mtr>

                    <m:mtr>
                      <m:mtd>
                        <m:mrow>
                          <m:mtable>
                            <m:mtr>
                              <m:mtd>
                                <m:mrow>
                                  <m:msubsup>
                                    <m:mi>λ</m:mi>

                                    <m:mi>4</m:mi>

                                    <m:mi>η</m:mi>
                                  </m:msubsup>

                                  <m:mo>=</m:mo>

                                  <m:mrow>
                                    <m:mfrac>
                                      <m:mi>(η+4)αΓ(1+κ)</m:mi>

                                      <m:mi>4!κ</m:mi>
                                    </m:mfrac>

                                    <m:mo>[ -(η+6)(η+5)(η+4</m:mo>

                                    <m:msup>
                                      <m:mi>)</m:mi>

                                      <m:mi>-κ</m:mi>
                                    </m:msup>

                                    <m:mo>+3(η+5)(η+4)(η+3</m:mo>

                                    <m:msup>
                                      <m:mi>)</m:mi>

                                      <m:mi>-κ</m:mi>
                                    </m:msup>

                                    <m:mo>]</m:mo>
                                  </m:mrow>
                                </m:mrow>
                              </m:mtd>
                            </m:mtr>

                            <m:mtr>
                              <m:mtd>
                                <m:mrow>
                                  <m:mtable>
                                    <m:mtr>
                                      <m:mtd>
                                        <m:mrow>
                                          <m:mi>-3(η+4)(η+3)(η+2</m:mi>

                                          <m:mrow>
                                            <m:msup>
                                              <m:mi>)</m:mi>

                                              <m:mi>-κ</m:mi>
                                            </m:msup>

                                            <m:mo>+ (η+3)(η+2)(η+1</m:mo>

                                            <m:msup>
                                              <m:mi>)</m:mi>

                                              <m:mi>-κ</m:mi>
                                            </m:msup>
                                          </m:mrow>
                                        </m:mrow>
                                      </m:mtd>
                                    </m:mtr>

                                    <m:mtr>
                                      <m:mtd>
                                        <m:mrow>
                                          <m:mi>where κ≠</m:mi>

                                          <m:mo>0</m:mo>
                                        </m:mrow>
                                      </m:mtd>
                                    </m:mtr>
                                  </m:mtable>
                                </m:mrow>
                              </m:mtd>
                            </m:mtr>
                          </m:mtable>
                        </m:mrow>
                      </m:mtd>
                    </m:mtr>
                  </m:mtable>
                </m:math>
              </inlineequation></entry>
          </row>

          <row>
            <entry>Gumbel</entry>

            <entry><inlineequation>
                <m:math display="inline">
                  <m:mtable>
                    <m:mtr>
                      <m:mtd>
                        <m:mrow>
                          <m:msubsup>
                            <m:mi>λ</m:mi>

                            <m:mi>1</m:mi>

                            <m:mi>η</m:mi>
                          </m:msubsup>

                          <m:mo>=</m:mo>

                          <m:mrow>
                            <m:mi>τ+α[0.5772+ln(η+1]</m:mi>

                            <m:msubsup>
                              <m:mi>λ</m:mi>

                              <m:mi>2</m:mi>

                              <m:mi>η</m:mi>
                            </m:msubsup>

                            <m:mi>=</m:mi>

                            <m:mfrac>
                              <m:mi>(η+2)α</m:mi>

                              <m:mi>2!</m:mi>
                            </m:mfrac>

                            <m:mi>[ln(η+2) - ln (η+1)</m:mi>
                          </m:mrow>
                        </m:mrow>
                      </m:mtd>
                    </m:mtr>

                    <m:mtr>
                      <m:mtd>
                        <m:mrow>
                          <m:msubsup>
                            <m:mi>λ</m:mi>

                            <m:mi>3</m:mi>

                            <m:mi>η</m:mi>
                          </m:msubsup>

                          <m:mo>=</m:mo>

                          <m:mrow>
                            <m:mfrac>
                              <m:mi>(η+3)α</m:mi>

                              <m:mi>3!</m:mi>
                            </m:mfrac>

                            <m:mo>[
                            (η+4)ln(η+3)-2(η+3)ln(η+2)+(η+2)ln(η+1)]</m:mo>
                          </m:mrow>
                        </m:mrow>
                      </m:mtd>
                    </m:mtr>

                    <m:mtr>
                      <m:mtd>
                        <m:mrow>
                          <m:mtable>
                            <m:mtr>
                              <m:mtd>
                                <m:mrow>
                                  <m:msubsup>
                                    <m:mi>λ</m:mi>

                                    <m:mi>4</m:mi>

                                    <m:mi>η</m:mi>
                                  </m:msubsup>

                                  <m:mo>=</m:mo>

                                  <m:mrow>
                                    <m:mfrac>
                                      <m:mi>(η+4)α</m:mi>

                                      <m:mi>4!</m:mi>
                                    </m:mfrac>

                                    <m:mo>[(η+6)(η+5)ln(η+4)-3(η+5)(η+4)ln(η+3)</m:mo>
                                  </m:mrow>
                                </m:mrow>
                              </m:mtd>
                            </m:mtr>

                            <m:mtr>
                              <m:mtd>
                                <m:mrow>
                                  <m:mi>+3(η+4)(η+3)ln(η+2)-(η+3)(η+2)ln(η+1)]</m:mi>
                                </m:mrow>
                              </m:mtd>
                            </m:mtr>
                          </m:mtable>
                        </m:mrow>
                      </m:mtd>
                    </m:mtr>
                  </m:mtable>
                </m:math>
              </inlineequation></entry>
          </row>
        </tbody>
      </tgroup>
    </table>

    <para>For ease of computation Wang (1997) derived the following
    approximation for the shape parameter <inlineequation>
        <m:math display="inline">
          <m:mi>κ</m:mi>
        </m:math>
      </inlineequation>:</para>

    <para><equation xml:id="b3_ch2_e_ieds7">
        <m:math display="inline">
          <m:mi>κ</m:mi>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:msub>
              <m:mi>a</m:mi>

              <m:mi>0</m:mi>
            </m:msub>

            <m:mo>+</m:mo>

            <m:mrow>
              <m:mrow>
                <m:msub>
                  <m:mi>a</m:mi>

                  <m:mi>1</m:mi>
                </m:msub>

                <m:msubsup>
                  <m:mi>[τ</m:mi>

                  <m:mi>3</m:mi>

                  <m:mi>η</m:mi>
                </m:msubsup>
              </m:mrow>

              <m:mo>]+</m:mo>

              <m:mrow>
                <m:mrow>
                  <m:msub>
                    <m:mi>a</m:mi>

                    <m:mi>2</m:mi>
                  </m:msub>

                  <m:msubsup>
                    <m:mi>[τ</m:mi>

                    <m:mi>3</m:mi>

                    <m:mi>η-2</m:mi>
                  </m:msubsup>
                </m:mrow>

                <m:mo>]+</m:mo>

                <m:mrow>
                  <m:msub>
                    <m:mi>a</m:mi>

                    <m:mi>3</m:mi>
                  </m:msub>

                  <m:mrow>
                    <m:msubsup>
                      <m:mi>[τ</m:mi>

                      <m:mi>3</m:mi>

                      <m:mi>η-3</m:mi>
                    </m:msubsup>

                    <m:msup>
                      <m:mi>]</m:mi>

                      <m:mi/>
                    </m:msup>
                  </m:mrow>
                </m:mrow>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:math>
      </equation></para>

    <para>where the polynomial coefficients vary with η according to <xref
    linkend="b3_ch2_t_idxtt"/>.</para>

    <table xml:id="b3_ch2_t_idxtt">
      <title>Polynomial coefficients for use with <xref
      linkend="b3_ch2_e_ieds7"/></title>

      <tgroup cols="5">
        <colspec align="center"/>

        <thead>
          <row>
            <entry align="center">η</entry>

            <entry align="center">a<subscript>0</subscript></entry>

            <entry align="center">a<subscript>1</subscript></entry>

            <entry align="center">a<subscript>2</subscript></entry>

            <entry align="center">a<subscript>3</subscript></entry>
          </row>
        </thead>

        <tbody>
          <row>
            <entry>0</entry>

            <entry>0.2849</entry>

            <entry>-1.8213</entry>

            <entry>0.8140</entry>

            <entry>-0.2835</entry>
          </row>

          <row>
            <entry>1</entry>

            <entry>0.4823</entry>

            <entry>-2.1494</entry>

            <entry>0.7269</entry>

            <entry>-0.2103</entry>
          </row>

          <row>
            <entry>2</entry>

            <entry>0.5914</entry>

            <entry>-2.3351</entry>

            <entry>0.6442</entry>

            <entry>-0.1616</entry>
          </row>

          <row>
            <entry>3</entry>

            <entry>0.6618</entry>

            <entry>-2.4548</entry>

            <entry>0.5733</entry>

            <entry>-0.1273</entry>
          </row>

          <row>
            <entry>4</entry>

            <entry>0.7113</entry>

            <entry>-2.5383</entry>

            <entry>0.5142</entry>

            <entry>-0.1027</entry>
          </row>
        </tbody>
      </tgroup>
    </table>

    <para>Wang (1997) derived the following estimators for LH moments with
    shift parameter <inlineequation>
        <m:math display="inline">
          <m:mi>η</m:mi>
        </m:math>
      </inlineequation>:</para>

    <equation xml:id="b3_ch2_e_q4032">
      <m:math display="block">
        <m:mrow>
          <m:msubsup>
            <m:mi>λ</m:mi>

            <m:mi>1</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mfrac>
              <m:mi>1</m:mi>

              <m:msubsup>
                <m:mi>C</m:mi>

                <m:mi>η+1</m:mi>

                <m:mi>n</m:mi>
              </m:msubsup>
            </m:mfrac>

            <m:mrow>
              <m:munderover>
                <m:mo>∑</m:mo>

                <m:mi>i=1</m:mi>

                <m:mi>n</m:mi>
              </m:munderover>

              <m:msubsup>
                <m:mi>C</m:mi>

                <m:mi>η</m:mi>

                <m:mi>j-1</m:mi>
              </m:msubsup>
            </m:mrow>

            <m:msub>
              <m:mi>x</m:mi>

              <m:mi>(i)</m:mi>
            </m:msub>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <equation xml:id="b3_ch2_e_uowzw">
      <m:math display="block">
        <m:mrow>
          <m:msubsup>
            <m:mi>λ</m:mi>

            <m:mi>2</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mfrac>
              <m:mi>1</m:mi>

              <m:mi>2</m:mi>
            </m:mfrac>

            <m:mfrac>
              <m:mi>1</m:mi>

              <m:msubsup>
                <m:mi>C</m:mi>

                <m:mi>η+2</m:mi>

                <m:mi>n</m:mi>
              </m:msubsup>
            </m:mfrac>

            <m:mrow>
              <m:munderover>
                <m:mo>∑</m:mo>

                <m:mi>i=1</m:mi>

                <m:mi>n</m:mi>
              </m:munderover>

              <m:mrow>
                <m:mo>(</m:mo>

                <m:mrow>
                  <m:msubsup>
                    <m:mi>C</m:mi>

                    <m:mi>η+1</m:mi>

                    <m:mi>i-1</m:mi>
                  </m:msubsup>

                  <m:mo>-</m:mo>

                  <m:mrow>
                    <m:msubsup>
                      <m:mi>C</m:mi>

                      <m:mi>η</m:mi>

                      <m:mi>i-1</m:mi>
                    </m:msubsup>

                    <m:msubsup>
                      <m:mi>C</m:mi>

                      <m:mi>1</m:mi>

                      <m:mi>n-i</m:mi>
                    </m:msubsup>
                  </m:mrow>
                </m:mrow>

                <m:mo>)</m:mo>
              </m:mrow>
            </m:mrow>

            <m:msub>
              <m:mi>q</m:mi>

              <m:mi>(i)</m:mi>
            </m:msub>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <equation xml:id="b3_ch2_e_3pbp1">
      <m:math display="block">
        <m:mrow>
          <m:msubsup>
            <m:mi>λ</m:mi>

            <m:mi>3</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mfrac>
              <m:mi>1</m:mi>

              <m:mi>3</m:mi>
            </m:mfrac>

            <m:mfrac>
              <m:mi>1</m:mi>

              <m:msubsup>
                <m:mi>C</m:mi>

                <m:mi>η+3</m:mi>

                <m:mi>n</m:mi>
              </m:msubsup>
            </m:mfrac>

            <m:mrow>
              <m:munderover>
                <m:mo>∑</m:mo>

                <m:mi>i=1</m:mi>

                <m:mi>n</m:mi>
              </m:munderover>

              <m:mrow>
                <m:mo>(</m:mo>

                <m:mrow>
                  <m:msubsup>
                    <m:mi>C</m:mi>

                    <m:mi>η+2</m:mi>

                    <m:mi>i-1</m:mi>
                  </m:msubsup>

                  <m:mo>-2</m:mo>

                  <m:mrow>
                    <m:mrow>
                      <m:msubsup>
                        <m:mi>C</m:mi>

                        <m:mi>η+1</m:mi>

                        <m:mi>i-1</m:mi>
                      </m:msubsup>

                      <m:msubsup>
                        <m:mi>C</m:mi>

                        <m:mi>1</m:mi>

                        <m:mi>n-i</m:mi>
                      </m:msubsup>
                    </m:mrow>

                    <m:mo>+</m:mo>

                    <m:mrow>
                      <m:msubsup>
                        <m:mi>C</m:mi>

                        <m:mi>η</m:mi>

                        <m:mi>i-1</m:mi>
                      </m:msubsup>

                      <m:msubsup>
                        <m:mi>C</m:mi>

                        <m:mi>2</m:mi>

                        <m:mi>n-i</m:mi>
                      </m:msubsup>
                    </m:mrow>
                  </m:mrow>
                </m:mrow>

                <m:mo>)</m:mo>
              </m:mrow>
            </m:mrow>

            <m:msub>
              <m:mi>q</m:mi>

              <m:mi>(i)</m:mi>
            </m:msub>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <equation xml:id="b3_ch2_e_cu4cg">
      <m:math display="block">
        <m:mrow>
          <m:msubsup>
            <m:mi>λ</m:mi>

            <m:mi>4</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mfrac>
              <m:mi>1</m:mi>

              <m:mi>4</m:mi>
            </m:mfrac>

            <m:mfrac>
              <m:mi>1</m:mi>

              <m:msubsup>
                <m:mi>C</m:mi>

                <m:mi>η+4</m:mi>

                <m:mi>n</m:mi>
              </m:msubsup>
            </m:mfrac>

            <m:mrow>
              <m:munderover>
                <m:mo>∑</m:mo>

                <m:mi>i=1</m:mi>

                <m:mi>n</m:mi>
              </m:munderover>

              <m:mrow>
                <m:mo>(</m:mo>

                <m:mrow>
                  <m:msubsup>
                    <m:mi>C</m:mi>

                    <m:mi>η+3</m:mi>

                    <m:mi>i-1</m:mi>
                  </m:msubsup>

                  <m:mo>-</m:mo>

                  <m:mrow>
                    <m:mrow>
                      <m:msubsup>
                        <m:mi>3C</m:mi>

                        <m:mi>η+2</m:mi>

                        <m:mi>i-1</m:mi>
                      </m:msubsup>

                      <m:msubsup>
                        <m:mi>C</m:mi>

                        <m:mi>1</m:mi>

                        <m:mi>n-i</m:mi>
                      </m:msubsup>
                    </m:mrow>

                    <m:mo>+</m:mo>

                    <m:mrow>
                      <m:mrow>
                        <m:msubsup>
                          <m:mi>3C</m:mi>

                          <m:mi>η+1</m:mi>

                          <m:mi>i-1</m:mi>
                        </m:msubsup>

                        <m:msubsup>
                          <m:mi>C</m:mi>

                          <m:mi>2</m:mi>

                          <m:mi>n-i</m:mi>
                        </m:msubsup>
                      </m:mrow>

                      <m:mo>-</m:mo>

                      <m:mrow>
                        <m:msubsup>
                          <m:mi>C</m:mi>

                          <m:mi>η</m:mi>

                          <m:mi>i-1</m:mi>
                        </m:msubsup>

                        <m:msubsup>
                          <m:mi>C</m:mi>

                          <m:mi>3</m:mi>

                          <m:mi>n-i</m:mi>
                        </m:msubsup>
                      </m:mrow>
                    </m:mrow>
                  </m:mrow>
                </m:mrow>

                <m:mo>)</m:mo>
              </m:mrow>
            </m:mrow>

            <m:msub>
              <m:mi>q</m:mi>

              <m:mi>(i)</m:mi>
            </m:msub>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>The selection of the best shift parameter requires some form of
    goodness-of-fit test. Wang (1998) argued that the first three LH moments
    are used to fit the GEV model leaving the fourth LH moment available for
    testing the adequacy of the fit. Wang proposed the following approximate
    test statistic:</para>

    <equation xml:id="b3_ch2_e_otv9s">
      <m:math display="block">
        <m:mrow>
          <m:mi>z</m:mi>

          <m:mo>=</m:mo>

          <m:mfrac>
            <m:mrow>
              <m:msubsup>
                <m:mi>τ</m:mi>

                <m:mi>4</m:mi>

                <m:mi>η</m:mi>
              </m:msubsup>

              <m:mo>-</m:mo>

              <m:msubsup>
                <m:mi>τ</m:mi>

                <m:mi>4</m:mi>

                <m:mi>η</m:mi>
              </m:msubsup>
            </m:mrow>

            <m:mrow>
              <m:mi>σ</m:mi>

              <m:mrow>
                <m:mo>(</m:mo>

                <m:mrow>
                  <m:mrow>
                    <m:msubsup>
                      <m:mi>τ</m:mi>

                      <m:mi>4</m:mi>

                      <m:mi>η</m:mi>
                    </m:msubsup>

                    <m:msubsup>
                      <m:mi>|τ</m:mi>

                      <m:mi>3</m:mi>

                      <m:mi>η</m:mi>
                    </m:msubsup>
                  </m:mrow>

                  <m:mo>=</m:mo>

                  <m:msubsup>
                    <m:mi>τ</m:mi>

                    <m:mi>3</m:mi>

                    <m:mi>η</m:mi>
                  </m:msubsup>
                </m:mrow>

                <m:mo>)</m:mo>
              </m:mrow>
            </m:mrow>
          </m:mfrac>
        </m:mrow>
      </m:math>
    </equation>

    <para>where <inlineequation>
        <m:math display="inline">
          <m:msubsup>
            <m:mi>τ</m:mi>

            <m:mi>4</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>
        </m:math>
      </inlineequation> is the sample estimate of the LH-kurtosis,
    <inlineequation>
        <m:math display="inline">
          <m:msubsup>
            <m:mi>τ</m:mi>

            <m:mi>4</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>
        </m:math>
      </inlineequation> is the LH-kurtosis derived from the GEV parameters
    fitted to the first three LH moments, and <inlineequation>
        <m:math display="inline">
          <m:mrow>
            <m:mi>σ</m:mi>

            <m:mo>(</m:mo>

            <m:msubsup>
              <m:mi>τ</m:mi>

              <m:mi>4</m:mi>

              <m:mi>η</m:mi>
            </m:msubsup>

            <m:msubsup>
              <m:mi>|τ</m:mi>

              <m:mi>3</m:mi>

              <m:mi>η</m:mi>
            </m:msubsup>

            <m:mi>=</m:mi>

            <m:msubsup>
              <m:mi>τ</m:mi>

              <m:mi>3</m:mi>

              <m:mi>η</m:mi>
            </m:msubsup>

            <m:mi>)</m:mi>
          </m:mrow>
        </m:math>
      </inlineequation> is the standard deviation of <inlineequation>
        <m:math display="inline">
          <m:msubsup>
            <m:mi>τ</m:mi>

            <m:mi>4</m:mi>

            <m:mi>η</m:mi>
          </m:msubsup>
        </m:math>
      </inlineequation> assuming the sample LH-skewness equals the LH-skewness
    derived from the GEV parameters fitted to the first three LH moments.
    Under the hypothesis that the underlying distribution is GEV, the test
    statistic z is approximately normal distributed with mean 0 and variance
    1. Wang (1998) describes a simple relationship to estimate <inlineequation>
        <m:math display="inline">
          <m:mrow>
            <m:mi>σ</m:mi>

            <m:msubsup>
              <m:mi>(τ</m:mi>

              <m:mi>4</m:mi>

              <m:mi>η</m:mi>
            </m:msubsup>

            <m:mi>|</m:mi>

            <m:msubsup>
              <m:mi>τ</m:mi>

              <m:mi>3</m:mi>

              <m:mi>η</m:mi>
            </m:msubsup>

            <m:mi>=</m:mi>

            <m:msubsup>
              <m:mi>τ</m:mi>

              <m:mi>3</m:mi>

              <m:mi>η</m:mi>
            </m:msubsup>

            <m:mi>)</m:mi>
          </m:mrow>
        </m:math>
      </inlineequation> .</para>
  </section>

  <section xml:id="b3_ch2_s_wltta">
    <title>Box 7: Parametric bootstrap</title>

    <para>The sampling distribution of an estimator can be approximated using
    the Monte Carlo method known as the parametric bootstrap:</para>

    <orderedlist>
      <listitem>
        <para>Fit the probability model to n years of gauged discharges using
        L or LH moments to yield the parameter estimate <inlineequation>
            <m:math display="inline">
              <m:mi>θ</m:mi>
            </m:math>
          </inlineequation>.</para>
      </listitem>

      <listitem>
        <para>Set i=1</para>
      </listitem>

      <listitem>
        <para>Randomly sample n flows from the fitted distribution; that is,
        q<subscript>ji</subscript> ← p(q|<inlineequation>
            <m:math display="inline">
              <m:mi>θ</m:mi>
            </m:math>
          </inlineequation>),j=1,...,n</para>
      </listitem>

      <listitem>
        <para>Fit the model to the sampled flows
        {q<subscript>ji</subscript>,j=1,..,n}using L or LH moments to yield
        the parameter estimate θ<subscript>i</subscript></para>
      </listitem>

      <listitem>
        <para>Increment i. Go to step 3 if i does not exceed N.</para>
      </listitem>
    </orderedlist>

    <para>This procedure yields N equi-weighted samples that approximate the
    sampling distribution p(<inlineequation>
        <m:math display="inline">
          <m:mi>θ</m:mi>
        </m:math>
      </inlineequation>|D). As a result, they can be used to quantify
    parameter uncertainty and estimate quantile confidence limits. However,
    because the parametric bootstrap assumes <inlineequation>
        <m:math display="inline">
          <m:mi>θ</m:mi>
        </m:math>
      </inlineequation> is the true parameter, it underestimates the
    uncertainty and therefore should not be used to estimate expected
    probabilities.</para>
  </section>

  <section xml:id="b3_ch2_s_lg0c6">
    <title>Example 1: Extrapolation and Process Understanding</title>

    <para>The importance of process understanding when extrapolating beyond
    the observed record is illustrated by a simple Monte Carlo experiment. A
    Poisson rectangular pulse rainfall model is used to generate a long record
    of high resolution rainfall. This is routed through a rainfall-runoff
    model to generate runoff into the stream system. The storage-discharge
    relationship for the stream is depicted by the bilinear relationship shown
    in <xref linkend="b3_ch2_f_hpsm2"/>. A feature of this relationship is the
    activation of significant flood terrace storage once a threshold discharge
    is exceeded.</para>

    <figure xml:id="b3_ch2_f_hpsm2">
      <title>Bilinear channel storage-discharge relationship</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3010.jpg"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>The routing model parameters were selected so that major flood
    terrace storage is activated by floods of less than 1% AEP. This situation
    was chosen to represent a river with multiple flood terraces with the
    lowest terraces accommodating the majority of floods and the highest
    terrace only inundated by extreme floods.</para>

    <para><xref linkend="b3_ch2_f_owuiv"/> presents the flood frequency curve
    based on 30000 simulated years – it shows a clear break in slope around
    the 1% AEP corresponding to the activation of major flood terrace storage.
    Indeed the flood frequency curve displays downward curvature despite that
    the fact the rainfall frequency curve displays upward curvature in the 1%
    to 0.1% (1 in 1000) AEP range. In contrast the flood frequency curve based
    on 100 years of “data” shows no evidence of downward curvature. This is
    because in a 100-year record there is little chance of the major flood
    terrace storage being activated. Indeed without knowledge of the
    underlying hydraulics one would be tempted to extrapolate the 100-year
    flood record using a straight line extrapolation. Such an extrapolation
    would rapidly diverge from the “true” frequency curve.</para>

    <figure xml:id="b3_ch2_f_owuiv">
      <title>Simulated rainfall and flood frequency curves with major
      floodplain storage activated at a threshold discharge of 3500
      m<superscript>3</superscript>/s</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3011.PNG" scalefit="1"
                     width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>Although the example idealises the dominant rainfall-runoff dynamics
    it delivers a very strong message. Extrapolation of flood frequency curves
    fitted to gauged discharges records requires the exercise of hydrologic
    judgment backed up by appropriate modelling. The problem of extrapolation
    is much more general. For example, in this example, if a rainfall-runoff
    approach were used with the rainfall-runoff model calibrated to small
    events the simulated flood frequency curve is likely to be compromised in
    a similar way.</para>
  </section>

  <section xml:id="b3_ch2_s_cli4f">
    <title>Example 2: Accuracy of Daily Gauged Discharges</title>

    <para>The use of daily discharge readings in Flood Frequency Analysis is
    most problematic for smaller catchments, which can be “flashy” in the
    sense that the hydrograph can rise and subside within a twenty four hour
    period. This effect can be quite significant, even for reasonably large
    catchments.</para>

    <para><xref linkend="b3_ch2_f_097da"/> and <xref
    linkend="b3_ch2_f_mvr25"/>, taken from Micevski <emphasis>et
    al</emphasis>. (2003), compare instantaneous annual maximum discharge
    against the discharge recorded at 9am on the same day for two gauging
    stations in the Hunter Valley: Goulburn River at Coggan with area 3340
    km<superscript>2</superscript> and Hunter River at Singleton with area
    16400 km<superscript>2</superscript>. The dashed line represents equality.
    <xref linkend="b3_ch2_f_097da"/> demonstrates that the true peak flow can
    be up to 10 times the 9am flow. In contrast the estimation error is much
    smaller for the larger catchment shown in <xref
    linkend="b3_ch2_f_mvr25"/>.</para>

    <figure xml:id="b3_ch2_f_097da">
      <title>Comparison between true peak flow and 9 am flow for Goulburn
      River at Coggan</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3012.PNG"/>
        </imageobject>
      </mediaobject>
    </figure>

    <figure xml:id="b3_ch2_f_mvr25">
      <title>Comparison between true peak flow and 9 am flow for Hunter River
      at Singleton</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/3013.PNG"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>The example demonstrates the need to check the representativeness of
    daily readings by comparing instantaneous peak flows against daily
    readings.</para>
  </section>
  <section xml:id="b3_ch2_s_o1s2n">
    <title>Example 3: Fitting a probability model to gauged data</title>
    <section xml:id="b3_ch2_s_400aj">
      <title>Launch TUFLOW Flike</title>
      <para>This example demonstrates undertaking a flood frequency analysis using the procedures
        described in this book. Specifically, this example covers the fitting of a Log Pearson Type
        3 (LP3) distribution to an annual maximum series for the Hunter River at Singleton. The
        analysis will be undertaken using TUFLOW Flike which has been developed to undertake flood
        frequency analysis as described in this book, that is, it has the ability to fit a range of
        statistical distributions using a Bayesian Inference method.</para>
      <para>Once TUFLOW Flike has been obtained and installed, launch <emphasis role="bold">TUFLOW
          Flike</emphasis> and the screen in <xref linkend="b3_ch2_f_77nti"/> will appear.</para>
      <figure xml:id="b3_ch2_f_77nti">
        <title><emphasis role="bold">TUFLOW Flike Splash Screen</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3054.PNG"/>
        </imageobject>
      </figure>
    </section>
    <section xml:id="b3_ch2_s_nv5b5">
      <title>Create the .fld file</title>
      <para>The first step will be to create the <emphasis role="bold">.fld</emphasis> file which
        contains information about the project. To create a new <emphasis role="bold">.fld</emphasis> file, select <emphasis role="bold">New</emphasis> from the <emphasis role="bold">File</emphasis> dropdown menu. This will open a new window called <emphasis role="bold">Open</emphasis> as shown in <xref linkend="b3_ch2_f_prmm3"/>.</para>
      <figure xml:id="b3_ch2_f_prmm3">
        <title><emphasis role="bold">Create New .fld file</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3055.PNG"/>
        </imageobject>
      </figure>
      <para>Create and save a new .fld file in an appropriate location, such as in a folder under
        the job directory, and give it a logical name, in this case <emphasis role="bold">Example_3.fld</emphasis>. A message will appear asking if you want to create the file,
        select <emphasis role="bold">Yes</emphasis>. Note that the window is titled <emphasis role="bold">Open</emphasis>, but it works for creating new files as well. Once the
          <emphasis role="bold">.fld</emphasis> file has been saved, the <emphasis role="bold">Flike
          Editor</emphasis> window will open which will be used in the next step.</para>
    </section>
    <section xml:id="b3_ch2_s_zkskh">
      <title>Configure the project details</title>
      <para>The <emphasis role="bold">.fld</emphasis> file is used to store the project data and
        configuration. Once the <emphasis role="bold">.fld</emphasis> has been created the <emphasis role="bold">Flike Editor</emphasis> window will open automatically (see <xref linkend="b3_ch2_f_ha723"/>) and the project will be configured here. The first bit of
        information to be completed is the project a name which is filled in the <emphasis role="bold">Title</emphasis> text box. The project title can go over two lines. </para>
      <figure xml:id="b3_ch2_f_ha723">
        <title><emphasis role="bold">Flike Editor Screen</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3015.PNG"/>
        </imageobject>
      </figure>
    </section>
    <section xml:id="b3_ch2_s_ylho0">
      <title>Import the data</title>
      <para>The next step is to import the flood series to analyse. To do this select the <emphasis role="bold">Observed values</emphasis> tab in the <emphasis role="bold">Flike
          Editor</emphasis> as shown in <xref linkend="b3_ch2_f_axe49"/>. In this tab the flood
        series to be investigated will be imported.</para>
      <figure xml:id="b3_ch2_f_axe49">
        <title><emphasis role="bold">Observed Values Screen</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3014.PNG"/>
        </imageobject>
      </figure>
      <para>To import the flood series select the <emphasis role="bold">Import</emphasis> button and
        the <emphasis role="bold">Import gauged values</emphasis> window opens as shown in <xref linkend="b3_ch2_f_7evjt"/>. Now select the <emphasis role="bold">Browse</emphasis> button
        and navigate to the Singleton flood series. This example data are included in the TUFLOW
        Flike download, a copy of which was installed in the <emphasis role="bold">data
        </emphasis>folder in the install location of TUFLOW-Flike. By default, this location is
          <emphasis role="italic">C:\TUFLOW Flike\data\singletonGaugedFlows.csv</emphasis>. This
        data also appears at the end of this example. </para>
      <figure xml:id="b3_ch2_f_7evjt">
        <title><emphasis role="bold">Import Gauged Values Screen</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3056.PNG"/>
        </imageobject>
      </figure>
      <para>Once the data file has been selected, the program will return to the <emphasis role="bold">Import gauged values</emphasis> window. As the input data format is flexible
        TUFLOW Flike needs to be told how to interpret the data file. To view the format of the
        data, select the <emphasis role="bold">View</emphasis> button and the data will be open in
        your default text editor (see <xref linkend="b3_ch2_f_xb2ll"/>). In the example data the
        first line contains a header line and the data follows this. The flow values are in the
        first column and the year in the fourth column. Having taken note of the data structure
        close the text editor and return to the <emphasis role="bold">Import gauged
          values</emphasis> window. It's a good habit to check the data in the text editor to ensure
        that the format of the data is known and the file has not been corrupted or includes a large
        number of trailing comma or whitespace. This last issue commonly occurs when deleting
        information from excel files, but it is easy to fix. Simply delete any trailing comma or
        white space in a text editor. </para>
      <figure xml:id="b3_ch2_f_xb2ll">
        <title><emphasis role="bold">View Gauged Values in Text Editor</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3057.PNG"/>
        </imageobject>
      </figure>    
      <para>The next step is to configure the import of the data. As the example data has a header,
        the first line needs to be skipped. Enter <emphasis role="bold">1</emphasis> into the
          <emphasis role="bold">Skip first __ records and then text field</emphasis>. This will skip
        the first line. Ensure that the <emphasis role="bold">Read to the end-of-file</emphasis>
        option is selected (this is the default). Occasionally, there may be a need to specify how
        many records to read, in which case this can be achieved by selecting the <emphasis role="bold">Read next __ records</emphasis> option and entering the desired number of
        records to read. Next, specify which column the flood data are in, by filling the <emphasis role="bold">gauged values are in column __ </emphasis>text box, in this example data this
        is column 1. Next, select the <emphasis role="bold">Years available in column __</emphasis>
        text box and specify the column that this data is in (column 4). Finally, select <emphasis role="bold">OK</emphasis> to import the data. The <emphasis role="bold">Import gauged
          values</emphasis> window should look similar to <xref linkend="b3_ch2_f_7evjt"/>.</para>
      <para>The <emphasis role="bold">Value</emphasis> and <emphasis role="bold">Year</emphasis>
        columns in the <emphasis role="bold">Observed values</emphasis> tab will now be filled with
        the data in the order that they were in the data file as shown in <xref linkend="b3_ch2_f_1cjit"/>. The data can be sorted by value and year using the <emphasis role="bold">Rank</emphasis> button. Selecting this button will open a new window (<xref linkend="b3_ch2_f_yrxtw"/>) where there are five choices to rank by, these are: </para>
      <itemizedlist>
        <itemizedlist>
          <listitem><emphasis role="bold">Descending flow: </emphasis>Ranks the data in order of
            values from largest to smallest<emphasis role="bold"> </emphasis></listitem>
          <listitem><emphasis role="bold">Ascending flow: </emphasis>Ranks the data in order of
            values from smallest to largest<emphasis role="bold"> </emphasis></listitem>
          <listitem><emphasis role="bold">Descending year:</emphasis> Ranks the data in order of
            year from largest to highest<emphasis role="bold"> </emphasis></listitem>
          <listitem><emphasis role="bold">Ascending year: </emphasis>Ranks the data in order of year
            from highest to largest </listitem>
          <listitem><emphasis role="bold">Leave unchanged </emphasis>: Leaves both the values and
            years unchanged</listitem>
        </itemizedlist>
      </itemizedlist>
      <para>It is always a good idea to initially rank your data in descending order so you can
        check the largest flows. For this data series the value is 12,525.66
          m<superscript>3</superscript>/s. Leave the data ranked in descending order for this
        example. </para>
      <para>Note that the value name and units can be specified by entering values in the <emphasis role="bold">Value</emphasis><emphasis role="bold">name</emphasis> and <emphasis role="bold">Unit</emphasis> text boxes. These titles do not affect the computations in any
        way, they do, however, assist in reviewing the results, particularly when presenting results
        to external audiences.</para>
      <figure xml:id="b3_ch2_f_1cjit">
        <title><emphasis role="bold">Observed Values screen with Imported Data</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3058.PNG"/>
        </imageobject>
      </figure>   
      <figure xml:id="b3_ch2_f_yrxtw">
        <title><emphasis role="bold">Rank Data Screen</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3059.PNG"/>
        </imageobject>
      </figure>   
    </section>
    <section xml:id="b3_ch2_s_5inth">
      <title>Configure the distribution and fit method</title>
      <para>Now that the data has been imported the statistical distribution can be fitted to the
        data. To do this, select the <emphasis role="bold">General</emphasis> tab. As noted above,
        for this example the Log Pearson Type III distribution will be fitted using the Bayesian
        Inference method.</para>
      <para>Before configuring the model it is worthwhile checking that TUFLOW Flike has interpreted
        the data correctly. The number of observed data is reported in the <emphasis role="bold">Number of observed data</emphasis> text box. In this case the number of observations or
        length of the data series is 31 as shown in <xref linkend="b3_ch2_f_56hql"/>. Before
        continuing, check that this is the case.</para>
      <para>Next, select the probability model; the Log Pearson Type III. To do this ensure that the
        radio button next to the text <emphasis role="bold">Log Pearson Type III (LP3)</emphasis> is
        selected (this is the default) as in <xref linkend="b3_ch2_f_56hql"/>.</para>
      <para>The final task is to choose the fitting method. In this example the Bayesian Inference
        method will be used. To do this, ensure that the radio button next to <emphasis role="bold">Bayesian with</emphasis> is selected and the radio button next to <emphasis role="bold">No prior information</emphasis> is selected as shown in <xref linkend="b3_ch2_f_56hql"/>.
        Again, both of these are the defaults.</para>
      <figure xml:id="b3_ch2_f_56hql">
        <title><emphasis role="bold">General Screen – After Data Import</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3060.PNG"/>
        </imageobject>
      </figure>
    </section>
    <section xml:id="b3_ch2_s_6za5s">
      <title>Running TUFLOW Flike and accessing Results </title>
      <para>TUFLOW Flike presents the results in two ways:</para>
      <itemizedlist>
        <listitem>
          <para>As a visual plot; and</para>
        </listitem>
        <listitem>
          <para>In a text based report file.</para>
        </listitem>
      </itemizedlist>
      <para>Both of these will be explored in this example and both should be consulted when
        undertaking a Flood Frequency Analysis. Before we proceed with this example the length of
        the x-axis in the plot needs to be specified; that is, the lowest probability (rarest event)
        to be displayed. It is recommended to always enter a value greater than the 1-in-Y AEP event
        that you are interested in. This is specified in the <emphasis role="bold">Maximum AEP
          1-in-Y in probability plot ___ years</emphasis> text box. In this example, enter the
        1-in-200 year AEP event as shown in <link xlink:href="http://localhost:8889/Fit.model.PNG">Figure 9</link>. By default the plot window automatically launches when a distribution is
        fitted.</para>
      <para>In addition to the plot window a report file can also be automatically launched in a
        text editor. This can be quite helpful when you are developing a model, as it allows you to
        more readily compare the results. To do this select the appropriate radio button next to
          <emphasis role="bold">Always display report file</emphasis> as shown in <xref linkend="b3_ch2_f_56hql"/>.</para>
    </section>
    <section xml:id="b3_ch2_s_kw5dq">
      <title>Run TUFLOW Flike</title>
      <para>Now that the data has been imported, the distribution selected, the fit method
        configured and the output configured TUFLOW Flike is ready to run. To fit the model select
          <emphasis role="bold">OK</emphasis> on the <emphasis role="bold">General</emphasis> tab
        and this will return you to the <emphasis role="bold">TUFLOW Flike</emphasis> window, which
        will look quite empty as in <xref linkend="b3_ch2_f_xprrq"/>. In this window, select the
          <emphasis role="bold">Option</emphasis> dropdown menu and choose <emphasis role="bold">Fit</emphasis><emphasis role="bold">model</emphasis>. This will run TUFLOW-Flike and
        present you with a <emphasis role="bold">Probability Plot </emphasis>as well as opening the
          <emphasis role="bold">Report File</emphasis> in a text editor.</para>
      <figure xml:id="b3_ch2_f_xprrq">
        <title><emphasis role="bold">Blank TUFLOW-Flike Screen</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3061.PNG"/>
        </imageobject>
      </figure>
    </section>
    <section xml:id="b3_ch2_s_wb72d">
      <title>Reviewing the results </title>
      <para>When TUFLOW-Flike has finished fitting the distribution to the input data, a plot screen
        will appear similar to <xref linkend="b3_ch2_f_mrvdm"/> and the results file will be shown
        in the default text editor as in <xref linkend="b3_ch2_f_t2d48"/>.</para>
      <figure xml:id="b3_ch2_f_mrvdm">
        <title><emphasis role="bold">Probability Plot</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3016.PNG"/>
        </imageobject>
      </figure>
      <figure xml:id="b3_ch2_f_t2d48">
        <title><emphasis role="bold">Results File</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3062.PNG"/>
        </imageobject>
      </figure>
      <para>When fitting a flood series to a probability distribution it is essential that the
        results are viewed and reviewed. This is most easily achieved by first viewing the results
        in the <emphasis role="bold">Probability Plot</emphasis>. If the <emphasis role="bold">Probability Plot</emphasis> window has been closed, it can be reopened by selecting the
          <emphasis role="bold">Option</emphasis> dropdown menu and then <emphasis role="bold">View</emphasis><emphasis role="bold">plot</emphasis>. The plot contains information about
        the fit as well as the quantile values and confidence limits. Within the plot window the
        y-axis contains information on discharge (or log discharge depending on the Plot scale
        selected) and x-axis displays the Annual Exceedance Probability (AEP) in terms of 1 in Y
        years. The plot displays the: </para>
      <itemizedlist>
        <listitem>
          <para>Log normal probability plot of the gauged flows with plotting position determined
            using the Cunnane plotting position, shown as blue triangles; </para>
        </listitem>
        <listitem>
          <para>X% AEP quantile curve (derived using the posterior mean parameters), shown as a
            black line; </para>
        </listitem>
        <listitem>
          <para>90% quantile confidence limits shown as dashed pink lines; and </para>
        </listitem>
        <listitem>
          <para>The expected probability quantile, shown as a red line. </para>
        </listitem>
      </itemizedlist>
      <para>For the data contained in this example the resulting plot displays a good fit to the
        gauged data and appears to have tight confidence limits with all gauged data points falling
        within the 90% confidence limits; by default the figure plots the logarithm of the flood
        peaks. The plot can be rescaled to remove the log from the flow values. Select the <emphasis role="bold">Plot</emphasis><emphasis role="bold">scale</emphasis> button and choose one of
        the non-log options, that is, either Gumble or Exponential and the uncertainty changes as in
          <xref linkend="b3_ch2_f_nc6jz"/>. This will present a more sobering perspective on the
        model fit with the confidence limit appearing much larger for rarer flood quantiles. This
        can be confirmed by reviewing the results in the <emphasis role="bold">Result
          file</emphasis>. <xref linkend="b3_ch2_t_y11qf"/> presents a subset of the results found
        in the <emphasis role="bold">Result file</emphasis> of selected X% AEP quantiles qY and
        their 90% confidence limits. For example, for the 1% AEP flood, the 5% and 95% confidence
        limits are respectively 37% and 546% of the quantile qY! The 0.2% AEP confidence limits are
        so wide as to render estimation meaningless. Note the expected AEP for the quantile qY
        consistently exceeds the nominal X% AEP. For example, the 1% (1 in 100) AEP quantile of
        19,572 m<superscript>3</superscript>/s has an expected AEP of 1.35% (1 in 74).</para>
 
        <figure xml:id="b3_ch2_f_nc6jz">
          <title><emphasis role="bold">Probability Plot using Gumbel Scale</emphasis></title>
          <imageobject>
            <imagedata fileref="../../figures/3063.PNG"/>
          </imageobject>
        </figure>
        <table xml:id="b3_ch2_t_y11qf">
          <caption>Selected Results</caption>
          <col width="20%"/>
          <col width="20%"/>
          <col width="20%"/>
          <col width="20%"/>
          <col width="20%"/>
          <thead>
            <tr>
              <th><emphasis role="bold">1 in Y AEP</emphasis></th>
              <th><emphasis role="bold">Quantile Estimate q</emphasis><subscript>Y</subscript></th>
              <th><emphasis role="bold">Quantile confidence limits 5% limit</emphasis></th>
              <th><emphasis role="bold">Quantile confidence limits 95% limit</emphasis></th>
              <th><emphasis role="bold">Expected 1 in Y AEP for
                q</emphasis><subscript>Y</subscript></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>10</td>
              <td>3,929</td>
              <td>2,229</td>
              <td>8,408</td>
              <td>10.1%</td>
            </tr>
            <tr>
              <td>50</td>
              <td>12,786</td>
              <td>5,502</td>
              <td>51,010</td>
              <td>2.32%</td>
            </tr>
            <tr>
              <td>100</td>
              <td>19,572</td>
              <td>7,188</td>
              <td>107,122</td>
              <td>1.36%</td>
            </tr>
            <tr>
              <td>500</td>
              <td>47,034</td>
              <td>11,507</td>
              <td>570,635</td>
              <td>0.48%</td>
            </tr>
          </tbody>
        </table>
     
      <para><emphasis role="bold">Gauged flows on the Hunter River at Singleton</emphasis></para>
      <informaltable>
        
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <thead/>
        <tbody>
          <tr>
            <td>1938</td>
            <td>76.26</td>
            <td>1946</td>
            <td>1374.42</td>
            <td>1954</td>
            <td>1391.43</td>
            <td>1962</td>
            <td>2125.4</td>
          </tr>
          <tr>
            <td>1939</td>
            <td>171.87</td>
            <td>1947</td>
            <td>280.18</td>
            <td>1955</td>
            <td>12525.66</td>
            <td>1963</td>
            <td>966.35</td>
          </tr>
          <tr>
            <td>1940</td>
            <td>218.21</td>
            <td>1948</td>
            <td>202.62</td>
            <td>1956</td>
            <td>1099.54</td>
            <td>1964</td>
            <td>2751.68</td>
          </tr>
          <tr>
            <td>1941</td>
            <td>668.79</td>
            <td>1949</td>
            <td>4052.42</td>
            <td>1957</td>
            <td>447.75</td>
            <td>1965</td>
            <td>49.03</td>
          </tr>
          <tr>
            <td>1942</td>
            <td>1374.42</td>
            <td>1950</td>
            <td>2323.77</td>
            <td>1958</td>
            <td>478.92</td>
            <td>1966</td>
            <td>76.51</td>
          </tr>
          <tr>
            <td>1943</td>
            <td>124.12</td>
            <td>1951</td>
            <td>2536.31</td>
            <td>1959</td>
            <td>180.52</td>
            <td>1967</td>
            <td>912.5</td>
          </tr>
          <tr>
            <td>1944</td>
            <td>276.3</td>
            <td>1952</td>
            <td>3315.62</td>
            <td>1960</td>
            <td>164.36</td>
            <td>1968</td>
            <td>926.67</td>
          </tr>
          <tr>
            <td>1945</td>
            <td>895.5</td>
            <td>1953</td>
            <td>1232.73</td>
            <td>1961</td>
            <td>229.54</td>
            <td/>
            <td/>
          </tr>
        </tbody>
      </informaltable>
    </section>
  </section>
  <section xml:id="b3_ch2_s_kg64r">
    <title>Example 4: Use of binomial censored historical data</title>
  <section xml:id="b3_ch2_s_375iu">
    <para>This example is a continuation of <emphasis role="bold">Example 3</emphasis> and it
      examines the benefit of using historical flood information. In the previous example the gauged
      record spanned the period 1938 to 1968. The biggest flood in that record occurred in 1955 with
      a discharge of 12,526m3/s. An examination of historic records indicates that during the
      ungauged period 1820 to 1937 there was only one flood that exceeded the 1955 flood and that
      this flood occurred in 1820. The information for the 1820 flood is not from a stream gauge;
      rather it is from a variety of sources including newspaper articles. This information is
      valuable, perhaps the most valuable, even though the magnitude of the 1820 flood is not
      reliably known. This information can be incorporated into a Bayesian approach. The way that
      this is done in TUFLOW Flike is through censoring data.</para>
    <para>From the information about the flood history at Singleton we can make the following
      conclusions:</para>
    <itemizedlist>
      <listitem>
        <para>Over the ungauged period 1820 to 1937 there was:</para>
        <itemizedlist>
          <listitem>
            <para>One flood above the 1955 flood; and</para>
          </listitem>
          <listitem>
            <para>117 floods below the 1955 flood.</para>
          </listitem>
        </itemizedlist>
      </listitem>
    </itemizedlist>
    <para>Note that the ungauged record length is 118 years, that is, all years from 1820 to 1937
      are included as it is assumed each year has an event. Also, note that the ungauged period
      cannot overlap with the gauged period.</para>
  </section>
    <section xml:id="b3_ch2_s_uksma">
      <title>Launch TUFLOW-Flike</title>
    </section>
    <section xml:id="b3_ch2_s_0f80u">
      <para>As in <emphasis role="bold">Example 3</emphasis> launch TUFLOW Flike; however, this time
        open the <emphasis role="bold">.</emphasis><emphasis role="bold">fld</emphasis> file
        previously created: <emphasis role="bold">Example_3.fld</emphasis>. This file will be used
        as it contains the data that are needed for this example. To do this select the File
        dropdown menu and then select <emphasis role="bold">Open</emphasis>. Navigate to the
          <emphasis role="bold">Example_3.fld</emphasis> in the next dialogue box and open the file.
        The <emphasis role="bold">Flike Editor</emphasis> window will then appear containing all the
        information from Example 3.</para>
    </section>
    <section xml:id="b3_ch2_s_5lcbh">
      <title>Save Example_4.fld</title>
      <para>The next step is to save the <emphasis role="bold">Example_4.fld</emphasis> file as a
        new file. It is best to do this immediately to ensure that no data is overwritten. To do
        this, select <emphasis role="bold">OK</emphasis> from the <emphasis role="bold">Flike
          Editor</emphasis> window which will return to the main <emphasis role="bold">TUFLOW
          Flike</emphasis> window. Select <emphasis role="bold">File</emphasis> again and then
          <emphasis role="bold">Save</emphasis><emphasis role="bold">as</emphasis>. Save the file as
          <emphasis role="bold">Example_4.fld</emphasis> in a new folder called <emphasis role="bold">Example 4.</emphasis></para>
    </section>
    <section xml:id="b3_ch2_s_jym0z">
      <title>Enter Historical Flood Information</title>
      <para>In this step the historical flood information is entered. To edit the <emphasis role="bold">Example_4.fld</emphasis> data from the <emphasis role="bold">TUFLOW-Flike</emphasis> window select <emphasis role="bold">Options</emphasis> and then
          <emphasis role="bold">Edit data</emphasis>. This reopens the Flike Editor window. Now
        select the <emphasis role="bold">Censoring of observed values</emphasis> tab and this will
        open a window similar to <xref linkend="b3_ch2_f_lx319"/> with no data.</para>
      <figure xml:id="b3_ch2_f_lx319">
        <title><emphasis role="bold">Censoring observed values tab</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3017.PNG"/>
        </imageobject>
      </figure>
      <para>The historical data needs to be entered into the <emphasis role="bold">Censoring of
          observed values</emphasis> tab, that is, we need to let TUFLOW-Flike know that there has
        been one flood greater than the 1955 flood between 1820 and 1937. So:</para>
      <itemizedlist>
        <listitem>
          <para>The <emphasis role="bold">Threshold value</emphasis> is
              12,526m<superscript>3</superscript>/s - the size of the 1955 flood.</para>
        </listitem>
        <listitem>
          <para>The Years greater than the threshold (<emphasis role="bold">Yrs
              &gt;</emphasis><emphasis role="bold"> threshold</emphasis>) is one (1) – the 1820
            flood.</para>
        </listitem>
        <listitem>
          <para>The Years less than or equal to the threshold (<emphasis role="bold">Yrs &lt;=
              threshold</emphasis>) is 117 – there were 117 years between 1820 and 1937 with flood
            less than the 1820 flood.</para>
        </listitem>
        <listitem>
          <para>The <emphasis role="bold">Start Year</emphasis> is 1820; and</para>
          <para>The <emphasis role="bold">End Year</emphasis> is 1937.</para>
        </listitem>
      </itemizedlist>
      <para>Once the data has been entered, select OK which will return the main <emphasis role="bold">TUFLOW-Flike</emphasis> window. TUFLOW-Flike preforms some checks of the data
        to ensure that it has been entered correctly. However, these are only checks and it is up to
        the user to ensure they have correctly configured the historic censoring.</para>
      <para>Return to the <emphasis role="bold">General</emphasis> tab by selecting <emphasis role="bold">Options</emphasis> and then <emphasis role="bold">Edit data</emphasis> and it
        should appear as in <xref linkend="b3_ch2_f_nkj8a"/>. <emphasis role="bold">Note the Number
          of censoring thresholds</emphasis> text field has been populated with the number 1, so
        TUFLOW-Flike has recognised that there censoring has been configured.</para>
      <para>As with the previous example, check that the <emphasis role="bold">Always display report
          file</emphasis> radio button has been selected.</para>
      <figure xml:id="b3_ch2_f_nkj8a">
        <title><emphasis role="bold">Configured Flike Editor</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3064.PNG"/>
        </imageobject>
      </figure>
    </section>
    <section xml:id="b3_ch2_s_4e1b5">
      <title>Run TUFLOW-Flike with Historic Censoring Data</title>
      <para>On the general tab select <emphasis role="bold">OK</emphasis> and return to the
          <emphasis role="bold">TUFLOW-Flike</emphasis> window. As in the previous exercise select
          <emphasis role="bold">Option</emphasis> and then <emphasis role="bold">Fit
          model</emphasis>. This will run TUFLOW-Flike and when the engine has finished the
          <emphasis role="bold">Probability Plot</emphasis> will open together with the <emphasis role="bold">Report File</emphasis>.</para>
    </section>
    <section xml:id="b3_ch2_s_nv0wq">
      <title>Results</title>
      <para><xref linkend="b3_ch2_t_febrt"/> presents the posterior mean, standard deviation and
        correlation for the Log Pearson Type 3 parameters: <emphasis role="italic">m</emphasis>,
          <emphasis role="italic">loges</emphasis> and <emphasis role="italic">g</emphasis> which
        are respectively the mean, standard deviation and skewness of loge(q) taken from the
          <emphasis role="bold">Report File</emphasis>. Comparison with Example 3 reveals the
        censored data have reduced by almost 17% the uncertainty in the skewness (<emphasis role="italic">g</emphasis>) parameter. This parameter controls the shape of the
        distribution, particularly in the tail region where the floods of interest are.</para>
      <table xml:id="b3_ch2_t_febrt">
        <caption>Posterior Mean, Standard Deviation and Correlation for the LP3</caption>
        <col width="16%"/>
        <col width="16%"/>
        <col width="16%"/>
        <col width="16%"/>
        <col width="16%"/>
        <col width="16%"/>
        <thead/>
        <tbody>
          <tr>
            <td>LP3 Parameter</td>
            <td>Mean</td>
            <td>Std. Deviation</td>
            <td>Correlation</td>
            <td/>
            <td/>
          </tr>
          <tr>
            <td>m</td>
            <td>6.365</td>
            <td>0.237</td>
            <td>1.000</td>
            <td/>
            <td/>
          </tr>
          <tr>
            <td>log<subscript>e</subscript>s</td>
            <td>0.303</td>
            <td>0.120</td>
            <td>-0.236</td>
            <td>1.000</td>
            <td/>
          </tr>
          <tr>
            <td>g</td>
            <td>-0.004</td>
            <td>0.405</td>
            <td>-0.227</td>
            <td>-0.409</td>
            <td>1.000</td>
          </tr>
        </tbody>
      </table>
      <para>
      
      </para>
      <para>The resulting <emphasis role="bold">Probability plot</emphasis> is shown in <xref linkend="b3_ch2_f_fbunw"/>. This figure displays on a log normal probability plot the
        gauged flows, the X% AEP quantile curve (derived using the posterior mean parameters), the
        90% quantile confidence limits and the expected probability curve. Compared with Example 3
        the tightening of the confidence limits is noticeable.</para>
      <figure xml:id="b3_ch2_f_136dw">
        <title><emphasis role="bold">Probability plot of the Singleton data with historic information</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3018.PNG"/>
        </imageobject>
      </figure>
      <para>The following table (<xref linkend="b3_ch2_t_a0hsi"/>) of selected 1 in Y AEP quantiles
        qY and their 90% confidence limits illustrates the benefit of the information contained in
        the historic data. For example, for the 1% AEP flood the 5% and 95% confidence limits are
        respectively 58% and 205% of the quantile qY! This represents a major reduction in quantile
        uncertainty compared with Example 3 which yielded limits of 38% and 553%. This is
        illustrated in graphically <xref linkend="b3_ch2_f_fbunw"/>.</para>
      <table xml:id="b3_ch2_t_a0hsi">
        <caption>Comparison of Selected Quantiles with 90% Confidence Limits</caption>
        <col width="20%"/>
        <col width="20%"/>
        <col width="20%"/>
        <col width="20%"/>
        <col width="20%"/>
        <thead>
          <tr>
            <th><emphasis role="bold">1 in Y AEP</emphasis></th>
            <th><emphasis role="bold">Quantile Estimate q</emphasis><subscript>Y</subscript></th>
            <th><emphasis role="bold">Quantile Confidence Limits 5% Limit</emphasis></th>
            <th><emphasis role="bold">Quantile Confidence Limits 95% Limit</emphasis></th>
            <th><emphasis role="bold">Expected 1 in Y AEP for
              q</emphasis><subscript>Y</subscript></th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>10</td>
            <td>3,294</td>
            <td>2,181</td>
            <td>4,947</td>
            <td>10.37%</td>
          </tr>
          <tr>
            <td>50</td>
            <td>9,350</td>
            <td>5,778</td>
            <td>16,511</td>
            <td>2.09%</td>
          </tr>
          <tr>
            <td>100</td>
            <td>13,511</td>
            <td>7,785</td>
            <td>27,687</td>
            <td>1.08%</td>
          </tr>
          <tr>
            <td>500</td>
            <td>28,542</td>
            <td>12,966</td>
            <td>85,583</td>
            <td>0.28%</td>
          </tr>
        </tbody>
      </table>
    
      <para>Note that <emphasis role="bold">Report File</emphasis> presents the Expected AEP in 1 in
        Y years whereas <xref linkend="b3_ch2_t_a0hsi"/> presents as the Expected AEP as a
        percentage.</para>
      <para>This example highlights the significant reductions in uncertainty that historical data
        can offer. However, care must be exercised to ensure the integrity of the historic
        information – see Section 2.3.8 for more details.</para>
      <figure xml:id="b3_ch2_f_fbunw">
        <title><emphasis role="bold">Probability plot of the Singleton data with historic information</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3065.PNG"/>
        </imageobject>
      </figure>
    </section>
  </section>
  <section xml:id="b3_ch2_s_0bj8p">
    <title>Example 5: Use of regional information</title>
    <para>
      <para>In this example the use of regional parameter information is explored, building on
        Example 3. As was shown in Example 3, there was significant uncertainty in the skewness
        parameter. In that example, the posterior mean of the skewness was estimated to be 0.131
        with a posterior standard deviation of 0.479. This led to significant uncertainty in the
        quantile estimates, for instance the 5% and 95% confidence limits for the 1% AEP quantile
        were 37% and 546% respectively of the 1% AEP quantile. This example shows how the use of
        regional information can reduce, sometimes significantly, the uncertainty of quantile
        estimates. Details on the use of regional information can be found in <emphasis role="underline">Section 2.3.10.</emphasis> and <emphasis role="underline">2.6.3.5.</emphasis></para>
      <para>In this hypothetical example, a regional analysis of skewness has been conducted and the
        expected regional skew was found to be 0.00 with a standard deviation of 0.30. This
        information can be incorporated into the Bayesian analysis undertaken by TUFLOW Flike as
        shown in this example. </para>
    </para>
    <section xml:id="b3_ch2_s_vyhk9">
      <title>Launch TUFLOW Flike</title>
      <para>
        <para>The Singleton data from the previous examples will be used in this example, so as in
          Example 4 launch TUFLOW Flike and open the <emphasis role="bold">.fld</emphasis> file
          created in Example 3. Save the opened <emphasis role="bold">.fld</emphasis> as, say,
            <emphasis role="bold">Example_5.fld</emphasis>.</para>
      </para>
    </section>
    <section xml:id="b3_ch2_s_jltet">
      <title>Enter Prior Information</title>
     
        <para>The next step will be to enter the prior information, that is the regional information
          on skew. To do this, select <emphasis role="bold">Edit data</emphasis>from the <emphasis role="bold">Options</emphasis> menu. As before, this opens the <emphasis role="bold">Flike Editor</emphasis>. To enter the prior regional information, check the <emphasis role="bold">Gaussian prior distributions</emphasis> radio button and then click on the
          Edit button as shown in <xref linkend="b3_ch2_f_mom23"/>. This will open the <emphasis role="bold">Prior for Log-Pearson 3</emphasis> window as shown in <xref linkend="b3_ch2_f_zr5se"/>.</para>
        <para>The regional skewness (0.00) is entered into the <emphasis role="bold">Mean Skew of
            log Q</emphasis> text box and the standard deviation of the regional skew (0.300) is
          entered into the <emphasis role="bold">Standard Deviation Skew of log Q</emphasis> as
          shown in <xref linkend="b3_ch2_f_zr5se"/>. Note in practice careful attention to the units
          being used is required.</para>
        <para>Very large prior standard deviations are assigned to the <emphasis role="bold">Mean of
            log Q</emphasis> and <emphasis role="bold">Standard deviation of log</emphasis> Q
          parameters to ensure there is no prior information about theses parameters. If the
            <emphasis role="italic">Log Pearson 3</emphasis> distribution has been selected, the
          option to import the prior information from the ARR Regional Flood Frequency Estimation
          method is available (refer to Book 3 Chapter 2).</para>
        <para>Select <emphasis role="bold">OK</emphasis> to return to the <emphasis role="bold">Flike editor</emphasis> window.</para>
        <figure xml:id="b3_ch2_f_mom23">
          <title><emphasis role="bold">Gaussian prior distributions</emphasis></title>
          <imageobject>
            <imagedata fileref="../../figures/3019.PNG"/>
          </imageobject>
        </figure>
        <figure xml:id="b3_ch2_f_zr5se">
          <title><emphasis role="bold">Prior for Log-Pearson 3 window</emphasis></title>
          <imageobject>
            <imagedata fileref="../../figures/3020.PNG"/>
          </imageobject>
        </figure>
      
    </section>
    <section xml:id="b3_ch2_s_hehr0">
      <title>Run TUFLOW Flike with Regional Information</title>
    
        <para>As in the previous examples select <emphasis role="bold">OK</emphasis>from the
            <emphasis role="bold">Flike Editor</emphasis> window to return to the main <emphasis role="bold">TUFLOW Flike</emphasis> window and select <emphasis role="bold">Fit
            model</emphasis> from the <emphasis role="bold">Options menu</emphasis> to run TUFLOW
          Flike. This should result in the Probability plot as shown in <xref linkend="b3_ch2_f_9a967"/>.</para>
        <figure xml:id="b3_ch2_f_9a967">
          <title><emphasis role="bold">Probability plot of with prior regional information</emphasis></title>
          <imageobject>
            <imagedata fileref="../../figures/3021.PNG"/>
          </imageobject>
        </figure>
       
          <para><xref linkend="b3_ch2_f_9a967"/> presents the probability plot for the LP3 model
            fitted to the gauged data with prior information on the skewness. Comparison of the
            results from this example with the results from Example 3 (see <xref linkend="b3_ch2_f_qk0wd"/>) reveals substantially reduced uncertainty in the right
            hand tail.</para>
          <figure xml:id="b3_ch2_f_qk0wd">
            <title><emphasis role="bold">Comparison between the results from Example 3 and Example 5</emphasis></title>
            <imageobject>
              <imagedata fileref="../../figures/3066.PNG"/>
            </imageobject>
          </figure>
        
      
      <table xml:id="b3_ch2_t_ap1ps">
        <caption>Comparison of LP3 Parameters with and without prior information</caption>
        <col width="20%"/>
        <col width="20%"/>
        <col width="20%"/>
        <col width="20%"/>
        <col width="20%"/>
        <thead>
          <tr>
            <th><emphasis role="bold">LP3 Parameter</emphasis></th>
            <th><emphasis role="bold">No Prior Information</emphasis></th>
            <th/>
            <th><emphasis role="bold">With Prior Information</emphasis></th>
            <th/>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td/>
            <td>Mean</td>
            <td>Std. Deviation</td>
            <td>Mean</td>
            <td>Std. Deviation</td>
          </tr>
          <tr>
            <td>m</td>
            <td>6.433</td>
            <td>0.262</td>
            <td>6.421</td>
            <td>0.251</td>
          </tr>
          <tr>
            <td>log<subscript>e</subscript>s</td>
            <td>0.353</td>
            <td>0.144</td>
            <td>0.320</td>
            <td>0.131</td>
          </tr>
          <tr>
            <td>g</td>
            <td>0.131</td>
            <td>0.479</td>
            <td>0.019</td>
            <td>0.261</td>
          </tr>
        </tbody>
      </table>
      <para>
      
      </para>
      <para>
        <para><xref linkend="b3_ch2_t_sbwn2"/> presents selected AEP quantiles qY and their 90%
          confidence limits. This table further illustrates the benefit of incorporating regional
          information. For example, for the 1% AEP flood the 5% and 95% confidence limits are
          respectively 37% and 546% of the quantile q1% when no prior information is used. These
          limits are reduced to 46% and 292%, respectively using prior regional information.</para>
      </para>
      <table xml:id="b3_ch2_t_sbwn2">
        <caption>Selected Results</caption>
        <col width="14%"/>
        <col width="14%"/>
        <col width="14%"/>
        <col width="14%"/>
        <col width="14%"/>
        <col width="14%"/>
        <col width="14%"/>
        <thead>
          <tr>
            <th><emphasis role="bold">AEP (%)</emphasis></th>
            <th><emphasis role="bold">No Prior Information</emphasis></th>
            <th/>
            <th/>
            <th><emphasis role="bold">With Prior Information</emphasis></th>
            <th/>
            <th/>
          </tr>
          <tr>
            <th/>
            <th><emphasis role="bold">Quantile Estimate q</emphasis><subscript>Y</subscript></th>
            <th><emphasis role="bold">Quantile Confidence 5% Limit</emphasis></th>
            <th><emphasis role="bold">Quantile Confidence 95% Limit</emphasis></th>
            <th><emphasis role="bold">Quantile Estimate q</emphasis><subscript>Y</subscript></th>
            <th><emphasis role="bold">Quantile Confidence 5% Limit</emphasis></th>
            <th><emphasis role="bold">Quantile Confidence 95% Limit</emphasis></th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>10%</td>
            <td>3,929</td>
            <td>2,229</td>
            <td>8,408</td>
            <td>3,598</td>
            <td>2,172</td>
            <td>6,702</td>
          </tr>
          <tr>
            <td>2%</td>
            <td>12,786</td>
            <td>5,502</td>
            <td>51,010</td>
            <td>10,535</td>
            <td>5,310</td>
            <td>26,633</td>
          </tr>
          <tr>
            <td>1%</td>
            <td>19,572</td>
            <td>7,188</td>
            <td>107,122</td>
            <td>15,413</td>
            <td>7,093</td>
            <td>45,087</td>
          </tr>
          <tr>
            <td>0.2%</td>
            <td>47,034</td>
            <td>11,507</td>
            <td>570,635</td>
            <td>33,365</td>
            <td>12,244</td>
            <td>134,107</td>
          </tr>
        </tbody>
      </table>
  
    </section>
  </section>

  <section xml:id="b3_ch2_s_oyr7w">
    <title>Example 6: Censoring PILFs using multiple Grubbs-Beck test</title>
    <para>In many Australian watercourses there are often years in which there are no floods. The
      annual maximum from those years are not representative of the population of floods and can
      unduly influence the fit of the distribution as discussed in Section 2.6.3.9. The flow values
      are referred to as Potentially Influential Low Flows (PILFs). It is recommended that in all
      flood frequency analyses the removal of these flows is investigated using the multiple
      Grubbs-Beck test to identify PILFs. The following example is taken from Pedruco <emphasis
        role="italic">et al</emphasis>. (2013) using data provided by the Wimmera Catchment
      Management Authority. The table at the end of this example lists 56 years of Annual Maximum
      discharges for the Wimmera River at Glynwylln. This data is included in the TUFLOW Flike
      download and was installed in the <emphasis role="bold">data</emphasis> folder in the install
      location of TUFLOW Flike. This location will be something similar to <emphasis role="italic"
        >C:\TUFLOW Flike\data\wimmeraGaugedFlows.csv</emphasis>.</para>
    <para>This example will examine the influence of PILFs and demonstrate how to use the multiple
      Grubbs-Beck test to safely remove them from the flood frequency analysis.</para>
    <section xml:id="b3_ch2_s_zda5a">
      <title>Launch TUFLOW Flike and Import Data</title>
      <para>As in Example 3 launch TUFLOW Flike and create a new <emphasis role="bold"
          >.fld</emphasis> file. Save the opened .fld as say, <emphasis role="bold"
          >Example_6.fld</emphasis>. Import the Wimmera River data in the same way that the
        Singleton data was imported, ensuring that the structure of the data has been checked using
        the <emphasis role="bold">View</emphasis> button. The <emphasis role="bold">Records
        </emphasis>start in the second row (skip the first), <emphasis role="bold">Years</emphasis>
        are in column 1 and the <emphasis role="bold">Gauged values</emphasis> are in column 2.
        Configure the import options and import the data.</para>
      <para>Once this has been done and the <emphasis role="bold">Gauged values</emphasis> have been
        ranked in descending order the Flike Editor window should look like <xref
          linkend="b3_ch2_f_6lj7c"/>.</para>
      <figure xml:id="b3_ch2_f_6lj7c">
        <title><emphasis role="bold">TUFLOW Flike editor window with Wimmera data</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3067.PNG"/>
        </imageobject>
      </figure>
    </section>
    <section xml:id="b3_ch2_s_22b6v">
      <title>Fit Distribution</title>
      <para>The Wimmera data will be fitted to a Generalised Extreme Value (GEV) distribution. To do
        this, return to the <emphasis role="bold">Flike Editor General</emphasis> tab and ensure
        that the following settings have been chosen:</para>
      <itemizedlist>
        <listitem>
          <para>Bayesian inference method with <emphasis role="bold">No prior information;
            </emphasis></para>
        </listitem>
        <listitem>
          <para>The <emphasis role="bold">GEV</emphasis> probability model; and</para>
        </listitem>
        <listitem>
          <para>The <emphasis role="bold">Maximum AEP</emphasis> is set to 200 years</para>
        </listitem>
      </itemizedlist>
      <para>Once these settings have been selected, select <emphasis role="bold">OK</emphasis> and
        run TUFLOW Flike in the usual way.</para>
    </section>
    <section xml:id="b3_ch2_s_njj43">
      <title>Initial Results </title>
      <para>When TUFLOW Flike has run a new probability plot window will open. The plot will
          <emphasis role="bold">not</emphasis> look like <xref linkend="b3_ch2_f_z3jbp"/>. To expose
        a better view of the distributions fit, the plot scale should be changed using the <emphasis
          role="bold">Plot Scale</emphasis> button from a <emphasis role="bold">Gumbel
        </emphasis>plot scale to a <emphasis role="bold">Gumbel-log</emphasis> plot scale and the
        y-axis rescaled using the <emphasis role="bold">Rescale</emphasis> button to have a minimum
        of 0.0 and a maximum of 4.0.</para>
      <para>In <xref linkend="b3_ch2_f_z3jbp"/>, the fit to the right-hand tail is not satisfactory.
        The expected quantiles are significantly greater than the gauged data, further the largest 3
        data points fall outside of the lower 90% confidence limits.</para>
      <figure xml:id="b3_ch2_f_z3jbp">
        <title><emphasis role="bold">Initial probability plot for Wimmera data with
          GEV</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3022.PNG"/>
        </imageobject>
      </figure>
    </section>
    <section xml:id="b3_ch2_s_d6qyg">
      <title>Multiple Grubbs-Beck test</title>
      <para>The fit of the distribution can be improved by removing PILFs. In TUFLOW Flike this can
        be done using the multiple Grubbs-Beck test, to do this, return to the <emphasis role="bold"
          >Flike Editor</emphasis> window and select the <emphasis role="bold">Censor</emphasis>
        button. TUFLOW Flike will run the multiple Grubbs-Beck test on the Wimmera data and when
        finished it will return a window similar to the one shown in <xref linkend="b3_ch2_f_iql1y"
        />. The multiple Grubbs-Beck test has detected 27 possible PILFs, select <emphasis
          role="bold">Yes</emphasis> to censor them.</para>
      <figure xml:id="b3_ch2_f_iql1y">
        <title><emphasis role="bold">Results of the multiple Grubbs-Beck test</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3023.PNG"/>
        </imageobject>
      </figure>
      <para>On agreeing to censor these flows, TUFLOW Flike automatically performs two changes to
        the inference setup:</para>
      <orderedlist>
        <listitem>
          <para>The 27 lowest discharges are excluded from the calibration.</para>
        </listitem>
        <listitem>
          <para>A censored threshold is added, with the information that there are 27 Annual Maximum
            discharges that lie below the threshold of 54.396m<superscript>3</superscript>/s which
            corresponds the 28th ranked discharge.</para>
        </listitem>
      </orderedlist>
      <para>These are further explained below</para>
      <section xml:id="b3_ch2_s_6nq35">
        <title>Excluded Data</title>
        <para>The exclusion of the lowest 27 discharges can be seen in the <emphasis role="bold"
            >Observed Flows</emphasis> tab of the <emphasis role="bold">Flike Editor</emphasis> as
          shown in <xref linkend="b3_ch2_f_tbyqe"/>. In this tab all the values below the threshold
          have the <emphasis role="bold">Exclude check</emphasis> box crossed, this can be seen by
          scrolling down the window or by re-ranking the data and selecting <emphasis role="bold"
            >Ascending</emphasis>. If you have re-ranked the data in ascending order re-rank it back
          into <emphasis role="bold">Decesending</emphasis> order.</para>
        <figure xml:id="b3_ch2_f_tbyqe">
          <title><emphasis role="bold">Excluded gauged values</emphasis></title>
          <imageobject>
            <imagedata fileref="../../figures/3024.PNG"/>
          </imageobject>
        </figure>
      </section>
      <section xml:id="b3_ch2_s_eudes">
        <title>Censoring Threshold</title>
        <para>The addition of the censored threshold appears in the <emphasis role="bold">Censoring
            of observed values</emphasis> tab of the <emphasis role="bold">Flike Editor</emphasis>
          as shown in <xref linkend="b3_ch2_f_xdzap"/>. The <emphasis role="bold"
            >Threshold</emphasis> value (54.396m<superscript>3</superscript>/s) has been
          automatically populated together with the years that are greater than the threshold (0).
          The number of years less than the threshold (27) has also been populated. What this is
          telling TUFLOW Flike is that 27 years of discharges are less than the threshold are being
          censored; that is, gauged values are not considered but the frequency is. The <emphasis
            role="bold">Start year</emphasis> and <emphasis role="bold">End year</emphasis> are also
          populated with dummy year ranges beginning 1000BC. This is done to satisfy an automatic
          check in TUFLOW Flike designed to assist in the entry of historic data.</para>
        <figure xml:id="b3_ch2_f_xdzap">
          <title><emphasis role="bold">Censoring of observed values</emphasis></title>
          <imageobject>
            <imagedata fileref="../../figures/3068.PNG"/>
          </imageobject>
        </figure>
      </section>
    </section>
    <section xml:id="b3_ch2_s_b2jgj">
      <title>Results using multiple Grubbs-Beck test</title>
      <para>Return to the main <emphasis role="bold">TUFLOW Flike</emphasis> window and run TUFLOW
        FLIKE by selecting <emphasis role="bold">Fit model</emphasis>. As usual, a <emphasis
          role="bold">Probability plot</emphasis> window will automatically appear, as for the
        initial results change the plot scale to Gumbel-log and rescale the y-axis to have a minimum
        of 0.0 and a maximum of 4.0. The resulting plot will look like <xref
          linkend="b3_ch2_f_cf285"/>.</para>
      <para>A comparison of <xref linkend="b3_ch2_f_z3jbp"/> and <xref linkend="b3_ch2_f_cf285"/>
        shows the improved fit, in <xref linkend="b3_ch2_f_cf285"/> all of the gauged data points
        fall within the 90% confidence limits. Further, censoring the PILFs using the multiple
        Grubbs-Beck test has significantly altered the quantile estimates and reduced the confidence
        limits as shown in <xref linkend="b3_ch2_t_a42ds"/>. For instance the quantile q1% when
        PILFs are excluded is around 21% of the initial estimate. The lower and upper confidence
        limits have been considerable reduced, initially they were 30% and 500% of the quantile q1%
        and following the removal of PILFs they became 68% and 220% of the quantile q1%.</para>
      <figure xml:id="b3_ch2_f_cf285">
        <title><emphasis role="bold">GEV fit - 56 years AM of gauged discharge - Using multiple
            Grubbs-Beck test</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3025.PNG"/>
        </imageobject>
      </figure>
        <table xml:id="b3_ch2_t_a42ds">
          <caption>Selected Results</caption>
          <col width="14%"/>
          <col width="14%"/>
          <col width="14%"/>
          <col width="14%"/>
          <col width="14%"/>
          <col width="14%"/>
          <col width="14%"/>
          <thead>
            <tr>
              <th><emphasis role="bold">AEP (%)</emphasis></th>
              <th><emphasis role="bold">No Removal of PILFS</emphasis></th>
              <th/>
              <th/>
              <th><emphasis role="bold">Removal of PILFS</emphasis></th>
              <th/>
              <th/>
            </tr>
            <tr>
              <th/>
              <th><emphasis role="bold">Quantile Estimate q<subscript>Y</subscript></emphasis></th>
              <th><emphasis role="bold">Quantile Confidence 5% Limit</emphasis></th>
              <th><emphasis role="bold">Quantile Confidence 95% Limit</emphasis></th>
              <th><emphasis role="bold">Quantile Estimate q<subscript>Y</subscript></emphasis></th>
              <th><emphasis role="bold">Quantile Confidence 5% Limit</emphasis></th>
              <th><emphasis role="bold">Quantile Confidence 95% Limit</emphasis></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>10%</td>
              <td>286</td>
              <td>172</td>
              <td>578</td>
              <td>227</td>
              <td>177</td>
              <td>311</td>
            </tr>
            <tr>
              <td>2%</td>
              <td>1,315</td>
              <td>493</td>
              <td>4,975</td>
              <td>423</td>
              <td>304</td>
              <td>784</td>
            </tr>
            <tr>
              <td>1%</td>
              <td>2,481</td>
              <td>737</td>
              <td>12,398</td>
              <td>521</td>
              <td>354</td>
              <td>1,145</td>
            </tr>
            <tr>
              <td>0.2%</td>
              <td>10,696</td>
              <td>1,802</td>
              <td>101,034</td>
              <td>789</td>
              <td>448</td>
              <td>2,813</td>
            </tr>
          </tbody>
        </table>
   
      <para><emphasis role="bold"> Annual Maximum data for the Wimmera River at
        Glynwylln</emphasis></para>
      <informaltable>
        <col width="7%"/>
        <col width="7%"/>
        <col width="7%"/>
        <col width="7%"/>
        <col width="7%"/>
        <col width="7%"/>
        <col width="7%"/>
        <thead/>
        <tbody>
          <tr>
            <td>464.35</td>
            <td>167.72</td>
            <td>119.63</td>
            <td>71.4</td>
            <td>32.18</td>
            <td>14.16</td>
            <td>8.52</td>
          </tr>
          <tr>
            <td>395.65</td>
            <td>155.22</td>
            <td>110.56</td>
            <td>69.67</td>
            <td>25.91</td>
            <td>12.64</td>
            <td>3.22</td>
          </tr>
          <tr>
            <td>285.92</td>
            <td>147</td>
            <td>102.62</td>
            <td>67.49</td>
            <td>24.83</td>
            <td>11.9</td>
            <td>2.28</td>
          </tr>
          <tr>
            <td>278.01</td>
            <td>143.99</td>
            <td>97.32</td>
            <td>61.64</td>
            <td>23.95</td>
            <td>11.79</td>
            <td>2.13</td>
          </tr>
          <tr>
            <td>235.22</td>
            <td>143.62</td>
            <td>96.78</td>
            <td>54.4</td>
            <td>22.76</td>
            <td>11.41</td>
            <td>1.9</td>
          </tr>
          <tr>
            <td>211.91</td>
            <td>142.66</td>
            <td>87.98</td>
            <td>38.62</td>
            <td>19.04</td>
            <td>10.8</td>
            <td>1.43</td>
          </tr>
          <tr>
            <td>173.79</td>
            <td>134.36</td>
            <td>79.15</td>
            <td>36.62</td>
            <td>17.37</td>
            <td>10.31</td>
            <td>1.16</td>
          </tr>
          <tr>
            <td>170.13</td>
            <td>123.8</td>
            <td>77.03</td>
            <td>34.07</td>
            <td>14.87</td>
            <td>10.08</td>
            <td>0.01</td>
          </tr>
        </tbody>
      </informaltable>
      <para> Example 7: Improving poor fits using censoring of low flow data</para>
    </section>
  </section>

  <section xml:id="b3_ch2_s_k1ei7">
    <para>The standard probability models such as GEV and LP3 may not adequately fit flood data for
      a variety of reasons, for example Probable Influential Low Flow Flows (PILFs). In this example
      the censoring of data is used to censor low discharge data and improve the fit of the
      distribution to the data.</para>
    <para>Often the poor fit of a distribution is associated with a sigmoidal probability plot as
      illustrated in <xref linkend="b3_ch2_f_irqh6"/>. In such cases a four or five-parameter
      distributions which have sufficient degrees of freedom can be used to track the data in both
      upper and lower tails of the sigmoidal curve. Alternatively a calibration approach that gives
      less weight to smaller floods can be adopted. The second approach is adopted in this
      example.</para>
    <figure xml:id="b3_ch2_f_irqh6">
      <title><emphasis role="bold">Bayesian fit to all gauged data Gumbel probability plot</emphasis></title>
      <imageobject>
        <imagedata fileref="../../figures/3026.PNG"/>
      </imageobject>
    </figure>
    <section xml:id="b3_ch2_s_vadix">
      <title>Launch TUFLOW Flike and Import Data</title>
      <para>As in previous examples launch TUFLOW Flike, create a new <emphasis role="bold">.fld</emphasis> file and import the Albert River at Bromfleet data (<emphasis role="italic">albertRvGaugedFlows.txt)</emphasis> file which was included in the TUFLOW
        Flike install in the <emphasis role="bold">data</emphasis> directory. Note the structure of
        this file and configure the <emphasis role="bold">Import gauged values</emphasis> window.
        The Albert River at Broomfleet data is included at the end of this example. </para>
    </section>
    <section xml:id="b3_ch2_s_j7tax">
      <title>Fit GEV Distribution</title>
      <para>To recreate <xref linkend="b3_ch2_f_irqh6"/> fit a GEV distribution to the Albert River
        data and accept the defaults in the <emphasis role="bold">General</emphasis> tab of the
          <emphasis role="bold">FLIKE Editor</emphasis>. The plot in <xref linkend="b3_ch2_f_irqh6"/> can be recreated by changing the plot scale to <emphasis role="bold">Gumbel</emphasis>
        and rescaling the y-axis to 0 and 4,000.</para>
      <para><xref linkend="b3_ch2_f_irqh6"/> displays the GEV Bayesian fit on a Gumbel probability
        plot. Although the observed floods are largely contained within the 90% confidence limits,
        the fit, nonetheless, is poor – the data exhibit a sigmoidal trend with reverse curvature
        developing for floods with an AEP greater than 50%. It appears that the confidence limits
        have been inflated because the GEV fit represents a poor compromise.</para>
    </section>
    <section xml:id="b3_ch2_s_qrtgk">
      <title>Use the multiple Grubbs Beck test to improve fit</title>
      <para>The first step in improving the poor fit of this data is to use the multiple Grubbs Beck
        test to remove PILFs. Repeat the procedure outline in the previous example. This will result
        in the censoring of 5 data points with a threshold of
        36.509m<superscript>3</superscript>/s.</para>
      <para>Now run TUFLOW Flike and fit the model. Changing the plot scale and rescale the y-axis
        as above will result in <xref linkend="b3_ch2_f_8wx12"/>.</para>
      <para><xref linkend="b3_ch2_f_8wx12"/> displays the fit after censoring the 5 low outliers
        identified by the multiple Grubbs-Beck test. The improvement in fit is marginal at best over
          <xref linkend="b3_ch2_f_irqh6"/>.</para>
      <figure xml:id="b3_ch2_f_8wx12">
        <title><emphasis role="bold">Bayesian fit with 5 low outliers censored after application of multiple Grubbs-Beck test</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3027.PNG"/>
        </imageobject>
      </figure>
    </section>
    <section xml:id="b3_ch2_s_2j4e5">
      <title>Trial and error approach</title>
      <para>To deal with this poor fit, a trial-and-error approach to selecting the threshold
        discharge for the censoring low flows can be used to obtain a fit that favours the right
        hand tail of the distribution. This involves testing different threshold values until an
        acceptable fit is produced. <xref linkend="b3_ch2_f_ck6ks"/> illustrates one such fit. To
        de-emphasise the left hand tail the floods below the threshold of 250
          m<superscript>3</superscript>/s were censored. This means the GEV distribution was fitted
        to:</para>
      <itemizedlist>
        <listitem>
          <para>A gauged record consisting of the 27 floods above
            250m<superscript>3</superscript>/s; and</para>
        </listitem>
        <listitem>
          <para>A censored record consisting of 23 floods below the threshold of
              250m<superscript>3</superscript>/s and 0 floods above this threshold.</para>
        </listitem>
      </itemizedlist>
      <para>To do this in TUFLOW Flike there are two steps, as in Example 6, these are:</para>
      <itemizedlist>
        <listitem>
          <para>Exclude the flows below 250m<superscript>3</superscript>/s</para>
        </listitem>
        <listitem>
          <para>Create a censoring threshold</para>
        </listitem>
      </itemizedlist>
      <para>This is essentially the same process that was undertaken to exclude flows in Example 6
        except it needs to be done manually. This is outlined below.</para>
      <section xml:id="b3_ch2_s_akbjo">
        <title>Excluded data</title>
        <para>The flows below 250m<superscript>3</superscript>/s need to be excluded from the
          analysis. To do this select the <emphasis role="bold">Observed values</emphasis> tab of
          the <emphasis role="bold">Flike Editor </emphasis>and choose the <emphasis role="bold">Block exclude</emphasis> button. Enter 250 into <emphasis role="bold">Value
            below</emphasis><emphasis role="bold">which values are to be excluded</emphasis> text
          box and select <emphasis role="bold">OK</emphasis>. This will exclude all values below
            250m<superscript>3</superscript>/s which can be confirmed by scrolling down the table in
          the <emphasis role="bold">Observed values</emphasis> tab.</para>
      </section>
      <section xml:id="b3_ch2_s_xyxg7">
        <title>Censoring threshold</title>
        <para>As in the previous example a censoring threshold needs to be entered into the
          Censoring of observed values tab. Populate the tab with the following information:</para>
        <itemizedlist>
          <listitem>
            <para><emphasis role="bold">Threshold value</emphasis>: 250</para>
          </listitem>
          <listitem>
            <para>Years greater than threshold (<emphasis role="bold">Yrs &gt;
              threshold</emphasis>): 0</para>
          </listitem>
          <listitem>
            <para>Years less than or equal to threshold (<emphasis role="bold">Yrs &lt;=
                threshold</emphasis>): 23</para>
          </listitem>
          <listitem>
            <para><emphasis role="bold">Start year</emphasis>: 1000</para>
          </listitem>
          <listitem>
            <para><emphasis role="bold">End year</emphasis>: 1022</para>
          </listitem>
        </itemizedlist>
      </section>
    </section>
    <section xml:id="b3_ch2_s_87t31">
      <title>Results of the trial and error approach</title>
      <para>Run TUFLOW Flike in the usual way and a Probability plot similar to <xref linkend="b3_ch2_f_ck6ks"/> will be obtained. </para>
      <para>The censored record provides an anchor point for the GEV distribution – it ensures that
        the chance of an Annual Maximum flood being less than 250m<superscript>3</superscript>/s is
        about 23/50 without forcing the GEV to fit the peaks below the
          250m<superscript>3</superscript>/s threshold. The fit effectively disregards floods with a
        greater than 50% AEP and provides a good fit to the upper tail. Another benefit is the
        substantially reduced 90% confidence limits which can be reviewed by examining the results
        files.</para>
      <figure xml:id="b3_ch2_f_ck6ks">
        <title><emphasis role="bold">Bayesian fit with floods below 250
              m<superscript>3</superscript>/s threshold treated as censored
          observations</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3028.PNG"/>
        </imageobject>
      </figure>
      <para><emphasis role="bold">Annual Maximum data for the Albert River at Bromfleet
          data</emphasis></para>
      <informaltable>
        <caption/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <thead/>
        <tbody>
          <tr>
            <td>1765.92</td>
            <td>1689.51</td>
            <td>1652.72</td>
            <td>1468.77</td>
            <td>1364.06</td>
            <td>1341.42</td>
            <td>1327.27</td>
            <td>1273.5</td>
          </tr>
          <tr>
            <td>1214.07</td>
            <td>1185.77</td>
            <td>1177.28</td>
            <td>1086.72</td>
            <td>865.98</td>
            <td>863.15</td>
            <td>860.32</td>
            <td>761.27</td>
          </tr>
          <tr>
            <td>761.27</td>
            <td>752.78</td>
            <td>676.37</td>
            <td>466.95</td>
            <td>461.29</td>
            <td>384.88</td>
            <td>362.24</td>
            <td>305.64</td>
          </tr>
          <tr>
            <td>302.81</td>
            <td>285.83</td>
            <td>271.68</td>
            <td>294.61</td>
            <td>249.61</td>
            <td>220.74</td>
            <td>210.55</td>
            <td>190.74</td>
          </tr>
          <tr>
            <td>156.5</td>
            <td>156.22</td>
            <td>131.03</td>
            <td>124.52</td>
            <td>116.88</td>
            <td>113.77</td>
            <td>99.9</td>
            <td>95.65</td>
          </tr>
          <tr>
            <td>88.3</td>
            <td>87.73</td>
            <td>78.11</td>
            <td>72.73</td>
            <td>36.51</td>
            <td>22.36</td>
            <td>16.7</td>
            <td>15.85</td>
          </tr>
          <tr>
            <td>15.57</td>
            <td>13.02</td>
            <td colspan="6"/>
          </tr>
        </tbody>
      </informaltable>
    </section>
  </section>

  <section xml:id="b3_ch2_s_j695i">
    <title>Example 8: A Non-Homogeneous Flood Probability Model</title>

    <para>The work of Micevski et al. (2003) illustrates an example of a
    non-homogeneous model. An indicator time series based on the IPO time
    series (Figure 7) was used to create the exogeneous vector x</para>

    <equation xml:id="b3_ch2_e_rqohy">
      <m:math display="block">
        <m:mrow>
          <m:mi>x</m:mi>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:msub>
              <m:mi>{I</m:mi>

              <m:mi>t</m:mi>
            </m:msub>

            <m:mo>, t = 1,...,n}</m:mo>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>where the indicator</para>

    <equation xml:id="b3_ch2_e_uynzz">
      <m:math display="block">
        <m:mrow>
          <m:msub>
            <m:mi>I</m:mi>

            <m:mi>t</m:mi>
          </m:msub>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mo>{</m:mo>

            <m:mtable>
              <m:mtr>
                <m:mtd>
                  <m:mrow>
                    <m:mi>1 if</m:mi>

                    <m:msub>
                      <m:mi>IPO</m:mi>

                      <m:mi>t</m:mi>
                    </m:msub>

                    <m:mrow>
                      <m:mi>≥</m:mi>

                      <m:msub>
                        <m:mi>IPO</m:mi>

                        <m:mi>thresh</m:mi>
                      </m:msub>
                    </m:mrow>
                  </m:mrow>
                </m:mtd>
              </m:mtr>

              <m:mtr>
                <m:mtd>
                  <m:mrow>
                    <m:mi>0 if</m:mi>

                    <m:msub>
                      <m:mi>IPO</m:mi>

                      <m:mi>t</m:mi>
                    </m:msub>

                    <m:msub>
                      <m:mi>&lt; IPO</m:mi>

                      <m:mi>thresh</m:mi>
                    </m:msub>
                  </m:mrow>
                </m:mtd>
              </m:mtr>
            </m:mtable>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>IPO<subscript>t</subscript> is the IPO index for year t and
    IPO<subscript>thresh</subscript> is a threshold value equal to
    -0.125.</para>

    <para>At each of the 33 NSW sites considered by Micevski et al. the AM
    peak flows were stratified according to the indicator It. A 2-parameter
    log-normal distribution was fitted to the gauged flows with indicator
    equal to 1 – this is the IPO+ distribution. Likewise, a 2-parameter
    log-normal distribution was fitted to the gauged flows with indicator
    equal to 0 – this is the IPO- distribution. Figure E3-1 presents the
    histogram for the ratio of the IPO- and IPO+ floods for selected 1 in Y
    AEPs. If the the IPO+ and IPO- distributions were homogeneous then about
    half of the sites should have a flood ratio &lt; 1 – Figure E8-1 shows
    otherwise.</para>

    <para>Figures E8-2 and E8-3 present log normal fits to the IPO+ and IPO-
    annual maximum flood data for the Clarence river at Lilydale respectively.
    Though the adequacy of the log normal model to fit high floods may be
    questioned, in the AEP range 1 in 2 to 1 in 10 years, the IPO- floods are
    about 2.6 times the IPO+ floods with the same AEP.</para>

    <figure xml:id="b3_ch2_f_l7nea">
      <title>Histogram of IPO- and IPO+ flood ratios.</title>

 
        <imageobject>
          <imagedata fileref="figures/FigureE6_15.JPG"/>
        </imageobject>
      
    </figure>

    <figure xml:id="b3_ch2_f_9ppj8">
      <title>Log-normal fit to 43 years of IPO+ data for the Clarence river at
      Lilydale (units ML/day).</title>

 
        <imageobject>
          <imagedata fileref="figures/FigureE6_16.JPG"/>
        </imageobject>
      
    </figure>

    <figure xml:id="b3_ch2_f_f3kfz">
      <title>Log-normal fit to 33 years of IPO- data for the Clarence river at
      Lilydale (units ML/day).</title>

 
        <imageobject>
          <imagedata fileref="figures/FigureE6_17.JPG"/>
        </imageobject>
      
    </figure>

    <figure xml:id="b3_ch2_f_l79jq">
      <title>Log-normal fit to 76 years of data for the Clarence river at
      Lilydale (units ML/day).</title>

 
        <imageobject>
          <imagedata fileref="figures/FigureE6_18.JPG"/>
        </imageobject>
      
    </figure>

    <para>To avoid bias in estimating long-term flood risk it is essential
    that the gauged record adequately span both IPO+ and IPO- years. In this
    example, the IPO+ record is 43 years and the IPO- record is 33 years in
    length. With reference to Figure 7 this length of record appears to
    adequately sample both IPO epochs. This suggests that fitting to all the
    data will yield a largely unbiased estimate of the long-term flood risk.
    Figure E8-4 illustrates a log normal fit to all the data.</para>

    <para>A better appreciation of the differences in flood risk can be
    gleaned by considering Figure E8-5 which presents the fitted log normal
    distributions to the IPO+, IPO- and total data. During an IPO+ period a
    flood peak of 100 m<superscript>3</superscript>/s has a 1 in 20 AEP while
    during an IPO- period it has a 1 in 4 AEP. Likewise a flood peak of 200
    m<superscript>3</superscript> /s has 1 in 100 and 1 in 10 AEPs for IPO+
    and IPO- periods respectively. The differences in flood risk are
    considerable. If a short gauged record falling largely in the IPO+ period
    was used, a standard flood frequency analysis could seriously
    underestimate the long-term or marginal flood risk.</para>

    <para>The marginal flood risk can be derived by combining the IPO+ and
    IPO- distribution using eqn (8) to give</para>

    <equation xml:id="b3_ch2_e_lcql0">
      <m:math display="block">
        <m:mrow>
          <m:mrow>
            <m:mi>P(Q≤</m:mi>

            <m:mo>q)</m:mo>

            <m:mi>=</m:mi>

            <m:mo>P(x</m:mo>
          </m:mrow>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mi>0)</m:mi>

            <m:mrow>
              <m:munderover>
                <m:mo>∫</m:mo>

                <m:mi>0</m:mi>

                <m:mi>q</m:mi>
              </m:munderover>

              <m:mi>p(z|</m:mi>
            </m:mrow>

            <m:mi>θ(x=0))dz + P (x=1)</m:mi>

            <m:mrow>
              <m:munderover>
                <m:mo>∫</m:mo>

                <m:mi>0</m:mi>

                <m:mi>q</m:mi>
              </m:munderover>

              <m:mi>p(z|</m:mi>
            </m:mrow>

            <m:mi>θ(x=1))dz</m:mi>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>The exogenous variable x can take two values, 0 or 1, depending on
    the IPO epoch. P(x=0), the probability of being in an IPO- epoch, is
    assigned the value 33/76 based on the observation that 33 of the 76 years
    of record were in the IPO- epoch. Likewise P(x=1), the probability of
    being in an IPO+ epoch, is assigned the value 43/76. It follows that
    p(z|<inlineequation>
        <m:math display="inline">
          <m:mi>θ</m:mi>
        </m:math>
      </inlineequation>,x=0) and p(z|<inlineequation>
        <m:math display="inline">
          <m:mi>θ</m:mi>
        </m:math>
      </inlineequation>,x=1) are the log normal pdfs fitted to IOP- and IPO+
    data respectively</para>

    <para>The derived marginal distribution is plotted in Figure E8-5. It
    almost exactly matches the log normal distribution fitted to all the
    data.</para>

    <figure xml:id="b3_ch2_f_81xae">
      <title>Marginal, IPO+ and IPO+ log-normal distributions for the Clarence
      river at Lilydale</title>

   
        <imageobject>
          <imagedata fileref="figures/FigureE6_19.JPG"/>
        </imageobject>
      
    </figure>
  </section>

  <section xml:id="b3_ch2_s_f243w">
    <title>Example 9: L moments fit to gauged data</title>
    <para>This example illustrates fitting a GEV distribution to gauged data using L moments. L
      moments are a special case of LH moments where there is no shift (H=0). The procedure to use L
      moments to fit a distribution is set out in Section 2.6.4. In this example Annual Maximum
      flood data for the Styx River at Jeogla will be fitted using L moments. The flood data are
      listed at the end of this example.</para>
    <para>The procedure for fitting distributions by L moments can be completed by hand, and also
      using TUFLOW Flike. Both of these techniques will be outlined in this example.</para>
    <section xml:id="b3_ch2_s_ai5el">
      <title>L moments by Hand</title>
      <para>The first four L moments can be estimated by equations 3.2.41 to 3.2.44 and are reported
        in <xref linkend="b3_ch2_t_kvf1l"/>. The GEV parameter estimates can be calculated by
        substituting the L moment estimates into the equations in Table 3.2.3 to estimate <emphasis role="italic">τ</emphasis>, <emphasis role="italic">Κ</emphasis> and <emphasis role="italic">α</emphasis>. The standard deviation and correlation were derived from 5,000
        bootstrapped samples following the procedure described in Section 2.6.4.6 and Box 7 (Section
        2.9.7). Note standard deviation and correlation cannot be calculated by hand.</para>
      <table xml:id="b3_ch2_t_kvf1l">
        <caption>L Moment and GEV Parameter Estimates</caption>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <thead>
          <tr>
            <th>L Moment</th>
            <th>L Moment Estimates</th>
            <th>GEV Parameter</th>
            <th>Parameter Estimate</th>
            <th>Standard Deviation</th>
            <th>Correlation</th>
            <th>Correlation</th>
            <th>Correlation</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><mtext>&#x03BB;</mtext><subscript>1</subscript></td>
            <td>189.238</td>
            <td><mtext>&#x03C4;</mtext></td>
            <td>100.660</td>
            <td>17.657</td>
            <td>1.000</td>
            <td/>
            <td/>
            <td/>
          </tr>
          <tr>
            <td><mtext>&#x03BB;</mtext><subscript>2</subscript></td>
            <td>92.476</td>
            <td><mtext>&#x03B1;</mtext>
            </td>
            <td>104.157</td>
            <td>15.554</td>
            <td>0.597</td>
            <td>1.000</td>
            <td/>
          </tr>
          <tr>
            <td><mtext>&#x03BB;</mtext><subscript>3</subscript></td>
            <td>29.264</td>
            <td><mtext>&#x03BA;</mtext>
            </td>
            <td>-0.219</td>
            <td>0.130</td>
            <td>0.358</td>
            <td>0.268</td>
            <td>1.000</td>
          </tr>
        </tbody>
      </table>
      <para>
    
      </para>
    </section>
    <section xml:id="b3_ch2_s_5qpnz">
      <title>L moments using TUFLOW Flike</title>
      <para>L moments and the distribution parameters can be estimated in TUFLOW Flike. To do this,
        create a new .fld file and import the Styx River at Jeogla data set. Return the <emphasis role="bold">Flike Editor General</emphasis> tab. Now set the Inference method to LH
        moments fit to observed values with and check the H=0 radio box. This last option sets the
        shift to 0 (i.e. L moments). The <emphasis role="bold">Flike Editor</emphasis> window should
        look like . Run TUFLOW Flike and examine the results file for the L moments and GEV
        parameters.</para>
    <figure xml:id="b3_ch2_f_mbhq9">
        <title>Flike Editor configured for L moments</title>
     
          <imageobject>
            <imagedata fileref="../../figures/3034.PNG"/>
          </imageobject>
        
      </figure>
      <para>The following table lists 47 ranked flows for the Styx River at Jeogla.</para>
      <informaltable>
        
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <thead/>
        <tbody>
          <tr>
            <td>878</td>
            <td>541</td>
            <td>521</td>
            <td>513</td>
            <td>436</td>
            <td>411</td>
            <td>405</td>
            <td>315</td>
            <td/>
          </tr>
          <tr>
            <td>309</td>
            <td>300</td>
            <td>294</td>
            <td>258</td>
            <td>255</td>
            <td>235</td>
            <td>221</td>
            <td>220</td>
          </tr>
          <tr>
            <td>206</td>
            <td>196</td>
            <td>194</td>
            <td>190</td>
            <td>186</td>
            <td>177</td>
            <td>164</td>
            <td>126</td>
          </tr>
          <tr>
            <td>117</td>
            <td>111</td>
            <td>108</td>
            <td>105</td>
            <td>92.2</td>
            <td>88.6</td>
            <td>79.9</td>
            <td>74</td>
          </tr>
          <tr>
            <td>71.9</td>
            <td>62.6</td>
            <td>61.2</td>
            <td>60.3</td>
            <td>58</td>
            <td>53.5</td>
            <td>39.1</td>
            <td>26.7</td>
          </tr>
          <tr>
            <td>26.1</td>
            <td>23.8</td>
            <td>22.4</td>
            <td>22.1</td>
            <td>18.6</td>
            <td>13</td>
            <td>8.18</td>
            <td/>
          </tr>
        </tbody>
      </informaltable>
    </section>
  </section>

  <section xml:id="b3_ch2_s_r8uuy">
    <title>Example 10: Improving poor fits using LH moments</title>
    <para>In Example 5 the fit of the distribution to the Albert River flood series was improved by
      censoring low flows. In this example, LH moments are used instead of censoring to improve the
      fit of the GEV distribution to the flood data.</para>
    <section xml:id="b3_ch2_s_6ae3u">
      <title>Launch TUFLOW Flike</title>
      <para>This example uses the same data as <emphasis role="bold">Example 7</emphasis> for the
        Albert River at Broomfleet, so the previous <emphasis role="bold">Example 7.fld</emphasis>
        file can be used. To do this, launch TUFLOW Flike and open <emphasis role="bold">Example_7.fld</emphasis> and save the opened <emphasis role="bold">.fld</emphasis> as
          <emphasis role="bold">Example_10.fld</emphasis>. Open the <emphasis role="bold">Flike
          Editor</emphasis> to configure the LH moments fitting method. Note that the <emphasis role="bold">Example_7.fld</emphasis> file was configured with a Bayesian inference
        method.</para>
    </section>
    <section xml:id="b3_ch2_s_tb1vz">
      <title>Configure Inference Method </title>
      <para>In <emphasis role="bold">Example 7</emphasis>, a Bayesian inference method was used with
        censored low flows, so a number of changes are required to <emphasis role="bold">Example_7.fld</emphasis> before the LH moments inference method can be used. As low flows
        were censored in the previous example, these need to be included back into the analysis
        by:</para>
      <itemizedlist>
        <listitem>
          <para>Removing the censoring threshold; and</para>
        </listitem>
        <listitem>
          <para>Including all the flood data.</para>
        </listitem>
      </itemizedlist>
      <para>Ensure that the <emphasis role="bold">Bayesian with</emphasis> button is still checked.
        If the <emphasis role="bold">LH moments fit to observed values with</emphasis> radio button
        is checked the <emphasis role="bold">Censoring of observed values</emphasis> tab cannot be
        accessed.</para>
      <para>To remove the censoring threshold, select the <emphasis role="bold">Censoring of
          observed values</emphasis> tab and select the <emphasis role="bold">Clear all</emphasis>
        button.</para>
      <para>To include all the flood data, select the <emphasis role="bold">Observed
          values</emphasis> tab and select the <emphasis role="bold">Include all</emphasis> button.
        Scroll through the data to ensure that all the crosses (<emphasis role="bold">x</emphasis>)
        in the <emphasis role="bold">Exclude</emphasis> column have been removed.</para>
    </section>
    <section xml:id="b3_ch2_s_ucckw">
      <title>Fit L Moments</title>
      <para>To configure TUFLOW Flike to fit distributions using the LH moments inference method,
        return to the <emphasis role="bold">General</emphasis> tab and check the <emphasis role="bold">LH moments fit to observed values with</emphasis> radio button. In the first
        instance, select the <emphasis role="bold">H=0</emphasis> radio button. This will fit a
        distribution using L moments, this is, LH moments with no shift.</para>
      <para>TUFLOW Flike will only fit LH moments with H &gt;= 1 for the GEV distribution, however
        it will fit L moments (H = 0) for all distributions. Ensure that the GEV probability model
        has been selected.</para>
      <para>The configured<emphasis role="bold"> Flike Editor</emphasis> should look like <xref linkend="b3_ch2_f_a2f69"/>. Select OK and run TUFLOW Flike. As usual, a probability plot
        will appear together with the report file. Rescale the plot so it looks like <xref linkend="b3_ch2_f_kinix"/>.</para>
      <figure xml:id="b3_ch2_f_a2f69">
        <title><emphasis role="bold">Configured Flike Editor</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3069.PNG"/>
        </imageobject>
      </figure>
      <figure xml:id="b3_ch2_f_kinix">
        <title><emphasis role="bold">L moment fit - Albert River at Broomfleet</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3035.PNG"/>
        </imageobject>
      </figure>
      <para><xref linkend="b3_ch2_f_kinix"/> displays the GEV L moment fit on a Gumbel probability
        plot. Although the observed floods are largely contained within the 90% confidence limits,
        the fit, nonetheless, is poor with systematic departures from the data which exhibits
        reverse curvature.</para>
    </section>
    <section xml:id="b3_ch2_s_8iki7">
      <title>Fit LH Moments</title>
      <para>To deal with this poor fit, a LH moment search was conducted to find the optimal shift
        parameter using the procedure described in Section 2.6.4.5. To do this in TUFLOW Flike check
        the <emphasis role="bold">Optimized H</emphasis> radio button and run TUFLOW Flike. The
        results file reveals that the optimal shift was found to be 4. <xref linkend="b3_ch2_f_mkro8"/> presents the LH moment fit with shift equal to 4. The fit
        effectively disregards floods more frequent than the 50% AEP (around
          350m<superscript>3</superscript>/s) and provides a very good fit to upper tail.</para>
      <figure xml:id="b3_ch2_f_mkro8">
        <title><emphasis role="bold">LH moment fit with shift H=4</emphasis></title>
        <imageobject>
          <imagedata fileref="../../figures/3036.PNG"/>
        </imageobject>
      </figure>
      <para>The very significant reduction in the quantile confidence intervals is largely due to
        the shape parameter <emphasis role="italic">Κ</emphasis> changing from –0.17 to 0.50. The L
        moment fit in Figure 2 was a compromise; most of the small and medium-sized floods suggested
        an upward curvature in the probability plot which resulted in a negative GEV shape parameter
        (to enable upward curvature). In contrast, the LH moment fit favoured the large-sized floods
        which exhibit a downward curvature resulted in a positive shape parameter. For positive
          <emphasis role="italic">Κ</emphasis> the GEV has an upper bound. In this case the upper
        bound is about 2070 m3/s which is only 17% greater than the largest observed flood.</para>
      <para>A comparison of the quantile derived from the Bayesian inference method with censoring
        of PILFs and those determined using Optimised LH moments in presented in <xref linkend="b3_ch2_t_zses5"/>. The two different inference methods produce similar results in
        terms of the calculated quantiles; however, the confidence limits are smaller using the
        Bayesian framework. This highlights how LH moment results could be used to inform the
        selection of the censoring threshold for PILFs in the Bayesian framework.</para>
      <table xml:id="b3_ch2_t_zses5">
        <caption>Comparison of Quantiles using a Bayesian and LH Moments Inference Methods</caption>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <col width="12%"/>
        <thead>
          <tr>
            <th>AEP (%)</th>
            <th>Bayesian with removal of PILFS</th>
            <th/>
            <th/>
            <th>Optimised LH Moments</th>
            <th/>
            <th/>
          </tr>
          <tr>
            <th/>
            <th>Quantile Estimate q<subscript>Y</subscript></th>
            <th>Quantile Confidence 5% Limit</th>
            <th>Quantile Confidence 95% Limit</th>
            <th>Quantile Estimate q<subscript>Y</subscript></th>
            <th>Quantile Confidence 5% Limit</th>
            <th>Quantile Confidence 95% Limit</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>10%</td>
            <td>1,400</td>
            <td>1,249</td>
            <td>1,590</td>
            <td>1,406</td>
            <td>1,133</td>
            <td>1,634</td>
          </tr>
          <tr>
            <td>2%</td>
            <td>1,720</td>
            <td>1,605</td>
            <td>1,931</td>
            <td>1,782</td>
            <td>1,492</td>
            <td>2,021</td>
          </tr>
          <tr>
            <td>1%</td>
            <td>1,782</td>
            <td>1,675</td>
            <td>2,003</td>
            <td>1,868</td>
            <td>1,546</td>
            <td>2,168</td>
          </tr>
          <tr>
            <td>0.2%</td>
            <td>1,854</td>
            <td>1,757</td>
            <td>2,111</td>
            <td>1,982</td>
            <td>1,599</td>
            <td>2,482</td>
          </tr>
        </tbody>
      </table>
 
    </section>
  </section>

  <section xml:id="b3_ch2_s_01343">
    <title>Example 11: Fitting a probability model to POT data</title>

    <para>This example is a continuation of Example 9 which considers the Styx
    River at Jeogla. It illustrates fitting an exponential distribution to POT
    data. The table lists all the independent peak flows recorded over a 47
    year period that exceeded a threshold of 74
    m<superscript>3</superscript>/s – the total number of peaks was 47.
    Comparison with the annual maximum flood peaks in Example 9 reveals that
    in 15 of the 47 years of record the annual maximum peak were below the
    threshold of 74 m<superscript>3</superscript>/s.</para>
    <informaltable>
      <col width="12%"/>
      <col width="12%"/>
      <col width="12%"/>
      <col width="12%"/>
      <col width="12%"/>
      <col width="12%"/>
      <col width="12%"/>
      <col width="12%"/>
      <thead/>
      <tbody>
        <tr>
          <td>878</td>
          <td>541</td>
          <td>521</td>
          <td>513</td>
          <td>436</td>
          <td>411</td>
          <td>405</td>
          <td>315</td>
        </tr>
        <tr>
          <td>309</td>
          <td>301</td>
          <td>300</td>
          <td>294</td>
          <td>283</td>
          <td>258</td>
          <td>255</td>
          <td>255</td>
        </tr>
        <tr>
          <td>238</td>
          <td>235</td>
          <td>221</td>
          <td>220</td>
          <td>206</td>
          <td>196</td>
          <td>194</td>
          <td>190</td>
        </tr>
        <tr>
          <td>186</td>
          <td>164</td>
          <td>150</td>
          <td>149</td>
          <td>134</td>
          <td>129</td>
          <td>129</td>
          <td>126</td>
        </tr>
        <tr>
          <td>119</td>
          <td>118</td>
          <td>117</td>
          <td>117</td>
          <td>111</td>
          <td>108</td>
          <td>105</td>
          <td>98</td>
        </tr>
        <tr>
          <td>92.2</td>
          <td>92.2</td>
          <td>91.7</td>
          <td>88.6</td>
          <td>85.2</td>
          <td>79.9</td>
          <td>74</td>
          <td/>
        </tr>
      </tbody>
    </informaltable>

   

    <para>The first two L moments were estimated as 226.36 and 79.2. Noting
    that the exponential distribution is a special case of the generalised
    Pareto when <inlineequation>
        <m:math display="inline">
          <m:mi>κ</m:mi>
        </m:math>
      </inlineequation> = 0, it follows from Table 3 that the exponential
    parameters are related to the L moments by</para>

    <equation xml:id="b3_ch2_e_tixbx">
      <m:math display="block">
        <m:mrow>
          <m:msub>
            <m:mi>λ</m:mi>

            <m:mi>1</m:mi>
          </m:msub>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:msub>
              <m:mi>q</m:mi>

              <m:mi>*</m:mi>
            </m:msub>

            <m:mo>+</m:mo>

            <m:mrow>
              <m:mi>β</m:mi>

              <m:mrow>
                <m:msub>
                  <m:mi>λ</m:mi>

                  <m:mi>2</m:mi>
                </m:msub>

                <m:mo>=</m:mo>

                <m:mfrac>
                  <m:mi>β</m:mi>

                  <m:mi>2</m:mi>
                </m:mfrac>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>which yields values for q* and β of 68.11 and 158.24 respectively.
    Using eqn (B1-7), the expected number of peaks that exceed w in a year
    is</para>

    <equation xml:id="b3_ch2_e_kbsh6">
      <m:math display="block">
        <m:mrow>
          <m:mi>EY (w)</m:mi>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mi>vP(q&gt;w)</m:mi>

            <m:mrow>
              <m:mo>=</m:mo>

              <m:mrow>
                <m:mi>v exp</m:mi>

                <m:mrow>
                  <m:mo>(</m:mo>

                  <m:mrow>
                    <m:mi>-</m:mi>

                    <m:mfrac>
                      <m:mi>w-q</m:mi>

                      <m:mi>β</m:mi>
                    </m:mfrac>
                  </m:mrow>

                  <m:mo>)</m:mo>
                </m:mrow>
              </m:mrow>
            </m:mrow>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <equation xml:id="b3_ch2_e_wzulq">
      <m:math display="block">
        <m:mrow>
          <m:mrow>
            <m:msub>
              <m:mi>log</m:mi>

              <m:mi>e</m:mi>
            </m:msub>

            <m:mo>EY(w)</m:mo>
          </m:mrow>

          <m:mo>=</m:mo>

          <m:mrow>
            <m:mrow>
              <m:msub>
                <m:mi>log</m:mi>

                <m:mi>e</m:mi>
              </m:msub>

              <m:mo>v</m:mo>
            </m:mrow>

            <m:mo>+</m:mo>

            <m:mrow>
              <m:mfrac>
                <m:mi>q</m:mi>

                <m:mi>β</m:mi>
              </m:mfrac>

              <m:mo>-</m:mo>

              <m:mfrac>
                <m:mi>w</m:mi>

                <m:mi>β</m:mi>
              </m:mfrac>
            </m:mrow>
          </m:mrow>
        </m:mrow>
      </m:math>
    </equation>

    <para>where v is the average number of flood peaks above the threshold q*
    per year.</para>

    <para>Given that 47 peaks above the threshold occurred in 47 years, v
    equals 1.0. The following figure presents a plot of the fitted POT
    exponential model against the observed POT series.</para>

    <figure xml:id="b3_ch2_f_ayxhm"> 
        <imageobject>
          <imagedata fileref="figures/FigureE6_23.JPG"/>
        </imageobject>
      
    </figure>
  </section>
</section>
<?oxy_options track_changes="on"?>