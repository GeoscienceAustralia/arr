<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE book PUBLIC "-//OASIS/DTD Docbook XML V4.2//EN" "c:/program%20files%20(x86)/corel/wordperfect%20office%20x6/languages/en/XML/DTD/DocBook4.2/docbookx.dtd">
<!-- Generated by WordPerfect(R) X6 -->
<book>
<chapter label="Chapter1">
<title></title>
<para>CONCEPTUAL FRAMEWORK</para>
<para></para>
<para>Definition of Flood Probability Model</para>
<para></para>
<para>General Definition</para>
<para></para>
<para>In flood frequency analysis flood peaks are considered to be random variables. 
Following convention with flood frequency analyses, the random variable
denoting the flood peak is denoted by an upper-case symbol (e.g. Q) whereas a
specific realization (or sample) is denoted by the lower-case symbol (e.g. q). 
Where there is no ambiguity lower-case symbols will be used.</para>
<para></para>
<para>It is assumed that each realization q is statistically independent of other
realizations.  This is the standard assumption applied in flood frequency
analysis and is believed to be widely applicable (e.g. Stedinger et al., 1993).  It
is for this reason that a discussion of data requirements is presented in Section 
of this Chapter in  Book 1 of Australian Rainfall and Runoff.</para>
<para></para>
<para>In its most general form, the flood probability model can be described by its
probability density function (pdf) p(q | &#952;, x, M) where q is the flood peak.  The
pdf of q is determined by the vector of parameters &#952; belonging to the
probability distribution family M and by x defined as the vector of exogenous
or external variables which affect the values of &#952;.  The notation &#8220;|&#8221; refers to
conditioning: the variables to the left of &#8220;|&#8221; depend on the values taken by
variables to the right of &#8220;|&#8221;.</para>
<para></para>
<para>The distribution function of Q is defined as the non-exceedance probability
P(Q&#8804;q) and is related to the pdf by</para>
<para><anchor id="WPGeneratedID_Xref_pdfeqn_1"/></para>
<section role="legacy_equation" label="paragraph">
<para>FUNC { P  `( ` Q ` &lt;= ` q ` LINE ` theta ` , ` x ` , ` M ~ = INT FROM 0 TO q ~ p ` ( ` z ` LINE ` theta ` , ` x ` , ` M ` ) ` dz
} </para>
</section>
<para>Empirically the pdf of q is the limiting form of the histogram of q as the
number of samples approaches infinity.  Importantly, as shown in equation
1.1.<link>1</link>, the area under the pdf is interpreted as probability.</para>
<para></para>
<para>Homogeneous flood probability model</para>
<para></para>
<para>The simplest form of the flood probability model arises when the parameter
vector &#952; does not depend on an exogenous vector x.  In that case each flood
peak is considered to be a random realization from the same probability model
p(q | &#952;, M).  Under this assumption flood peaks form a homogeneous time
series.</para>
<para></para>
<para>Non-homogeneous flood probability model</para>
<para></para>
<para>A more complicated situation arises when flood peaks do not form a
homogeneous time series.  This may arise for a number of reasons including the
following:</para>
<para></para>
<itemizedlist mark="&#8226;">
<listitem>
<para>Rainfall and flood mechanisms may be changing over time.  For example,
long-term climate change due to global warming, land use change and river
regulation may render the flood record non-homogeneous; and</para>
</listitem>
</itemizedlist>
<para></para>
<itemizedlist mark="&#8226;">
<listitem>
<para>Climate may experience pseudo-periodic shifts that persist over periods
lasting from several years to several decades.  There is growing evidence
that parts of Australia are subject to such forcing and that this significantly
affects flood risk (see, for example, Warner and Erskine, 1988; Harvey et. al,
1991; Franks and Kuczera, 2002; Kiem <emphasis role="italic">et al</emphasis>., 2003; Micevski <emphasis role="italic">et al</emphasis>., 2003).</para>
</listitem>
</itemizedlist>
<para></para>
<para>Although this chapter in Book 1 of Australian Rainfall and Runoff will provide
some guidance on non-homogeneous flood probability models it needs to be
stressed that this is an area of continuing research and, therefore, users are
therefore advised to keep abreast of new developments.</para>
<para></para>
<para>Flood Risk Perspectives</para>
<para></para>
<para>General</para>
<para></para>
<para>Flood frequency analysis deals with the probability distribution of significant
flood peaks.  Throughout the year, there are typically many flood peaks
associated with individual storm events.  This is illustrated in Figure 1.1.<link>2</link>
where a time series plot of a streamflow discharge is presented.</para>
<para></para>
<para>There are two ways of describing the probability of exceeding a significant
flood magnitude:</para>
<para></para>
<orderedlist numeration="arabic" continuation="restarts">
<listitem>
<para>The probability distribution of the largest flood peak occurring over a
particular interval of time, which, in practice, is one year; and</para>
</listitem>
</orderedlist>
<para></para>
<orderedlist numeration="arabic" continuation="continues">
<listitem>
<para>The probability distribution of the time between consecutive flood peaks
that exceed a particular magnitude.</para>
</listitem>
</orderedlist>
<para>
<graphic fileref="CONCEPTUALFRAMEWORK/V5FIG4~1.jpg" width="4.723in" depth="2.994in" align="center" valign="top" format="JPG"/></para>
<para> - Peak-over-threshold series</para>
<para><anchor id="WPGeneratedID_Xref_potseriesfigure_1"/></para>
<para></para>
<para>These two perspectives are intimately connected as the following exposition
will show.  Central to this connection is the annual maximum series, obtained
by extracting the largest flood peak in every year of the record, and the peak-over-threshold (POT) series, obtained by extracting independent flood peaks
above some threshold discharge.</para>
<para></para>
<para>Referring to Figure 1.1.<link>2</link>, let the random variable q be a local peak discharge
defined as a discharge which has lower discharge on either side of the peak. 
This presents an immediate problem as any bump on the hydrograph would
produce a local peak.  To circumvent this problem we focus on peak flows
greater than some threshold discharge defined as q<subscript>o</subscript>.  The threshold is selected
so that the peaks above the threshold are sufficiently separated in time to be
statistically independent of each other. </para>
<para></para>
<para>Suppose over a time interval of length T there are n peaks over the threshold q<subscript>o</subscript>. 
This defines the POT time series of n independent realizations {q<subscript>1</subscript>,&#8230;,q<subscript>n</subscript>}.</para>
<para></para>
<para>Let w be the maximum value in the POT time series; that is,</para>
<para></para>
<section role="legacy_equation" label="paragraph">
<para>FUNC { w ~ = ~ max \{ ` q SUB ` ,  ` DOTSLOW ` , ` q SUB n  ` \} } </para>
</section>
<para>For w to be the maximum value each observed peak must be less than or equal
to w.  In probability theory, this condition is expressed by the joint event
consisting of the intersection of the following n events, ie
</para>
<section role="textbox" label="inline">
<para>FUNC { \{ ` ( ` q SUB 1 ~ &lt;= ~ w ` ) ~ CAP ~ ( ` q SUB 2 ~ &lt;= ~ w ` ) ~ CAP ~ DOTSLOW ~ CAP ~ ( ` q SUB n ~ &lt;= ~
w ` ) ` \} } </para>
</section>
<para>.</para>
<para></para>
<para>Because the peaks are assumed to be statistically independent the probability of
the joint event is the product of the probabilities of the individual events. 
Therefore the probability that the random variable W &#8804; w in a POT series with
n events occurring over the interval T simplifies to</para>
<para><anchor id="WPGeneratedID_Xref_GKequation3_1"/></para>
<section role="legacy_equation" label="paragraph">
<para>FUNC { MATRIX { P ` ( ` W ~ &lt;= ~ w ` LINE ` n ` , ` T ` ) &amp; ALIGNL = ~ P ` [ ` ( ` q SUB 1 ~ &lt;= ~ w ` ) ~ CAP ~ ( ` q
SUB 2 ~ &lt;= ~ w ` ) ~ CAP ~ DOTSLOW ~ CAP ~ ( ` q SUB n ~ &lt;= ~ w ` ) ` ] # ~ &amp;  ALIGNL = ~ P  `( ` q SUB 1 ~ &lt;= ~
w ` ) ` P ` ( ` q SUB 2 ~ &lt;= ~ w ` ) ~ DOTSLOW ~ P  `( ` q SUB n ~ &lt;= ~ w ` ) #~ &amp; ALIGNL = ~ P ` ( ` q ~ &lt;= ~ w ` )
SUP n } } </para>
</section>
<para>The last term in equation 1.1.<link>3</link> comes from the assumption that all the peaks
above the threshold q<subscript>o</subscript> are sampled from the same distribution with the pdf p(q |
q &gt; q<subscript>o</subscript>).</para>
<para></para>
<para>The number of POT events n occurring over an interval T is random.  Suppose
that the random variable n follows a Poisson distribution with &#957; being the
average number of POT events per unit time; that is,</para>
<para><anchor id="WPGeneratedID_Xref_POToccurrenceeqn_1"/></para>
<section role="legacy_equation" label="paragraph">
<para>FUNC { P ` ( ` n ` LINE ` nu ` ) ~ = ~ { ( ` nu ` T ` ) SUP n ~ exp ` ( ` - ` nu ` T ` ) } OVER { n ` ! } ~ , ~ n ~ =  ~ 0 ` , ` 1 `
, ` 2 ` , ` DOTSLOW ~ } </para>
</section>
<para>Equation 1.1.<link>4</link> can be applied to cases where the distribution of POT
occurrences varies according to the seasons encountered within time interval T. 
Provided the distribution of POT occurrences in each season is Poisson, the
distribution of POT occurrences over interval T is Poisson with the parameter
&#957;T equal to the sum of the average number of occurrences in each season.  This
result is a consequence of the fact that the sum of Poisson random variables is
Poisson distributed.</para>
<para></para>
<para>After some algebra, application of the total probability theorem yields the
distribution of the largest flood peak magnitude over the interval with duration
T</para>
<para><anchor id="WPGeneratedID_Xref_excprobeqn5_1"/></para>
<section role="legacy_equation" label="paragraph">
<para>FUNC { MATRIX { P ` ( ` W ~ &lt;= ~ w ` LINE ` T ` ) ~  &amp; ALIGNL = ~ SUM FROM { n ` = ` 0 } TO INF ` P ` ( ` W ~
&lt;= ~ w  ` LINE ` n ` , ` T ` ) ` P ` ( ` n ` LINE ` nu ` ) # ~ &amp; ALIGNL = ~ exp ` [ ` - ` ( ` nu ` T ` ) ` P ` ( ` Q ~ &gt; ~ w ` ) ` ]
} } </para>
</section>
<para>where P(W &#8804; w | T) is the probability that the largest flood peak over time
interval T is less than or equal to w.  This result hinges on the assumption that
all the peaks above the threshold q<subscript>o</subscript> are sampled from the same distribution.  If
the pdf p(q | q &gt; q<subscript>o</subscript>) exhibits significant seasonal differences equation 1.1.<link>3</link>
cannot be simplified necessitating a more involved analysis.</para>
<para></para>
<para>Distribution of Time Between Floods</para>
<para></para>
<para>The objective is to derive the probability distribution of the time between
consecutive flood peaks with magnitude in excess of w.  With regard to
equation 1.1.<link>5</link>, if the largest flood peak during time T is less than or equal to w,
then the time to the next peak with magnitude in excess of w must be greater
than T.  It therefore follows from equation 1.1.<link>5</link> that the distribution of time
between flood peaks with magnitude exceeding w is</para>
<para></para>
<section role="legacy_equation" label="paragraph">
<para>FUNC { P ` ( ` Time  ~ \to ~ next ~ peak ~ exceeding ~ w ~ &lt;= ~ T ` ) ~ =  } # ~ # FUNC { ~ 1 ~ - ~ exp ` [ ` - ` nu ` P ` ( `
Q ~ &gt; ~ w ` ) ` T  ` ] } </para>
</section>
<para>This is recognized as an exponential distribution with parameter &#957;P(Q&gt;w)
which is interpreted as the expected number of peaks exceeding w per unit
time. An important property of the exponential distribution is that its expected
value is equal to the inverse of its parameter. It therefore follows that the
expected time interval between peaks that exceed w is</para>
<para><anchor id="WPGeneratedID_Xref_excprobeqn7_1"/></para>
<section role="legacy_equation" label="paragraph">
<para>FUNC { STACKALIGN { T SUB P ` ( ` w ` ) &amp; = ~ 1 OVER { Expected ~ number ~ of ~ peaks ~ &gt; ~ w ~ per ~ unit ~
time } # ~ &amp; = ~ 1 OVER { nu ` P ` ( ` Q ~ &gt; ~ w ` ) }  } } </para>
</section>
<para>T<subscript>P</subscript>(w) is termed the average recurrence interval (ARI) for magnitude w and
provides a convenient probability measure for POT series.</para>
<para></para>
<para>Annual Maximum Flood Risk</para>
<para></para>
<para>With regard to equation 1.1.<link>5</link>, P (W &#8804; w | T = 1) represents the probability that
the largest flood peak during the year is less than or equal to w. The annual
exceedance probability AEP(w) is given by 1 &#45; P (W &#8804; w | T = 1) and provides
a convenient probability measure for the annual maximum series.  It is
understood that the 1 in Y AEP flood has a probability of 1/Y of being equalled
or exceeded in any one year.</para>
<para></para>
<para>An alternative measure is based on the average recurrence interval of annual
maximum flood peaks exceeding magnitude w.  The probability of waiting n
years for the next annual maximum flood to exceed w can be shown to be</para>
<para></para>
<section role="legacy_equation" label="paragraph">
<para>FUNC { P `( ` Annual ~ maximum ~ peak ~ exceeds ~ w ~ \in ~ n SUP { th } ~ year ` ) ~ =  } # </para>
<para>~ # </para>
<para>FUNC { P ` ( ` W ~ &lt;= ~ w ` | ` T ~ = ~ 1 ` ) SUP  { n ` - ` 1 } ~ P ` ( ` W ~ &gt; ~ w ` | ` T ~ = ~ 1 ` ) } </para>
</section>
<para>This is known as the geometric distribution.  The expected number of years
between annual maximum flood peaks with magnitude in excess of w can be
shown to be</para>
<para><anchor id="WPGeneratedID_Xref_excprobeqn9_1"/></para>
<section role="legacy_equation" label="paragraph">
<para>FUNC { T SUB A ` ( ` w ` ) ~ = ~ 1 OVER { 1 ~ - ~ P ` ( ` W ~ &lt;= ~ w ` LINE ` T ~ = ~ 1 ` ) } ~ = ~ 1 OVER { AEP ` ( `
w ` ) } } </para>
</section>
<para></para>
<para>Choice of Series</para>
<para></para>
<para>It is important to distinguish between T<subscript>P</subscript> and T<subscript>A</subscript> as they have different
meanings even though they are referred to as Average Recurrence Intervals. 
From equations 1.1.<link>5</link>, 1.1.<link>7</link>,and 1.1.<link>9</link>, it follows that the relationship between
T<subscript>P</subscript> (w) and T<subscript>A</subscript> (w) is</para>
<para></para>
<section role="legacy_equation" label="paragraph">
<para>FUNC { T SUB A ` ( ` w ` ) ~ = ~ 1 OVER { 1 ~ - ~ exp ` LEFT ( ` - ` 1 OVER { T SUB P ` ( ` w ` ) } ` RIGHT ) } } </para>
</section>
<para><anchor id="WPGeneratedID_Xref_TATPRelationship_1"/>
<graphic fileref="CONCEPTUALFRAMEWORK/V5FIG4~2.jpg" width="4.723in" depth="4.698in" align="center" valign="top" format="JPG"/></para>
<para> - Relationship between POT and Annual Maximum Average
Recurrence Intervals</para>
<para>This relationship is in Figure 1.1.<link>2</link>.  For an ARI of 10 or more years the
difference between T<subscript>A</subscript> and T<subscript>P</subscript> is minimal and POT and annual maximum
analyses should yield similar results.  For ARIs less than 10 years, however, the
ARI for annual maximum series will exceed the ARI for the POT series for the
same discharge.  This conclusion arises from the smaller floods during years
with large annual maximum floods may exceed the annual maximum flood in
other years.</para>
<para></para>
<para>These considerations make it essential when quoting ARIs to make clear
whether they refer to annual maximum or POT series.  The annual maximum
and POT ARIs refer to different properties of the flood time series.  This
motivates the convention used in Australian Rainfall and Runoff, namely AEPs
are used when referring to annual maximum series, while ARIs are used when
referring to POT series.</para>
<para></para>
<para>Consideration of Figure 1.1.<link>2</link> leads to the following guidelines:</para>
<para></para>
<orderedlist numeration="arabic" continuation="restarts">
<listitem>
<para>T<subscript>A</subscript> &gt; 10 yearsUse of annual maximum series is generally preferred because it
is straightforward to ensure statistical independence between
annual maxima and allows the analysis to better focus on low
AEP events.  This series is generally used in design, as low
AEPs in this range are generally required for estimation of a
design flood for a structure or works at a particular site.</para>
</listitem>
</orderedlist>
<para></para>
<orderedlist numeration="arabic" continuation="continues">
<listitem>
<para>T<subscript>A</subscript> &lt; 10 yearsUse of POT series is generally preferred because all floods are
of interest in this range, whether they are the highest in the
particular year of record or not.  The annual maximum series
may omit many floods of interest.  The POT series is
appropriate for estimating design flows of low ARI in urban
stormwater contexts including water quality treatment devices
and measures and for diversion works, coffer dams and other
temporary structures.  However, it is infrequently used because
flow records are not often available at sites where minor works
with a design ARI of less than 10 years are required.  A
significant application is in the development of regional flood
estimation methods for small to medium sized catchments (e.g.
Pilgrim and McDermott, 1982; Flavell, 1983; Adams and
McMahon, 1985; and Adams, 1987).  It should also be noted
that the design rainfall data in Book II effectively represent the
results of frequency analysis of POT series rainfall data.</para>
</listitem>
</orderedlist>
<para></para>
<para>Advantages and Disadvantages of Flood Frequency Analysis</para>
<para></para>
<para>Analysts need to be aware of the advantages and disadvantages of flood frequency
analysis.</para>
<para></para>
<para>Flood peaks are the product of a complex joint probability process involving the
interaction of many random variables associated with the rainfall event, antecedent
conditions and rainfall-runoff transformation.  Peak flood records represent the
integrated response of the storm event with the catchment.  They provide a direct
measure of flood exceedance probabilities.  As a result flood frequency analysis
is less susceptible to bias, possibly large, that can affect alternative methods based
on design rainfall (Kuczera <emphasis role="italic">et al</emphasis>., 2003).</para>
<para></para>
<para>Other advantages of flood frequency analysis include its comparative simplicity
and capacity to quantify uncertainty arising from limited information.  It remains
a moot point whether flood frequency methods are less accurate than rainfall-based
methods for which rigorous uncertainty analysis is yet to be developed.</para>
<para></para>
<para>Offsetting these significant advantages are several disadvantages:</para>
<para></para>
<itemizedlist mark="&#8226;">
<listitem>
<para>The true probability distribution family M is unknown.  Unfortunately,
different models can fit the bulk of the flood data with similar capability, yet
can diverge in the right hand tail when extrapolated beyond the data and have
difficulty dealing with the left hand tail.</para>
</listitem>
</itemizedlist>
<para></para>
<itemizedlist mark="&#8226;">
<listitem>
<para>Short records may produce flood estimates with considerable uncertainty.
However, the ready ability to compute confidence limits directly informs the
user about the credibility of the estimate.</para>
</listitem>
</itemizedlist>
<para></para>
<itemizedlist mark="&#8226;">
<listitem>
<para>It may be difficult or impossible to adjust the data if the catchment conditions
under which the flood data were obtained have changed during the period of
record, or are different to those applying to the future design life of a structure
or works being designed.</para>
</listitem>
</itemizedlist>
<para></para>
<itemizedlist mark="&#8226;">
<listitem>
<para>Considerable extrapolation of rating curves is necessary to convert recorded
stage to discharge for the largest flood peaks at most Australian gauging
stations. Also the probability of malfunction of recording instruments is
increased during major floods. Suspect floods and the years in which they
occurred may be omitted in analysis of annual maximum series, but this reduces
the sample size and may introduce bias if the suspect floods are all major
events. Though these problems are inherent to the calibration of all methods
employing major flood peaks, flood frequency analysis is more sensitive
because of its need to use major flood peaks.</para>
</listitem>
</itemizedlist>
<para></para>
<para>Range of Application</para>
<para></para>
<para>As noted, the true flood probability family is unknown.  In practice the choice of
model is guided by goodness of fit to data, understanding of the hydrologic
characteristics of the region, and regional hydrologic experience.  Therefore, use
of  the fitted frequency curve for ARIs up to that of the data is regarded as an
interpolation exercise deemed to be reliable in the sense that confidence limits
capture the uncertainty.  However, when the frequency curve is extrapolated well
beyond the observed data, confidence limits which quantify the effect of sampling
variability on parameter uncertainty may underestimate the true uncertainty.  In
these circumstances, model bias may be significant and even dominant. 
Demonstrated in Example ? is the need to understand the processes affecting flood
peaks beyond the observed record and illustrates the pitfall of blind extrapolation.</para>
<para></para>
<para>Large extrapolations of flood frequency analyses are not recommended.  It is
acknowledged that prescribing strict limits on maximum ARIs or minimum AEPs
does not have a strong conceptual foundation.  The limits to extrapolation should
be guided by consideration of confidence limits, which are affected by the
information content of the data and choice of flood model, and by judgments about
model bias which cannot be quantified.  In situations where the analyst is prepared
to make the judgment that the processes operating in the range of the observed
record continue to dominate for larger floods, model bias may be deemed to be
manageable - of course the effects of sampling uncertainty may be so amplified for
significant extrapolation to render the frequency estimate of little value.</para>
<para></para>
<para>In the absence of user analysis about the degree of model bias when extrapolating,
the following guidelines are offered to promote consistency with previous
practice:  As discussed further in Book VI, the 1 in 100 AEP flood is the largest
event that should be estimated by direct frequency analysis for important work. 
The maximum flood that should be estimated by this means under any
circumstances is the 1 in 500 AEP event.   Where a regional flood frequency
method transfer of data from an adjacent catchment is used, the limiting AEP
should be 1 in 100.  Described in Book VI are procedures for estimating floods
beyond the probabilities noted above.  These procedures interpolate flood
magnitudes between the 1 in 100 AEP event and the probable maximum flood. 
While these procedures involve some arbitrary assumptions, they provide a
consistent approach and overcome many of the problems involved in extrapolation
of flood frequency analysis resulting from choice of the appropriate probability
distribution.</para>
</chapter>
</book>
