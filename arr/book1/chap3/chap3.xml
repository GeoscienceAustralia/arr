<?xml version="1.0" encoding="UTF-8"?>
<chapter status="In Preparation" xml:id="b1_ch3"
         xmlns="http://docbook.org/ns/docbook"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:svg="http://www.w3.org/2000/svg"
         xmlns:m="http://www.w3.org/1998/Math/MathML"
         xmlns:html="http://www.w3.org/1999/xhtml"
         xmlns:db="http://docbook.org/ns/docbook">
  <info>
    <title>Approaches to Flood Estimation</title>

    <xi:include href="../../common/authors/nathan_rory.xml"/>

    <xi:include href="../../common/authors/ball_james.xml"/>
  </info>

  <informaltable border="1">
    <tr>
      <td colspan="2">Chapter Status</td>
    </tr>

    <tr>
      <td>Book</td>

      <td>1</td>
    </tr>

    <tr>
      <td>Chapter</td>

      <td>3</td>
    </tr>

    <tr>
      <td>Date</td>

      <td>27/11/2015</td>
    </tr>

    <tr>
      <td>Content</td>

      <td>Draft for industry comment</td>
    </tr>

    <tr>
      <td>Graphs and Figures</td>

      <td>Advanced draft</td>
    </tr>

    <tr>
      <td>Examples</td>

      <td>N/A</td>
    </tr>

    <tr>
      <td>General</td>

      <td>Subject to final review and consistency check</td>
    </tr>
  </informaltable>

  <section xml:id="b1_ch3_s_n1dn4">
    <title>Introduction</title>

    <para>Design flood estimation is a focus for many engineering
    hydrologists. In many situations, advice is required on flood magnitudes
    for the design of culverts and bridges for roads and railways, the design
    of urban drainage systems, the design of flood mitigation levees and other
    flood mitigation structures, design of dam spillways, and many other
    situations. The flood characteristic of most importance depends on the
    nature of the problem under consideration, but it is often necessary to
    estimate peak flow, peak level, flood volume, and flood rise. The analysis
    might be focused on a single location – such as a bridge waterway or levee
    protecting a township– or it may be necessary to consider the performance
    of the whole catchment as a system, as required in urban drainage
    design.</para>

    <para>Design objectives are most commonly specified using risk-based
    criteria, and thus the focus of this guidance is on the use of methods
    that provide estimates of flood characteristics for a specified
    probability of exceedance (referred to as flood quantiles, see <xref
    linkend="b1_ch2_s_n6pll"/>).</para>

    <para>The general nature of the estimation problem is illustrated in <xref
    linkend="b1_ch3_f_ndayd"/>. This figure shows the annual maxima floods
    (blue circular symbols) from 75 years of available gauged records. These
    flood maxima have been ranked from largest to smallest and are plotted
    against an estimate of their sample exceedance probability (as described
    in <xref linkend="book3"/>). Such information can be used directly to
    identify the underlying probability model of flood behaviour at the site
    at which the data was collected. The flood peaks are usually considered to
    be independent random variables, and it is often assumed that each flood
    is a random realisation of a single probability model. The gauged flood
    peaks shown in <xref linkend="b1_ch3_f_ndayd"/> do appear to be from a
    homogeneous sample (ie. a single probability model), but in many practical
    problems the relationship between rainfall and flood may change over time,
    and it may be necessary to either censor the data or identify appropriate
    exogenous factors to condition the fit of the adopted probability
    model.</para>

    <para>The best estimate of the relationship between flood magnitude and
    Annual Exceedance Probability (AEP) (<xref linkend="b1_ch2_s_n6pll"/>)
    obtained by fitting a probability model is shown by the solid red curve in
    <xref linkend="b1_ch3_f_ndayd"/>. The gauged data represent a finite
    sample of a given size, and thus any estimate of flood risk using a fitted
    probability model is subject to uncertainty, as illustrated by the
    increasingly divergent dashed red curves in <xref
    linkend="b1_ch3_f_ndayd"/> (referred to as confidence limits). The
    computation of such confidence limits usually only reflects the limits of
    the available sample, or perhaps the increasing uncertainty involved in
    the extrapolation of the relationship between recorded stage and estimated
    flood peak. The computed confidence limits are also conditioned on the
    assumed underlying probability model. However, it needs to be recognised
    that these factors only represent the uncertainties most easily
    characterised; other factors, such as the influence of a non-stationary
    climate, changing land-use during the period of record, and the changing
    nature of flood response with event magnitude, confound attempts to
    identify the most appropriate probability model. Accordingly, the true
    uncertainty around such estimates will be larger than that based solely on
    consideration of the size of the available sample. Of course, data are
    rarely available at the location of design interest, and additional
    uncertainty is involved in the scaling and/or transposition of flood risk
    estimates to the required site.</para>

    <figure label="1031" xml:id="b1_ch3_f_ndayd">
      <title>Illustration of Stochastic Influence of Hydrologic Factors on
      Flood Peaks and the Uncertainty in Flood Risk Estimates Associated with
      Observed Flood Data</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="../../figures/1031.png"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>One of the great advantages of fitting a probability flood model to
    observed data is that the approach avoids the problem of considering the
    complex joint probabilities involved in flood generation processes. Floods
    are the result of the interaction between many random variables associated
    with natural and anthropogenic factors; natural factors include
    interactions between the characteristics of the rainfall event, antecedent
    conditions, and other stochastic factors such as tide levels and debris
    flows; anthropogenic factors might include the influence of dam and weir
    operations, urbanisation, retarding basins, flood mitigation works, and
    land-management practices.</para>

    <para><xref linkend="b1_ch3_f_ndayd"/> also illustrates the influence of
    natural variability on flood generation processes, and is based on the
    stochastic simulation of flood processes using 10,000 years of rainfall
    data under the assumption of a stationary climate. The stochastic flood
    maxima were obtained by varying key factors that influence the production
    of flood runoff, namely rainfall depth, initial and continuing losses, and
    the spatial and temporal patterns of catchment rainfalls. The flood peaks
    in <xref linkend="b1_ch3_f_ndayd"/>are plotted against the AEP of the
    causative rainfall, and the scatter of the stochastic maxima illustrates
    the natural variability inherent in the production of flood runoff. While
    these maxima have been derived from mathematical modelling of event
    rainfall bursts, an indication of this variability can be seen in the
    relationship between observed rainfalls and runoff in gauged catchments
    (though of course with real-world data we do not have 10,000 years of
    observations).</para>

    <para>The scatter of stochastic flood maxima resulting from different
    combination of flood producing factors illustrates the inherent difficulty
    in removing bias from “simple design event” methods. Such methods use a
    flood model to transform probabilistic bursts of rainfall (the design
    rainfalls as presented in <xref linkend="book2"/>) to corresponding
    estimates of floods. For example it is seen from <xref
    linkend="b1_ch3_f_ndayd"/> that the flood peaks resulting from 1% AEP
    rainfalls range in magnitude between around 500
    m<superscript>3</superscript>/s and 2000 m<superscript>3</superscript>/s;
    it is also seen that the rainfall that might generate a flood with a 1,000
    m<superscript>3</superscript>/s peak might vary between a 20% and 0.1%
    AEP. Traditional practice has been to adopt fixed values of losses and
    rainfall patterns for use with design rainfalls to derive a single flood
    that is assumed to have the same AEP as its causative rainfall
    (probability neutrality). If chosen carefully it is possible to select a
    set of values that yields an unbiased estimate of the design flood for a
    particular catchment, but without taking steps to explicitly cater for the
    joint probabilities involved, there is a considerable margin for error
    (Weinmann et al, 2002; Kuczera et al., 2006).</para>

    <para>Accordingly, a key difference between this and earlier versions of
    ARR is the focus on how best to achieve “probability neutrality” between
    rainfall inputs and flood outputs when using rainfall-based techniques. A
    number of more computationally intensive procedures are introduced (such
    as ensemble event, Monte Carlo event, and continuous simulation
    approaches) to help ensure that the method used to transform rainfalls
    into design floods is undertaken in a fashion that minimises bias in the
    resulting exceedance probabilities. An overview of these concepts is
    provided in <xref linkend="b1_ch3_s_ccenm"/>, and more detailed
    description of the procedures is provided in <xref
    linkend="book4"/>.</para>

    <para>The methods discussed here are divided into two broad classes of
    procedures based on: <orderedlist numeration="lowerroman">
        <listitem>
          <para>the direct analysis of observed flood and related data (<xref
          linkend="b1_ch3_s_o4nkk"/>) and</para>
        </listitem>

        <listitem>
          <para>the use of simulation models to transform rainfall into flood
          maxima (<xref linkend="b1_ch3_s_ccenm"/>).</para>
        </listitem>
      </orderedlist></para>

    <para>All methods involve the use of some kind of statistical model (or
    transfer function) to extrapolate information in space or time. Each
    method also has its strengths and limitations and they vary in their
    suitability to different types of data and design contexts, and this is
    discussed in <xref linkend="b1_ch3-1e"/>.</para>
  </section>

  <section xml:id="b1_ch3_s_o4nkk">
    <title>Flood data based procedures</title>

    <section xml:id="b1_ch3_s_sgzmf">
      <title>Overview</title>

      <para>An overview of the procedures commonly used to analyse flood data
      directly is provided in <xref linkend="b1_ch3_t_rotgx"/>. Flood
      frequency techniques (<xref linkend="b1_ch3_s_1wjii"/>) are used to
      estimate the probability of flood exceedances directly from observed
      flood maxima, and are often used to extrapolate to probabilities beyond
      that inferred by the length of available record. Flood Frequency
      Analyses are most commonly applied using only the data at the site of
      interest using Peaks-over-Threshold and Annual Maxima Series (“at-site
      analyses”), but the resulting estimates of flood risk can be
      significantly improved by the consideration of flood behaviour at
      multiple sites that are judged to have similar flood frequency
      distributions (“at-site/regional analyses”). This concept of pooling
      information from multiple sites is often referred to as “trading space
      for time” <?oxy_comment_start author="retallick" timestamp="20151128T134254+1100" comment="is the for needed?"?>for<?oxy_comment_end ?>,
      with appropriate care, the information on flood exceedances across a
      region can improve the fit of the probability model at a single site
      with a short period of record.</para>

      <para>One drawback of frequency analyses is that it can only provide
      quantile estimates at sites where data is available. Accordingly, a
      range of procedures have been developed to estimate flood risk at sites
      with little or no data (<xref
      linkend="b1_ch3_s_1wjii"/><?oxy_comment_start author="retallick" timestamp="20151128T134349+1100" comment="is this the right reference?? should it be the RFFE chap, the FFA chap or all of book 3"?>)<?oxy_comment_end ?>.
      These procedures generally involve the use of regression models to
      estimate the parameters of probability models (or the flood quantiles)
      using physical and meteorological characteristics, although simpler
      scaling functions can sometimes be used for local analyses.</para>

      <table xml:id="b1_ch3_t_rotgx">
        <caption>Summary of Common Procedures used to Directly Analyse Flood
        Data</caption>

        <thead>
          <tr>
            <th/>

            <th>Frequency analysis of frequent floods</th>

            <th>Frequency analysis of rare floods</th>

            <th>At-site/regional flood frequency analysis</th>

            <th>Regional Flood Frequency Estimation</th>
          </tr>
        </thead>

        <tbody>
          <tr>
            <td>Inputs</td>

            <td>Peak-over-Threshold series</td>

            <td>Annual Maxima Series at single site of interest</td>

            <td>Gauged flood maxima at multiple sites with similar flood
            behaviour</td>

            <td>Catchment characteristics and flood quantiles (or parameters)
            derived from frequency analyses</td>
          </tr>

          <tr>
            <td>Analysis</td>

            <td>Selected probability model is fitted to flood maxima (eg
            exponential distribution fitted by L-Moments)</td>

            <td>Selected probability model is fitted to flood maxima (eg LP
            III/GEV distributions fitted by L-Moments)</td>

            <td>Information from multiple catchments is used to improve fit of
            probability model (eg regional L-Moments or Bayesian
            inference)</td>

            <td>Regression on model parameters or flood quantiles (eg RFFE
            method), or local scaling functions based on catchment
            characteristics</td>
          </tr>

          <tr>
            <td>Outputs</td>

            <td><para>Flood quantiles for AEPs &gt; 10% at a gauged
            site</para></td>

            <td><para>Flood quantiles for AEPs &lt; 10% at a gauged
            site</para></td>

            <td>Improved flood quantiles at multiple sites of interest</td>

            <td>Flood quantiles at ungauged sites</td>
          </tr>

          <tr>
            <td>ARR Guidance</td>

            <td><xref linkend="b3_ch2_s_r1114"/> and <xref
            linkend="b3_ch2_s7"/></td>

            <td><xref linkend="b3_ch2_s_nhxbm"/> and <xref
            linkend="b3_ch2_s6"/></td>

            <td><xref linkend="b3_ch2_s_mkmnz"/> (Bayesian Calibration)</td>

            <td><xref linkend="b3_ch3"/></td>
          </tr>
        </tbody>
      </table>
    </section>

    <section xml:id="b1_ch3_s_1wjii">
      <title>Flood Frequency Techniques</title>

      <para>Flood Frequency Analysis involves the fitting of a probability
      model to recorded maxima to relate the magnitude of extreme events to
      their frequency of occurrence. The method can be applied directly to
      flood peaks (as described in <xref linkend="book3"/>) or rainfall (as
      used in <xref linkend="book2"/>), or indeed to any set of flood
      characteristics for which it is desired to determine the relationship
      between event magnitude and exceedance probability. The technique is
      generally not applicable to flood level maxima as the manner in which
      flood levels increase with flood magnitude is heavily dependent on
      channel geometry and thus is not suited to statistical
      extrapolation.</para>

      <para>Flood Frequency Analyses can be broadly divided into three types
      of applications (<xref linkend="b1_ch3_t_rotgx"/>), namely:<itemizedlist>
          <listitem>
            <para>At-site - the parameters of the probability distributions
            are fitted to annual maxima series to derive estimates of flood
            risk rarer than 10% AEP (or to peaks above a given threshold for
            more common floods) solely using information at the site of
            interest</para>
          </listitem>

          <listitem>
            <para>At-site/regional - the information used to fit the model
            parameters is obtained from the site of interest as well as from
            other sites considered to exhibit similar flood behaviour.</para>
          </listitem>

          <listitem>
            <para>Regional - the information used to fit the model parameters
            is obtained from a group of sites considered to exhibit similar
            flood behaviour, where, as described in the following section,
            regression-based procedures may be used to estimate the model
            parameters (or probability quantiles) at the ungauged sites of
            interest</para>
          </listitem>
        </itemizedlist></para>

      <para>Flood frequency methods are particularly attractive as they avoid
      the need to consider the complex processes and joint probabilities
      involved in the transformation of rainfall into flood. However, the
      utility of these methods is heavily dependent on both the length of
      available record and its representativeness to the catchment and
      climatic conditions of interest, as they are based on the assumption of
      stationary data series. Details on what distributions should be used,
      and how to select the sample of maxima and fit the distribution, are
      provided in <xref linkend="book3"/>.</para>

      <para>There is advantage in undertaking frequency analyses at multiple
      sites in a local region of interest as this provides information on how
      local flood behaviour changes with catchment area, and other factors
      such as rainfall intensity can also be considered for more detailed
      analyses. Simple quantile regression models (ie. the development of a
      regression relationship between, say, catchment area and 10% AEP flood
      peak) are readily derived and are well suited to transposing flood risk
      estimates to locations upstream or downstream of a gauging site. Such
      simple scaling functions can also be applied to estimates derived using
      rainfall-based procedures.</para>
    </section>

    <section xml:id="b1_ch3_s_6j26d">
      <title>Regional Flood Methods</title>

      <para>Regional flood methods generally involve the application of a
      regression technique in which flood characteristics are related to
      catchment and relevant meteorological characteristics; the regression
      equation can be fitted to the flood quantiles directly (“quantile
      regression technique”), or else they can be fitted to the parameters of
      a probability model (“parameter regression technique”).</para>

      <para><xref linkend="book3"/> provides details of the application of the
      latter approach to data sets for different Australian regions in which
      the three parameters of the probability model are estimated from
      catchment characteristics using a Bayesian regression approach (Rahman
      et al, 2014). The developed procedure provides a quick means to estimate
      the magnitude of peak flows between the 50% to 1% AEPs, with the
      additional attraction that uncertainty bounds are provided. The
      regression equations presented in <xref linkend="book3"/> were developed
      using parameters obtained from at-site/regional flood frequency
      analyses, and thus represent a rigorous example of Regional Flood
      Frequency Estimation based on parameter regression.</para>

      <para>In some situations it might be useful to obtain an additional
      independent estimate based on local data, and if so then prediction
      equations can be developed by regressing catchment characteristics
      against flood quantiles obtained from at-site(/regional) flood frequency
      analyses. The most common example of this is to develop a relationship
      between flood quantiles and catchment area for nested sites located in
      the same catchment (typically this is undertaken using log-transformed
      data). The utility of such an approach when compared to the procedure
      presented in <xref linkend="book3"/> depends on the relevance of the
      data to the problem at hand, and on the extent to which the assumptions
      of the fitted model have been satisfied.</para>
    </section>
  </section>

  <section xml:id="b1_ch3_s_ccenm">
    <title>Rainfall based procedures</title>

    <section xml:id="b1_ch3_s_qhrcw">
      <title>General</title>

      <para>Rainfall-based models are commonly used to extrapolate flood
      behaviour at a particular location using information from a short period
      of observed data; this can be done using either event-based or
      continuous simulation approaches, as described in <xref
      linkend="b1_ch3_s_8739o"/> and <xref linkend="b1_ch3_s_4h1lr"/> below.
      The parameters of such models can also be transposed to a different
      location (or modified to represent different catchment conditions) and
      used to estimate flood characteristics for which no gauging information
      is available.</para>

      <para><xref linkend="b1_ch3_t_97p0i"/> summarises the different
      characteristics of the event-based and continuous simulation approaches.
      The three broad approaches to event-based simulation all use the same
      hydrologic model to convert design rainfall inputs into hydrograph
      outputs, the main difference is in the level of sophistication used to
      minimise bias in the probability neutrality of the transformation.
      Continuous simulation approaches utilise model structures which
      generally differ markedly from those used in event-based models.</para>

      <para>Event-based approaches are based on the transformation of rainfall
      depths of given duration and AEP (“design rainfalls”) into flood
      hydrographs by routing rainfall excess (obtained by applying a loss
      model to rainfall depths) through the catchment storage. Such models can
      include the allowance of additional pre- and post-burst rainfalls to
      represent complete storm events, and can separately consider baseflow
      contribution from prior rainfall events to represent total hydrographs.
      The defining feature of such models is that they are focused on the
      simulation of an individual flood event and that antecedent conditions
      need to be specified in some explicit fashion. Simple Design Event
      methods are applied in a deterministic fashion, where key inputs are
      fixed at values that minimise the bias in the transformation of rainfall
      into runoff. Alternatively, stochastic techniques can be used to
      explicitly resolve the joint probabilities of key hydrologic
      interactions; ensemble techniques provide simple (and approximate) means
      of minimising the bias associated with a single hydrologic variable,
      whereas Monte Carlo techniques represent a more rigorous solution that
      can be expanded to consider interactions from a range of natural and
      anthropogenic factors. It should be noted that the guidance provided in
      ARR only focuses on the use of stochastic techniques to cater for
      (random) variability of key inputs, and its use to characterise
      epistemic uncertainty is assumed to be the domain of specialist
      statistical hydrologists.</para>

      <para>Continuous simulation approaches remove the need to specify
      antecedent conditions as these are implicitly considered in the
      successive updating of state variables via the simulation of continuous
      rainfall (and other) input time series. The continuous simulation of key
      state variables also has the potential to simplify the consideration of
      the complex joint probabilities involved in flood generation processes.
      The conceptual basis of continuous simulation is the simulation of data
      that would have been recorded at a location if a gauge were present at
      that location. Hence estimation of design flood characteristics from
      data generated through application of a continuous simulation modelling
      system requires the undertaking of subsequent statistical analysis, as
      outlined in <xref linkend="b1_ch3_s_1wjii"/>. The advantages of
      continuous simulation may be offset by the need to consider additional
      complexity which are avoided by event-based approaches, though the
      relative merits of each approach is dependent upon the available data
      and the nature of the design problem being considered.</para>

      <para><table xml:id="b1_ch3_t_97p0i">
          <caption>Summary of Recommended Rainfall-Based Procedures</caption>

          <thead>
            <tr>
              <th/>

              <th>Simple Design Event</th>

              <th>Ensemble Event</th>

              <th>Monte Carlo Event</th>

              <th>Continuous Simulation</th>
            </tr>
          </thead>

          <tbody>
            <tr>
              <td>Hydrologic Inputs</td>

              <td colspan="3">Design rainfalls (ie rainfall depth for given
              burst duration and Annual Exceedance Probability)</td>

              <td>Observed (or synthetic) time series of rainfall and
              evaporation.</td>
            </tr>

            <tr>
              <td>Hydrologic variability</td>

              <td>Fixed patterns of rainfall and other inputs</td>

              <td>Ensemble of <emphasis role="italic">N</emphasis> temporal
              patterns</td>

              <td>Ensemble (or distribution) of temporal patterns, losses, and
              other factors.</td>

              <td>As represented in the time series of inputs – if not in time
              series then not represented</td>
            </tr>

            <tr>
              <td>Model</td>

              <td colspan="3">Event-based model based on routing rainfall
              excess through catchment storage (see <xref linkend="book5"/>
              for details of technique)</td>

              <td>Model of catchment processes influencing runoff
              generation</td>
            </tr>

            <tr>
              <td>Framework</td>

              <td>Single simulation for each combination of rainfall depth and
              AEP</td>

              <td><emphasis role="italic">N</emphasis> simulations for each
              combination of rainfall depth and AEP (N &gt;10)</td>

              <td>Stochastic sampling of input distributions using continuous
              or stratified domain (potentially thousands of simulations)</td>

              <td>Continuous simulation at time step for <emphasis
              role="italic">N</emphasis> years</td>
            </tr>

            <tr>
              <td>Flood AEP</td>

              <td colspan="2">Assumed same as input rainfall</td>

              <td rowspan="2">Statistical analysis of joint probabilities (eg
              frequency analysis of maxima or Total Probability Theorem)</td>

              <td rowspan="2">Computed from frequency analysis of <emphasis
              role="italic">N</emphasis> annual maxima</td>
            </tr>

            <tr>
              <td>Flood magnitude</td>

              <td>Single estimate derived from each set of inputs</td>

              <td>Simple average (or median) of <emphasis
              role="italic">N</emphasis> simulations</td>
            </tr>

            <tr>
              <td>ARR guidance</td>

              <td><xref linkend="book4"/></td>

              <td><xref linkend="book4"/></td>

              <td><xref linkend="book4"/></td>

              <td><xref linkend="book4"/></td>
            </tr>
          </tbody>
        </table></para>
    </section>

    <section xml:id="b1_ch3_s_8739o">
      <title>Event-based simulation</title>

      <para>The simple design event method represents common industry practice
      in Australia and overseas, and traditionally includes the use of the
      Rational Method, Unit Hydrograph, SCS, Gradex and runoff-routing
      procedures (Haan and Schulze, 1987; Cordery and Pilgrim, 2000; McKercher
      and Macky, 2001; Smithers, 2012). With this approach, a rainfall event
      with pre-selected AEP and duration is transformed into a flood
      hydrograph by a simple hydrologic model (or transfer function). The
      approach is termed “deterministic” in the sense that the single
      resulting flood output is uniquely derived from a set of inputs that are
      explicitly selected. The transformation often involves the application
      of two modelling steps, namely: <orderedlist numeration="lowerroman">
          <listitem>
            <para>a <emphasis role="italic">runoff production model</emphasis>
            - to convert the storm rainfall input at any point in the
            catchment into rainfall excess (or runoff) at that location,
            and;</para>
          </listitem>

          <listitem>
            <para>a <emphasis role="italic">hydrograph formation
            model</emphasis> - to simulate the conversion of rainfall excess
            into a flood hydrograph at the point of interest.</para>
          </listitem>
        </orderedlist>The AEP of the derived flood is assumed to be the same
      as the input rainfall. This assumption is made on the basis that the
      hydrologic factors that control runoff production are set to be
      probability-neutral. In practice this means that factors related to the
      temporal and spatial distribution of rainfall, antecedent conditions and
      losses, are set to “typical” values (from the central tendency of their
      distributions) that are associated with the input rainfall. Factors
      related to formation of the hydrograph are generally assumed to be
      invariant with rainfall. Design events for different rainfall durations
      are simulated, and the one producing the highest peak flow
      (corresponding to the critical rainfall duration) is adopted as
      producing the design flood for the selected AEP (flood quantile).</para>

      <para>The ensemble event method represents a modest increase in
      computational requirements. Rather than adopting typical fixed values of
      inputs in the hope of achieving probability-neutrality, modelled inputs
      are selected from an ensemble of inputs and the simulation results are
      based on the central tendency of the outputs (ie. the average or the
      median, as judged appropriate for the degree of non-linearity involved).
      If the members of the ensemble do not occur with equal likelihood (as
      would usually be the case with temporal patterns) then it will be
      necessary to weight the results by the relative likelihood of the
      selected inputs occurring. A representative hydrograph from the ensemble
      can be scaled to match the derived peak for design purposes. This
      approach represents a simple means of accounting for the hydrologic
      variability of a single dominant factor (ie temporal patterns), and
      testing has demonstrated (eg Sih et al, 2008; Entura , 2015;
      <?oxy_comment_start author="retallick" timestamp="20151128T154256+1100" comment="add to reference list wma tp report 3 "?>WMAwater<?oxy_comment_end ?>,
      2015) that this approach provides results for many practical purposes
      that are similar to that obtained from more rigorous methods.</para>

      <para>The basis of the Monte Carlo event method is a recognition that
      flood maxima can result from a variety of combinations of flood
      producing factors, rather than from a single combination as is assumed
      with the design event approach. For example, the same peak flood could
      result from a large, front-loaded storm on a dry basin, or a moderate,
      more uniformly distributed storm on a saturated basin. Such approaches
      attempt to mimic the joint variability of the hydrologic factors of most
      importance, thereby providing a more realistic representation of the
      flood generation processes. The method is easily adapted to focus on
      only those aspects that are most relevant to the problem. To this end,
      it is possible to adopt single fixed values for factors that have only a
      small influence on runoff production, and full distributions (or data
      ensembles) for other more important inputs, such as losses, and temporal
      patterns, or any influential factor (such as initial reservoir level)
      that may impact on the outcome. The approach involves undertaking
      numerous simulations where the stochastic factors are sampled in
      accordance with the variation observed in nature and any dependencies
      between the different factors. In the most general Monte Carlo
      simulation approach for design flood estimation, rainfall events of
      different durations are sampled stochastically from their distribution
      (Weinmann et al, 2002). Alternatively, the simulations can be undertaken
      for specific storm durations (applying the critical rainfall duration
      concept) and the exceedance probability of the desired flood
      characteristic may be computed using the Total Probability Theorem
      (Nathan et al, 2002). The latter approach is simpler and more aligned to
      available design information, and is more easily implemented by those
      familiar with the traditional design event approach.</para>

      <para>The simple design event approach gives a single set of design
      hydrographs that can be used for subsequent modelling steps, such as
      input to a hydraulic model to determine flood levels for a given
      exceedance probability. With the Ensemble and Monte Carlo event methods
      an ensemble of hydrographs is produced and it is often not practical to
      consider all these hydrographs in subsequent simulation steps. With both
      the ensemble and Monte Carlo approaches a representative hydrograph can
      be simply scaled to match the probability-neutral estimate of the peak
      flood; the representative hydrograph needs to capture the typical volume
      and timing characteristics for the selected duration and severity of the
      event, though some of the advantages of ensemble and Monte Carlo event
      methods are lost if an ensemble of events is not used through all the
      key modelling steps.</para>
    </section>

    <section xml:id="b1_ch3_s_4h1lr">
      <title>Continuous simulation</title>

      <para>With continuous simulation approaches, a conceptual model of the
      catchment is used to convert input time series of rainfall and
      evaporation into an output time series of streamflow; the flood events
      of interest are then extracted from the simulated streamflow record and
      analysed by conventional frequency analysis. The models used to
      transform the input rainfall into streamflow tend to be rather more
      complex than those commonly used in the design event or stochastic
      approaches. The main reason for this complexity is the ability of the
      models to account for changes in state variables (eg. soil moisture and
      other catchment stores) during the simulation period. While these models
      have been used for the past 40 years for the prediction of continuous
      flow sequences, their dominant purpose has been for estimation of flow
      sequences for either yield analysis or for environmental considerations
      (Chiew, 2010). However, their use has been extended to the estimation of
      design floods (Cameron et al, 2000; Boughton and Droop, 2003; Blazkova,
      S., &amp; Beven, 2004, 2009).</para>

      <para>“Hybrid” approaches have the potential to capitalise on the
      advantage of both event-based and continuous simulation approaches.
      Typically, hybrid approaches use statistical information on rainfall
      events in combination with continuous simulation and event-based models.
      With these approaches, long term recorded (or stochastic) climate
      sequences can be used in combination with a continuous simulation model
      to generate a time series of catchment soil moisture and streamflows.
      This information is used to specify antecedent conditions for an
      event-based model, which is then used in combination with statistical
      information on rainfall events to generate extreme flood hydrographs.
      For example, SEFM (MGS Engineering, 2009) and SCHADEX (Paquet et al,
      2013) are examples of the hybrid approach. In both these models a
      continuous hydrological simulation model is used to generate the
      possible hydrological states of the catchment, and floods are simulated
      on an event basis. While there are a number of conceptual advantages to
      these methods, significant development would be required for their
      implementation for routine design purposes.</para>
    </section>
  </section>

  <section xml:id="b1_ch3-1e">
    <title>Selection of Approach</title>

    <section xml:id="b1_ch3_s_krhjd">
      <title>Overview</title>

      <para>The methods described above have their differing strengths and
      weaknesses, and this means that each method is suited to a particular
      range of data availability and design contexts. While the broad
      differences in the applicability of the different methods are discussed
      below, it should be recognised that there is considerable overlap in
      their ranges of applicability and it is strongly advisable to apply more
      than one method to any given design situation. The comparison of
      different methods yields insights about errors or assumptions that might
      otherwise be missed, and the process of reconciling the different
      assessments provides valuable information that aids adoption of a final
      “best estimate”.</para>

      <para>In developing guidance on the selection of an approach it is first
      worth briefly summarising the strengths and weakness of the different
      methods. This is done separately for flood data based procedures and
      rainfall based procedures, and this is then followed by general guidance
      for selection of an approach.</para>
    </section>

    <section xml:id="b1_ch3_s_xrg5l">
      <title>Advantages and Limitations of Flood Data Based procedures</title>

      <para>The prime advantage of Flood Frequency Analyses is that they
      provide a direct estimate of flood exceedance probabilities based on
      gauged data. Peak flood records represent the integrated response of a
      catchment to storm events and thus are not subject to the potential for
      bias that can affect rainfall-based procedures. Furthermore, Flood
      Frequency Analyses are quick to apply compared to rainfall-based
      procedures and have the ability to provide estimates of uncertainty,
      most easily those associated with the size of sample and gauging errors.
      These represent very considerable advantages, and thus it is not
      surprising that flood frequency analysis is an important tool for the
      practicing flood hydrologist.</para>

      <para>However, there are some practical disadvantages with the
      technique. The available peak flood records may not be representative of
      the conditions relevant to the problem of interest: changing land-use,
      urbanisation, upstream regulation, and non-stationary climate are all
      factors that may confound efforts to characterise flood risk. The length
      of available record may also limit the utility of the flood estimates
      for the rarer quantiles of interest. Also, peak flow records are
      obtained from the conversion of stage data and there may be considerable
      uncertainty about the reliability of the rating curve when extrapolated
      to the largest recorded <?oxy_comment_start author="retallick" timestamp="20151128T170420+1100" comment="refer to data section on rating curves"?>events<?oxy_comment_end ?>.
      There is also uncertainty associated with the choice of probability
      model which is not reflected in the width of derived confidence limits:
      the true probability distribution is unknown and it may be that
      different models may fit the observed data equally well, yet diverge
      markedly when used to estimate flood quantiles beyond the period of
      record.</para>

      <para>Perhaps the most obvious limitation of Flood Frequency Analysis is
      that it relies upon the availability of recorded flood data. This is a
      particular limitation in urban drainage design as there are so few
      gauged records of any utility in developed catchments. But the
      availability of representative records is also often a limitation in
      rural catchments, either because of changed upstream conditions or
      because the site of interest may be remote from the closest gauging
      station.</para>

      <para>For this reason, considerable effort has been expended on the
      development of a regional flood model that can be used to estimate flood
      quantiles in ungauged catchments (<xref linkend="b3_ch3"/>). The prime
      advantage of this technique is that it provides estimates of flood risk
      (with uncertainty) using readily available information at ungauged
      sites; the estimates can also be combined with at-site analyses to help
      improve the accuracy of the estimated flood exceedance probabilities.
      The prime disadvantage of the technique is that the estimates are only
      applicable to the range of catchment characteristics used in development
      of the model, and this largely excludes urbanised catchments and those
      influenced by upstream impoundments (or other source of major
      modification).</para>

      <para>The main advantages and limitations of flood data based procedures
      are summarised in <xref linkend="b1_ch3_t_ee1zg"/>. In addition to the
      points made above, specific mention is made of the applicability of
      Peak-over-Threshold analysis to events more frequent than 10% AEP, and
      the use of Annual Maxima Series for the estimation of rarer events. Also
      included in this table is reference to the use of large scale empirical
      techniques. While these techniques have the advantage of providing an
      indication of the upper limiting bounds on the magnitude of floods using
      national and global data sets (eg Nathan et al, 1994; Herschy, 2003), it
      is difficult to assign exceedance probabilities to such events and thus
      such procedures are better seen as a complement, and not an alternative,
      to traditional regional flood frequency techniques (Castellarin,
      2007).</para>

      <para><table xml:id="b1_ch3_t_ee1zg">
          <caption>Summary of Advantages and Limitations of Common Procedures
          used to Directly Analyse Flood Data</caption>

          <thead>
            <tr>
              <th>Method</th>

              <th>Advantages</th>

              <th>Limitations</th>

              <th>Comments on Applicability</th>
            </tr>
          </thead>

          <tbody>
            <tr>
              <td>Peak-over-Threshold analysis</td>

              <td><itemizedlist>
                  <listitem>
                    <para>Exceedance threshold can be selected to suit
                    frequency range of most interest</para>
                  </listitem>
                </itemizedlist></td>

              <td><itemizedlist>
                  <listitem>
                    <para>Sensitive to adopted independence criteria</para>
                  </listitem>

                  <listitem>
                    <para>Fewer generic software packages available to aid
                    analysis</para>
                  </listitem>
                </itemizedlist></td>

              <td><itemizedlist>
                  <listitem>
                    <para>Particularly suited to exceedance probabilities more
                    frequent than 10% AEP</para>
                  </listitem>

                  <listitem>
                    <para>Requires development of transposition/scaling
                    functions for application to ungauged sites</para>
                  </listitem>
                </itemizedlist></td>
            </tr>

            <tr>
              <td>At-site Flood Frequency Analysis based on Annual Maxima
              Series</td>

              <td><itemizedlist>
                  <listitem>
                    <para>Well established procedures that are strongly
                    supported by literature</para>
                  </listitem>

                  <listitem>
                    <para>Software readily available that includes assessment
                    of uncertainty</para>
                  </listitem>

                  <listitem>
                    <para>Estimates obtained for modest investment of
                    effort</para>
                  </listitem>
                </itemizedlist></td>

              <td><itemizedlist>
                  <listitem>
                    <para>Rare estimates sensitive to length of available
                    record, a small number of rare events, and assumptions of
                    stationarity</para>
                  </listitem>

                  <listitem>
                    <para>Extrapolation best undertaken with knowledge of
                    changing channel geometry and rating curve errors</para>
                  </listitem>
                </itemizedlist></td>

              <td><itemizedlist>
                  <listitem>
                    <para>Requires development of transposition/scaling
                    functions for application to ungauged sites</para>
                  </listitem>
                </itemizedlist></td>
            </tr>

            <tr>
              <td>At-site/regional frequency analysis based on Annual Maxima
              Series</td>

              <td><itemizedlist>
                  <listitem>
                    <para>Well established procedures that are strongly
                    supported by literature</para>
                  </listitem>

                  <listitem>
                    <para>Provides more robust estimates of rare events,
                    especially for sites with limited length of record</para>
                  </listitem>
                </itemizedlist></td>

              <td><itemizedlist>
                  <listitem>
                    <para>Dependent on degree of homogeneity of gauged sites
                    used in the analysis</para>
                  </listitem>

                  <listitem>
                    <para>Requires more specialist expertise than at-site
                    analysis</para>
                  </listitem>
                </itemizedlist></td>

              <td><itemizedlist>
                  <listitem>
                    <para>Functions for transposition to ungauged sites
                    readily derived from regional information used to
                    undertake the analysis</para>
                  </listitem>
                </itemizedlist></td>
            </tr>

            <tr>
              <td>Regional flood model</td>

              <td><itemizedlist>
                  <listitem>
                    <para>Based on rigorous statistical procedure that takes
                    advantage of large processed data sets</para>
                  </listitem>

                  <listitem>
                    <para>Estimates include uncertainty and are derived with
                    small investment of effort</para>
                  </listitem>
                </itemizedlist></td>

              <td><itemizedlist>
                  <listitem>
                    <para>Largely restricted to catchments smaller than 1000
                    km²</para>
                  </listitem>
                </itemizedlist> <itemizedlist>
                  <listitem>
                    <para>Flood response needs to be within range of
                    characteristics used in development of the method</para>
                  </listitem>

                  <listitem>
                    <para>larger degree of uncertainty (wider confidence
                    limits) than flood estimates from at-site analysis</para>
                  </listitem>

                  <listitem>
                    <para>Representativeness of the gauges used</para>
                  </listitem>
                </itemizedlist></td>

              <td><itemizedlist>
                  <listitem>
                    <para>Ease of application allows this to be used as
                    independent estimate for all other methods</para>
                  </listitem>
                </itemizedlist></td>
            </tr>

            <tr>
              <td>Large scale empirical</td>

              <td><itemizedlist>
                  <listitem>
                    <para>Estimates readily obtained once relevant data sets
                    have been sourced</para>
                  </listitem>

                  <listitem>
                    <para>Generally a useful indicator of the upper bound of
                    flood behaviour</para>
                  </listitem>
                </itemizedlist></td>

              <td><itemizedlist>
                  <listitem>
                    <para>Enveloped characteristics may not be relevant to
                    site of interest</para>
                  </listitem>

                  <listitem>
                    <para>Not suited to inferring probabilities of
                    exceedance</para>
                  </listitem>
                </itemizedlist></td>

              <td><itemizedlist>
                  <listitem>
                    <para>Useful as a sanity check on results obtained from
                    other procedures</para>
                  </listitem>

                  <listitem>
                    <para>Regional nature of information allows for
                    application to ungauged sites</para>
                  </listitem>
                </itemizedlist></td>
            </tr>
          </tbody>
        </table></para>
    </section>

    <section xml:id="b1_ch3_s_8gqvw">
      <title>Advantages and Limitations of Rainfall-Based Procedures</title>

      <para>A key advantage of rainfall-based approaches is that they provide
      the means to derive flood hydrographs. The derivation of a full
      hydrograph rather than a single attribute (such as flood peak) allows
      the design loading condition to be assessed in terms of both peak and
      volume, which is of prime importance when considering the mitigating
      influence of flood storage.</para>

      <para>Of arguably greater importance is the ability of rainfall-based
      approaches to take advantage of the extensive availability of rainfall
      data. This is a very important advantage as rainfall characteristics
      vary across space in a more predictable and generally more uniform
      fashion than floods. This feature, along with the greater length and
      density of rainfall gauging, allows the derivation of probabilistic
      estimates of rainfalls that are much rarer and more easily transposed
      than flood characteristics.</para>

      <para>However, these significant advantages are offset by the need to
      transform rainfalls into floods using some kind of design event transfer
      function or simulation model. Common examples of the former include the
      Rational Method and Curve Number method of the US Soil Conservation
      Service; while such methods provide an attractive means of simplifying
      the complexity involved in generation of flood peaks, their use in this
      edition has been replaced by the more defensible implementation of the
      Regional Flood Model (<xref linkend="b3_ch3"/>). The focus of this
      guidance is thus on the use of event-based and continuous simulation
      approaches. While these models provide a conceptually more attractive
      means to derive flood hydrographs arising from storm rainfall events,
      they present the very real potential for introducing probability (AEP)
      bias in the transformation. That is, the methods are well suited to the
      simulation of flood hydrographs, but great care is required when
      assigning exceedance probabilities to the resulting flood
      characteristic.</para>

      <para>The advantages and limitations of some common approaches to
      rainfall-based procedures are summarised in <xref
      linkend="b1_ch3_t_4c8y6"/>. The first row of this table summarises the
      attributes of continuous simulation approaches, and the remaining rows
      refer to event-based approaches.</para>

      <para>The continuous simulation approach has the major advantage that it
      implicitly allows for the correlations between the flood producing
      factors over different time scales. This can be a great advantage in
      some systems (such as a cascade of storages or complex urban
      environments) where the volume of flood runoff is the key determinant of
      flood risk. However, its major drawback for flood estimation is that
      considerable modelling effort is required to reproduce the flood
      characteristics of interest; the structure of continuous simulation
      models is geared towards reproduction of the complete streamflow regime,
      and not on the reproduction of annual maxima. This has implications for
      model structure, as well as for how the model is parameterised and
      calibrated to suit the different flood conditions of interest. With
      continuous simulation, the vast majority of the information used to
      inform model parameterisation is not relevant to flood events other than
      to ensure that the right antecedent conditions prevail before onset of
      the storm. Under extreme conditions, many state variables inherent to
      the model structure might be bounded, and the process descriptions
      relevant to such states may be poorly formulated and yield outcomes that
      are not consistent with physical reasoning; while this is the case for
      flood event models, the more complex structure generally used with
      continuous simulation models may confound attempts to detect the
      occurrence of such behaviour. In addition, if the length of historic
      (sub-daily) rainfalls is not long enough to allow estimation of the
      exceedance probabilities of interest, it will be necessary to use
      stochastic rainfall generation techniques (or some down-scaling
      technique) to produce synthetic sequences of sufficient length. Lastly,
      given the interdependence between model parameters and the difficulty of
      parameter identification, it can be difficult to transpose such models
      to ungauged catchments.</para>

      <para>The deterministic application of “design-event” models based on
      linear and non-linear routing has a long history of application in
      Australia. However, considerable care needs to be taken when selecting
      “typical” values of the key inputs to avoid the introduction of
      probability bias in the transformation of design rainfalls into floods.
      Ensemble event approaches have the potential to mitigate this bias, but
      these are only likely to be defensible for those problems influenced by
      a single dominant factor in addition to rainfall. Monte Carlo techniques
      can be used to derive expected probability quantiles of selected flood
      characteristics arising from the joint interaction of many factors, but
      the defensibility of these estimates rests upon the representativeness
      of the inputs and the correct treatment of correlations which may be
      present.</para>

      <para><table xml:id="b1_ch3_t_4c8y6">
          <caption>Summary of Advantages and Limitations of Common
          Rainfall-Based Procedures</caption>

          <thead>
            <tr>
              <th>Method</th>

              <th>Advantages</th>

              <th>Limitations</th>

              <th>Comments on Applicability</th>
            </tr>
          </thead>

          <tbody>
            <tr>
              <td>Continuous Simulation</td>

              <td><itemizedlist>
                  <listitem>
                    <para>Well suited to assessing flood risk in complex
                    systems that are sensitive to flood volume</para>
                  </listitem>

                  <listitem>
                    <para>Most applicable to range of very frequent to
                    frequent events</para>
                  </listitem>
                </itemizedlist></td>

              <td><itemizedlist>
                  <listitem>
                    <para>Difficult to parameterise model to correctly
                    reproduce the frequency of flood exceedance in manner that
                    adequately captures shape of observed hydrographs</para>
                  </listitem>
                </itemizedlist></td>

              <td><itemizedlist>
                  <listitem>
                    <para>Useful for hindcasting streamflows for sites with
                    short periods of record</para>
                  </listitem>

                  <listitem>
                    <para>Model parameters not easily transposed to ungauged
                    locations</para>
                  </listitem>
                </itemizedlist></td>
            </tr>

            <tr>
              <td>Simple Event</td>

              <td><itemizedlist>
                  <listitem>
                    <para>Long tradition of use thus familiar to most
                    practitioners</para>
                  </listitem>
                </itemizedlist></td>

              <td><itemizedlist>
                  <listitem>
                    <para>Difficult to demonstrate that probability -
                    neutrality is achieved</para>
                  </listitem>
                </itemizedlist></td>

              <td><itemizedlist>
                  <listitem>
                    <para>Little justification to use this simplistic method
                    with currently available computing resources, but suited
                    to derivation of preliminary estimates</para>
                  </listitem>
                </itemizedlist></td>
            </tr>

            <tr>
              <td>Ensemble Event</td>

              <td><itemizedlist>
                  <listitem>
                    <para>Simple means of minimising probability bias for
                    modest level of effort</para>
                  </listitem>

                  <listitem>
                    <para>Well suited to accommodating single source of
                    hydrologic variability in simple catchments</para>
                  </listitem>
                </itemizedlist></td>

              <td><itemizedlist>
                  <listitem>
                    <para>Not suited to considering multiple sources of
                    hydrologic variability or other joint-probability
                    influences</para>
                  </listitem>

                  <listitem>
                    <para>Difficult to determine if probability bias remains
                    in the estimates</para>
                  </listitem>
                </itemizedlist></td>

              <td><itemizedlist>
                  <listitem>
                    <para>Provides easy transition for practitioners familiar
                    with design event method</para>
                  </listitem>

                  <listitem>
                    <para>The required sets of ensemble temporal patterns are
                    now available</para>
                  </listitem>
                </itemizedlist></td>
            </tr>

            <tr>
              <td>Monte Carlo event</td>

              <td><itemizedlist>
                  <listitem>
                    <para>Rigorous means of deriving expected probability
                    estimates for range of factors considered</para>
                  </listitem>

                  <listitem>
                    <para>Readily extended to consider multiple sources of
                    variability and additional joint-probability factors (both
                    anthropogenic and natural)</para>
                  </listitem>
                </itemizedlist></td>

              <td><itemizedlist>
                  <listitem>
                    <para>Requires specialist skills to develop bespoke
                    solutions and thus dependent on availability of
                    software</para>
                  </listitem>

                  <listitem>
                    <para>For more complex applications care needs to be taken
                    to ensure correlations between dependent factors are
                    appropriately considered</para>
                  </listitem>
                </itemizedlist></td>

              <td><itemizedlist>
                  <listitem>
                    <para>Non-dimensional loss distributions and temporal
                    pattern ensembles are now available</para>
                  </listitem>

                  <listitem>
                    <para>The expected probability estimates account for
                    hydrologic variability not parameter uncertainty as the
                    necessary information on governing distributions is
                    generally not available.</para>
                  </listitem>
                </itemizedlist></td>
            </tr>
          </tbody>
        </table></para>
    </section>

    <section xml:id="b1_ch3_s_6yx28">
      <title>Relative Applicability of Different Approaches</title>

      <para>The broad nature of applicability of the different methods is
      illustrated in <xref linkend="b1_ch3_f_9qc3y"/>. <xref
      linkend="b1_ch3_f_9qc3y"/> is not intended to be prescriptive, but
      rather it is intended to illustrate the relative ability of the
      different methods to provide unbiased estimates of flood characteristics
      in the given AEP range. <xref linkend="b1_ch3_f_9qc3y"/>is best
      interpreted with reference to <xref linkend="b1_ch3_t_ee1zg"/> which
      summarises the strengths and limitations of each method and provides
      some brief comments on their application.</para>

      <para>Flood Frequency Analyses are most relevant to the estimation of
      peak flows for Very Frequent to Rare floods. Flood Frequency Analysis
      methods can also be applied to other flood characteristics (e.g. flood
      volume over given duration) but this involves additional
      assumptions.</para>

      <para>Peak-Over-Threshold analysis (<xref linkend="b3_ch2_s7"/>) is most
      relevant to the estimation of flood exceedances that occur several times
      a year, up to floods more frequent than around 10% AEP. For rarer events
      the use of an Annual Maximum Series is preferred (<xref
      linkend="b3_ch2_s6"/>), and with good quality information at-site
      frequency analyses are suited to the estimation of Rare floods of 2% and
      1% AEP. The use of regional flood data provides valuable information
      that can be used to help parameterise the shape of the flood
      distribution, and thus where feasible it is desirable to use
      at-site/regional flood frequency methods (<xref linkend="b3_ch2_s6"/>).
      The use of regional information can support the estimation of flood
      risks beyond 1% AEP and can greatly increase the confidence of estimates
      obtained using information at a single site.</para>

      <figure label="1032" xml:id="b1_ch3_f_9qc3y">
        <title>Illustration of Relative Efficacy of Different Approaches for
        the Estimation of Design Floods</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="../../figures/1032.png"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>The RFFE model (Rahman et al, 2014; <xref linkend="b3_ch2_s6"/>)
      provides estimates of peak flows for Frequent to Rare floods for sites
      where there is no streamflow data. While its primary purpose is for the
      estimation of flood quantiles, the resulting estimates can also be used
      to develop scaling functions to support the transposition of results
      obtained from rainfall-based procedures to ungauged sites. This is the
      same concept as the simple quantile regression approach discussed above,
      but as it is based on a more rigorous statistical procedure it is more
      suited to transposition of results where factors other than merely area
      are important. The RFFE method is quick to apply and provides a formal
      assessment of uncertainty, and thus is well suited to provide
      independent estimates for comparison with other approaches.</para>

      <para><xref linkend="b1_ch3_f_9qc3y"/> also illustrates the areas of
      design application most suited to rainfall-based procedures. These are
      applicable over a wider range of AEPs than techniques based directly on
      the analysis of flow data as it is easier to extrapolate rainfall
      behaviour across space and time than it is for flow data. But while
      these methods can capitalise on our ability to extrapolate rainfall data
      to rarer AEPs and infill spatial gaps in observations more readily than
      flows, their use introduces the need to model the transformation of
      rainfalls into floods.</para>

      <para>Continuous simulation procedures are well suited to the analysis
      of complex systems which are dependent on the sequencing of flood
      volumes as the method implicitly accounts for the joint probabilities
      involved. Application of these methods require more specialist skill
      than event-based procedures; for example, it is important that the
      probabilistic behaviour of the input rainfall series relevant to the
      catchment (either historic or synthetic) is consistent with design
      rainfall information provided in <xref linkend="book2"/>, and that the
      model structure yields flood hydrographs that are consistent with
      available evidence. Transposition of model parameters to ungauged sites
      presents significant technical difficulties which would require
      specialist expertise to resolve. Given these challenges it is presently
      recommended that the main benefit of continuous simulation approaches is
      for the extension of flow records at gauged sites with short periods of
      record, where system performance is critically dependent on the
      sequencing of flow volumes; if flow data are not available, then it may
      be appropriate to consider their application to small scale urban
      environments where runoff processes can be inferred from an analysis of
      effective impervious areas. Its position in <xref
      linkend="b1_ch3_f_9qc3y"/> indicates the degree of accuracy of results
      that can be expected from this method relative to at-site frequency
      analysis.</para>

      <para>By comparison with continuous simulation models, event-based
      models are far more parsimonious and more easily transposed to ungauged
      catchments; it is easier to fit the fewer model parameters involved to
      observed floods, and their structure has been tailored specifically to
      represent flood behaviour. However, while such models are easily
      calibrated and their parameterisation is generally commensurate with the
      nature of available data, their use generally involves the simulation of
      floods beyond the observed record. As such, it is necessary to make
      assumptions about the changing nature of non-linearity of flood response
      with flood magnitude and trust that the model structure and adopted
      process descriptions are applicable over the range of floods being
      simulated. These assumptions introduce major uncertainties into the
      flood estimates, and this uncertainty increases markedly with the degree
      of extrapolation involved. This issue is discussed in greater detail in
      <xref linkend="book8"/>.</para>

      <para>The event-based methods considered in these guidelines generally
      involve a similar suite of storage-routing methods (<xref
      linkend="book5"/>). There are some conceptual differences in the way
      that these models are formulated, but in general these differences are
      minor compared to the constraints imposed by the available data.
      Australian practice has generally not favoured the use of
      unitgraph-based methods combined with node-link routing models (eg
      Feldman, 2000); in principle such models are equally defensible as
      storage-routing methods, and the strongest reason to prefer the latter
      is the desire for consistency when used to estimate Extreme floods that
      are well beyond the observed record, and also for the local experience
      with regionalisation of model parameters.</para>

      <para>Perhaps the greatest choice to be made with event-based models is
      the adopted simulation environment (as discussed in <xref
      linkend="book4"/>). For systems that are sensitive to differences in
      temporal patterns there is little justification to use simple event
      methods: the additional computational burden imposed by ensemble event
      models is modest, and the resulting estimates are much more likely to
      satisfy the assumption of probability-neutrality. However, this
      additional effort may not be warranted in those urban systems which are
      dominated by hydraulic controls, and in such cases the most appropriate
      modelling approach is likely to be a hydraulic modelling system with
      flow inputs provided in a deterministic manner. Monte Carlo event
      schemes provide a rigorous solution to the joint probabilities involved,
      and the solution scheme ensures expected probability quantiles that are
      probability-neutral, at least for the given set of ensemble inputs and
      distributions used to characterise hydrologic variability in the key
      selected inputs. For those catchments or systems where flood outputs are
      strongly dependent on the joint likelihood of multiple factors, it is
      necessary to adopt a Monte Carlo event approach.</para>

      <para>The greatest uncertainties in terms of both flood magnitude and
      exceedance probabilities are associated with the estimation of Extreme
      floods beyond 1 in 2000 AEP. There is very little data to support
      probabilistic estimates of floods in this range, and it is prudent to
      compare such estimates with empirical analysis of maxima based from
      national (eg Nathan et al, 1994) or even global (Herschy, 2003) data
      sets.</para>

      <para>It should be noted that the procedures based directly on the
      analysis of flood data can readily provide an assessment of uncertainty.
      Additional uncertainty is introduced when transposing flood information
      to locations away from the gauging site used in the analysis, and the
      Regional Flood Frequency Estimation Method (RFFE) is the only method
      where this is provided in a form easily accessed by practitioners. The
      Monte Carlo event approach provides an appropriate framework to consider
      uncertainty in a formal fashion, though this will only provide
      indicative uncertainties: the greater the degree of extrapolation the
      greater the influence of uncertainty due to model structure and this is
      a factor that is not easily characterised. The uncertainty bounds shown
      in the top panel of <xref linkend="b1_ch3_f_9qc3y"/> are clearly
      notional and merely reflect the fact that uncertainty of the estimates
      increase markedly with event magnitude. It must be accepted that when
      the above procedures are applied to locations not included in their
      calibration that the associated uncertainties will be perhaps up to an
      order of magnitude greater.</para>

      <para>Lastly, it needs to be recognised that the ranges of applicability
      of the different methods illustrated in <xref linkend="b1_ch3_f_9qc3y"/>
      are somewhat notional, and that there is considerable overlap in their
      ranges of applicability. It is thus strongly advisable to apply more
      than one method to any given design situation, where adoption of a final
      “best estimate” is ideally achieved by weighting estimates obtained from
      different methods by their uncertainty. Estimates of uncertainty for
      flood frequency analyses and regional flood estimates are provided in
      <xref linkend="book3"/>, and methods for use with rainfall-based
      techniques are provided in <xref linkend="book4"/>, with examples
      showing how uncertainty propagates through to the design outcome being
      provided in <xref linkend="book7"/>. In practice, the information
      required to assign relative uncertainties to different methods is either
      limited or difficult to obtain, and careful judgment will be required to
      derive a single best estimate with associated confidence
      intervals.</para>
    </section>
  </section>

  <section>
    <title>References</title>

    <para>Blazkova, S., &amp; Beven, K. (2004). Flood frequency estimation by
    continuous simulation of subcatchment rainfalls and discharges with the
    aim of improving dam safety assessment in a large basin in the Czech
    Republic. <emphasis role="italic">Journal of Hydrology</emphasis>,
    292(1-4), 153–172. doi:10.1016/j.jhydrol.2003.12.025</para>

    <para>Blazkova, S., and K. Beven (2009), A limits of acceptability
    approach to model evaluation and uncertainty estimation in flood frequency
    estimation by continuous simulation: Skalka catchment, Czech Republic,
    <emphasis role="italic">Water Resour. Res.</emphasis>, 45, W00B16,
    doi:10.1029/2007WR006726.</para>

    <para>Cameron, D., Beven, K., and Naden, P. (2000): Flood frequency
    estimation by continuous simulation under climate change (with
    uncertainty), <emphasis role="italic">Hydrol. Earth Syst. Sci.</emphasis>,
    4, 393-405, doi:10.5194/hess-4-393-2000.</para>

    <para>Castellarin, A. (2007). Probabilistic envelope curves for design
    flood estimation at ungauged sites. <emphasis role="italic">Water
    Resources Research</emphasis>, 43(4), 1–12.
    doi:10.1029/2005WR004384</para>

    <para>Chiew, F. H. S. (2010). Lumped Conceptual Rainfall-Runoff Models and
    Simple Water Balance Methods: Overview and Applications in Ungauged and
    Data Limited Regions. <emphasis role="italic">Geography
    Compass</emphasis>, 4(3), 206–225.
    doi:10.1111/j.1749-8198.2009.00318.x</para>

    <para>Boughton, W and Droop, O, (2003): Continuous simulation for design
    flood estimation - a review, <emphasis role="italic">Environmental
    Modelling and Software</emphasis>, 18:309-318.</para>

    <para>Cordery I and Pilgrim DH (2000): The State of the Art of Flood
    Prediction. In: Parker DJ (ed.) <emphasis role="italic">Floods. Volume
    II.</emphasis> Routledge, London. 185–197.</para>

    <para>Entura Report (when finalised/included in AR&amp;R?) – evaluation of
    different approaches.</para>

    <para>Feldman, A. D. (2000). Hydrologic Modeling System HEC-HMS Technical
    Reference Manual. CDP-74B, U.S. Army Corps of Engineers.</para>

    <para>Haan, C., &amp; Schulze, R. (1987). Return Period Flow Prediction
    with Uncertain Parameters. <emphasis role="italic">American Society of
    Agricultural Engineers</emphasis>, 30(3), 665–669.
    doi:10.1109/IWCFTA.2011.52</para>

    <para>Herschy, R. (2003): <emphasis role="italic">World catalogue of
    maximum observed floods</emphasis>. IAHS Publ No. 284, 285 pp.</para>

    <para>Kuczera, G., Lambert, M.F., Heneker, T. Jennings, S., Frost, A. and
    Coombes, P. (2006) Joint probability and design storms at the crossroads,
    <emphasis role="italic">Australian Journal of Water Resources</emphasis>,
    10(2), 5-21.</para>

    <para>McKerchar, a. I., &amp; Macky, G. H. (2001). Comparison of a
    regional method for estimating design floods with two rainfall-based
    methods. <emphasis role="italic">Journal of Hydrology New
    Zealand</emphasis>, 40(2), 129–138.</para>

    <para>MGS Engineering Consultants (2009): <emphasis role="italic">General
    Stochastic Event Flood Model (SEFM), Technical Support Model</emphasis>.
    Manual prepared for the United States Department of Interior, Bureau of
    Reclamation Flood Hydrology Group.</para>

    <para>Nathan R.J., Weinmann P.E., and Gato S. (1994) A quick method for
    estimation of the probable maximum flood in southeast Australia.
    International Hydrology and Water Resources Symposium: Water Down Under,
    November, Adelaide, I.E. Aust. Natl. Conf. Publ. No. /94, 229-234.</para>

    <para>Paquet, E., Garavaglia, F., Gailhard, J. and Garçon, R. (2013), The
    SCHADEX method: a semi-continuous rainfall-runoff simulation for extreme
    flood estimation, <emphasis role="italic">J Hydrol</emphasis> Vol 495,
    23–37.</para>

    <para>Rahman, A., Haddad, K, Haque, M, Kuczera, G., Weinmann, E. (2014):
    <emphasis role="italic">Project 5 Regional Flood Methods: Stage
    3</emphasis>, report prepared for Australian Rainfall and Runoff Revision
    Process.</para>

    <para>Sih, K., Hill, P., &amp; Nathan, R. J. (2008): Evaluation of simple
    approaches to incorporating variability in design temporal patterns.
    <emphasis role="italic">Proc Water Down Under Hydrology and Water
    Resources Symposium</emphasis>, (pp. 1049–1059).</para>

    <para>Smithers, J. C. (2012): Methods for design flood estimation in South
    Africa, Water SA, 38(4), 633-646.</para>

    <para>Weinmann PE, Rahman A, Hoang TMT, Laurenson EM, Nathan RJ. (2002):
    Monte Carlo simulation of flood frequency curves from rainfall - the way
    ahead, <emphasis role="italic">Australian Journal of Water
    Resources</emphasis>, IEAust, 6(1):71-80.</para>
  </section>
</chapter>
